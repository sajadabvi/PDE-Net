--name=burgers-2-upwind-sparse0.005-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=2 --device=cuda:0 --stablize=0 --sparsity=0.005 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
0
--name=burgers-2-upwind-sparse0-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=2 --device=cuda:1 --stablize=0 --sparsity=0 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
1
--name=burgers-2-central-sparse0.005-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=2 --device=cuda:2 --stablize=0 --sparsity=0.005 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
2
--name=burgers-2-central-sparse0-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=2 --device=cuda:3 --stablize=0 --sparsity=0 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
3
wait
{'--name': 'burgers-2-central-sparse0-noise0.001', '--dtype': 'double', '--device': 'cuda:3', '--constraint': '2', '--dt': 0.01, '--cell_num': 1, '--eps': 6.283185307179586, '--blocks': [0, 1, 2, 3, 4, 5, 6, 9, 12, 15, 18, 21, 24, 27, 30, 35, 40], '--kernel_size': 5, '--max_order': 2, '--dx': 0.19634954084936207, '--hidden_layers': 5, '--scheme': 'upwind', '--dataname': 'burgers', '--viscosity': 0.05, '--zoom': 4, '--max_dt': 0.000625, '--batch_size': 28, '--data_timescheme': 'rk2', '--channel_names': 'u,v', '--freq': 4, '--data_start_time': 1.0, '--start_noise': 0.001, '--end_noise': 0.001, '--stablize': 0.0, '--sparsity': 0.0, '--momentsparsity': 0.001, '--npseed': -1, '--torchseed': -1, '--maxiter': 2000, '--recordfile': 'None', '--recordcycle': 200, '--savecycle': -1, '--start_from': -1}
Traceback (most recent call last):
  File "train.py", line 58, in <module>
    globalnames, callback, model, data_model, sampling, addnoise = setenv.setenv(options)
  File "/data/users2/sajad/code/PDE-Net/setenv.py", line 68, in setenv
    globalnames, callback, model = _set_model(options)
  File "/data/users2/sajad/code/PDE-Net/setenv.py", line 45, in _set_model
    model.to(globalnames['device'])
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 386, in to
    return self._apply(convert)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 193, in _apply
    module._apply(fn)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 193, in _apply
    module._apply(fn)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 205, in _apply
    self._buffers[key] = fn(buf)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 384, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
{'--name': 'burgers-2-upwind-sparse0-noise0.001', '--dtype': 'double', '--device': 'cuda:1', '--constraint': '2', '--dt': 0.01, '--cell_num': 1, '--eps': 6.283185307179586, '--blocks': [0, 1, 2, 3, 4, 5, 6, 9, 12, 15, 18, 21, 24, 27, 30, 35, 40], '--kernel_size': 5, '--max_order': 2, '--dx': 0.19634954084936207, '--hidden_layers': 5, '--scheme': 'upwind', '--dataname': 'burgers', '--viscosity': 0.05, '--zoom': 4, '--max_dt': 0.000625, '--batch_size': 28, '--data_timescheme': 'rk2', '--channel_names': 'u,v', '--freq': 4, '--data_start_time': 1.0, '--start_noise': 0.001, '--end_noise': 0.001, '--stablize': 0.0, '--sparsity': 0.0, '--momentsparsity': 0.001, '--npseed': -1, '--torchseed': -1, '--maxiter': 2000, '--recordfile': 'None', '--recordcycle': 200, '--savecycle': -1, '--start_from': -1}
block:  0
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  2.0993329542545274
current stage is: warmup
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9497, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2427,  2.0638,  1.8863, 19.5004,  9.8155, 16.3562,  0.2481,  1.9405,
         2.0823, 16.7153,  9.7067, 18.9862], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 13.04
Func: 5.31e+00  |g|: 3.16e+00
stableloss: 3.18e-03   dataloss: 5.31e+00   sparseloss: 2.42e+01 momentloss: 7.27e+00
iter:   200    time: 10.45
Func: 3.42e-02  |g|: 2.18e-02
stableloss: 1.14e-02   dataloss: 3.42e-02   sparseloss: 5.33e+01 momentloss: 7.27e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.031940
         Iterations: 315
         Function evaluations: 392
         Gradient evaluations: 385
convolution moment and kernels
[[1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 0.    1.    0.   -0.33 -0.25]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 2.78e-17  3.33e-16 -1.50e+00  2.00e+00 -5.00e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[ 0.    0.    0.    0.    0.  ]
 [ 1.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [-0.33  0.    0.    0.    0.  ]
 [-0.25  0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  2.78e-17  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  3.33e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.50e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -5.00e-01  0.00e+00  0.00e+00]]
[[0.   0.   1.   0.   0.08]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [-2.22e-16  1.00e+00 -2.00e+00  1.00e+00 -1.53e-16]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 6.94e-03 -5.56e-02  9.25e-18  5.56e-02 -6.94e-03]
 [-5.56e-02  4.44e-01 -7.40e-17 -4.44e-01  5.56e-02]
 [ 9.25e-18 -7.40e-17  1.23e-32  7.40e-17 -9.25e-18]
 [ 5.56e-02 -4.44e-01  7.40e-17  4.44e-01 -5.56e-02]
 [-6.94e-03  5.56e-02 -9.25e-18 -5.56e-02  6.94e-03]]
[[0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [1.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.08 0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00 -2.22e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.53e-16  0.00e+00  0.00e+00]]
SymNet parameters
[[-0.82 -0.16 -0.12 -0.04 -0.03  0.    0.22 -0.   -0.02  0.    0.01 -0.  ]
 [ 1.08 -0.42  0.05  0.35  0.2  -0.03  0.35  0.06  0.13 -0.05 -0.04  0.01]]
SymNet parameters
[-0.01  0.08]
SymNet parameters
[[ 4.56e-02 -5.61e-02  3.67e-03  5.61e-02  2.44e-02 -2.09e-03  1.70e+00  8.25e-03
   3.04e-02 -8.01e-03 -3.66e-03  1.38e-03  1.16e-02]
 [ 5.41e-01 -4.44e-01  8.14e-01 -1.24e-01 -7.35e-02  1.33e-02  5.72e-01 -1.29e-02
  -4.77e-02  1.04e-02  1.29e-02 -4.61e-03 -9.65e-04]]
SymNet parameters
[-0.16 -0.  ]
SymNet parameters
[[-6.70e-01 -7.06e-01 -9.50e-02 -1.89e-01 -1.11e-01  1.47e-02  8.93e-01 -2.50e-02
  -6.98e-02  2.08e-02  2.12e-02 -7.72e-03  1.01e-02  5.75e-04]
 [ 1.30e+00 -1.03e-01  1.29e-02  1.01e-01  5.95e-02 -6.39e-03  8.33e-01  2.37e-02
   4.06e-02 -1.90e-02 -1.41e-02  3.44e-03 -1.64e-02 -9.41e-04]]
SymNet parameters
[-0.08  0.11]
SymNet parameters
[[ 0.9  -0.32  0.43  0.12 -0.33  0.28  0.06 -0.07 -0.12 -0.05  0.1  -0.13  0.28  0.19
  -0.14]
 [ 0.6   0.72 -0.1  -0.16 -0.11  0.1   0.29 -0.15  0.26 -0.34 -0.07  0.    0.08 -0.51
  -0.23]]
SymNet parameters
[-0.03  0.05]
SymNet parameters
[[ 0.83 -1.06  0.1  -0.37 -0.46  0.11  0.13  0.18 -0.23  0.02  0.05 -0.13  0.15  0.13
   0.18 -0.07]
 [-0.52  0.66  0.04 -0.07 -0.03  0.02 -0.08  0.25 -0.1  -0.22 -0.05 -0.06 -0.45  0.15
  -0.3   0.  ]]
SymNet parameters
[ 0.01 -0.13]
SymNet parameters
[[ 7.74e-02  9.21e-02 -7.35e-02  7.03e-02  2.19e-02  3.21e-02 -7.34e-02  8.50e-03
   1.04e-02 -3.74e-03 -6.87e-03  7.10e-04 -8.81e-01 -6.12e-01  8.95e-01  6.65e-03
  -1.42e-02]]
SymNet parameters
[0.01]
SymNet parameters
[[-0.98  0.   -0.01  0.    0.01 -0.    0.99  0.05  0.08  0.01 -0.04  0.05]
 [ 0.39  0.24 -0.25  0.01 -0.04  0.01  0.59 -0.61  0.75 -0.09  0.03  0.24]]
SymNet parameters
[-0.2  -0.12]
SymNet parameters
[[ 7.49e-01 -1.11e-01  1.20e-01 -4.97e-03  9.05e-04  2.54e-03 -5.95e-01  3.95e-01
   4.61e-01  1.77e-02  7.75e-02 -1.75e-01 -7.80e-03]
 [ 2.22e-02 -5.31e-02  5.68e-02 -8.61e-04  1.14e-02 -1.14e-03 -9.46e-01 -4.05e-02
  -1.55e-01  2.22e-02 -1.23e-02 -4.02e-02  2.53e-03]]
SymNet parameters
[0.15 0.03]
SymNet parameters
[[-8.31e-01  2.40e-02 -2.24e-02  5.69e-03 -9.10e-04  1.54e-03 -2.77e-01 -2.08e-01
   2.17e-01 -2.09e-03 -2.47e-05  4.33e-02  1.97e-03 -4.83e-03]
 [-2.91e-01  2.90e-02 -3.25e-02 -6.69e-03 -3.69e-02  9.01e-03 -2.01e-01 -3.24e-01
  -4.54e-01 -5.32e-02  1.26e-01 -9.65e-02 -1.41e-02 -4.75e-04]]
SymNet parameters
[-0.06 -0.21]
SymNet parameters
[[-0.43  0.03 -0.04 -0.06 -0.01 -0.01 -0.98 -0.31  0.07 -0.04 -0.11 -0.13  0.06 -0.06
  -0.01]
 [ 0.77 -0.19  0.26 -0.04  0.09 -0.01 -0.51 -0.36  0.23  0.22 -0.23  0.01  0.15  0.54
   0.42]]
SymNet parameters
[0.3  0.11]
SymNet parameters
[[-1.3  -0.03  0.03 -0.    0.01 -0.    0.12  0.13  0.23  0.01 -0.02 -0.03  0.01  0.01
   0.03 -0.01]
 [ 0.16  0.25 -0.27  0.   -0.08  0.02 -1.09  0.54  0.34 -0.14  0.16  0.11 -0.    0.02
   0.01 -0.01]]
SymNet parameters
[ 0.02 -0.23]
SymNet parameters
[[-0.   -0.03  0.03 -0.    0.   -0.    0.08  0.12 -0.09  0.05 -0.01  0.01 -0.62  0.74
  -0.61  0.04  0.42]]
SymNet parameters
[0.02]
finally, finish this stage
iter:   315    time: 8.98
Func: 3.19e-02  |g|: 3.64e-02
stableloss: 1.19e-02   dataloss: 3.19e-02   sparseloss: 6.07e+01 momentloss: 7.27e+00
current expression:
[u00*u01, u10*v00, u00, u02, u20, u00**3, u00**2*u02, u00**2, u00*u01**2, u00*u11, u01*u10*v00, u02*v00, u00*u01*v00, u01, u00*v00, u10, u01*u10, u00*u02, v01, u00**2*v00]
[-0.89 -0.88  0.05  0.04  0.03 -0.02 -0.01 -0.01  0.01 -0.01  0.01 -0.01 -0.01 -0.01
  0.01  0.01 -0.   -0.    0.    0.  ]
[u00*v01, v00*v10, v20, v02, v00, v00**3, u00, v00**2*v20, u00*v01*v10, v00*v10**2, u00*v00*v11, v00**2*v01, v00*v20, u00**2*v01, u01*v00, u10*v00, u00**2*v00, v11, u00**2*u10, u00**3]
[-0.89 -0.89  0.04  0.04  0.03 -0.02  0.01 -0.01  0.01  0.01  0.01  0.01 -0.01 -0.01
 -0.01  0.01  0.   -0.   -0.   -0.  ]
block:  1
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -1.3583791258058904
current stage is: block-1
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8653, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2750,  2.3174,  2.0941, 21.6585, 10.3666, 18.2826,  0.2661,  2.1465,
         2.2530, 18.8896, 10.8481, 20.9448], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 1052.82
Func: 4.72e-02  |g|: 6.09e-01
stableloss: 1.95e-02   dataloss: 3.99e-02   sparseloss: 6.07e+01 momentloss: 7.27e+00
iter:   200    time: 10.76
Func: 2.16e-02  |g|: 2.43e-02
stableloss: 1.42e-02   dataloss: 1.48e-02   sparseloss: 6.10e+01 momentloss: 6.79e+00
iter:   400    time: 10.53
Func: 2.06e-02  |g|: 8.49e-03
stableloss: 1.19e-02   dataloss: 1.41e-02   sparseloss: 6.38e+01 momentloss: 6.48e+00
iter:   600    time: 10.59
Func: 2.02e-02  |g|: 1.13e-02
stableloss: 1.18e-02   dataloss: 1.37e-02   sparseloss: 6.75e+01 momentloss: 6.48e+00
iter:   800    time: 10.59
Func: 1.99e-02  |g|: 6.96e-03
stableloss: 1.22e-02   dataloss: 1.35e-02   sparseloss: 7.22e+01 momentloss: 6.49e+00
iter:  1000    time: 11.27
Func: 1.98e-02  |g|: 2.96e-02
stableloss: 1.22e-02   dataloss: 1.34e-02   sparseloss: 7.56e+01 momentloss: 6.47e+00
iter:  1200    time: 11.37
Func: 1.98e-02  |g|: 1.61e-01
stableloss: 1.22e-02   dataloss: 1.33e-02   sparseloss: 7.97e+01 momentloss: 6.48e+00
iter:  1400    time: 10.61
Func: 1.98e-02  |g|: 2.16e-02
stableloss: 1.23e-02   dataloss: 1.33e-02   sparseloss: 8.48e+01 momentloss: 6.47e+00
iter:  1600    time: 10.43
Func: 1.98e-02  |g|: 1.07e-02
stableloss: 1.23e-02   dataloss: 1.33e-02   sparseloss: 8.76e+01 momentloss: 6.47e+00
iter:  1800    time: 11.20
Func: 1.98e-02  |g|: 1.06e-01
stableloss: 1.23e-02   dataloss: 1.33e-02   sparseloss: 8.91e+01 momentloss: 6.48e+00
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.019739
         Iterations: 2000
         Function evaluations: 2004
         Gradient evaluations: 2004
convolution moment and kernels
[[ 1.00e+00  0.00e+00  2.07e-04  2.41e-03 -3.51e-02]
 [ 0.00e+00  4.87e-05  2.59e-03  1.50e-03  3.33e-03]
 [ 2.07e-04  6.34e-04  2.04e-03 -1.24e-03  9.24e-04]
 [-8.43e-03  1.20e-03  4.52e-03 -2.58e-03 -7.76e-03]
 [-1.96e-02  2.77e-02  6.72e-04 -7.27e-03  6.91e-05]]
[[ 0.01 -0.04  0.01  0.01 -0.  ]
 [-0.03  0.14  0.01 -0.06  0.01]
 [-0.   -0.    0.66  0.29 -0.07]
 [-0.01  0.06  0.16 -0.15  0.04]
 [ 0.   -0.01 -0.06  0.05 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.01e-01 -6.63e-02]
 [ 0.00e+00  0.00e+00  4.45e-03  5.78e-04  3.00e-04]
 [ 0.00e+00  1.43e-02  1.69e-03  1.52e-02 -7.34e-03]
 [ 4.74e-03  2.78e-04  4.30e-04  8.79e-04 -2.02e-03]
 [ 1.53e-03 -3.99e-03 -4.23e-03 -5.65e-03 -2.74e-03]]
[[ 2.47e-03 -5.00e-03  3.12e-03  2.52e-03 -3.96e-03]
 [-2.12e-02  4.62e-02 -4.92e-02  6.44e-03  1.63e-02]
 [ 1.03e-01 -5.82e-01 -3.03e-01  1.02e+00 -2.27e-01]
 [-1.67e-02  3.46e-02 -4.47e-02 -3.93e-03  1.99e-02]
 [ 5.62e-05  3.46e-03 -3.78e-03  9.79e-03 -5.63e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.49e-03  3.76e-03]
 [ 1.00e+00  0.00e+00  6.75e-03 -5.94e-04 -2.34e-02]
 [ 0.00e+00  1.13e-02  5.10e-04 -7.87e-03 -2.47e-03]
 [-1.02e-01  3.52e-03  8.11e-03 -2.22e-03 -9.66e-03]
 [-6.62e-02  2.19e-02 -5.83e-03 -8.32e-03 -1.28e-04]]
[[ 0.01 -0.04  0.11 -0.   -0.  ]
 [-0.02  0.09 -0.55 -0.04  0.02]
 [ 0.03 -0.17 -0.25  0.   -0.01]
 [-0.03  0.14  0.93 -0.01  0.01]
 [ 0.   -0.02 -0.21  0.03 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  2.86e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  6.88e-05  6.76e-04]
 [ 0.00e+00  0.00e+00  3.26e-03 -2.56e-03 -1.11e-03]
 [ 0.00e+00  1.35e-03 -2.97e-04 -9.60e-04  9.13e-05]
 [ 9.38e-03 -3.07e-03 -2.80e-03  2.55e-03 -4.23e-03]]
[[-5.81e-03  1.83e-02 -8.05e-03  6.85e-03 -1.94e-03]
 [ 2.22e-02 -6.36e-02  1.47e-02 -1.62e-02  5.34e-03]
 [-1.13e-01  1.41e+00 -2.50e+00  1.34e+00 -8.86e-02]
 [ 2.17e-02 -6.19e-02  1.76e-02 -2.21e-02  7.24e-03]
 [-5.21e-03  1.62e-02 -7.44e-03  8.41e-03 -2.54e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.83e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -1.30e-03  4.77e-05]
 [ 0.00e+00  0.00e+00 -5.21e-04  3.98e-05  8.29e-04]
 [ 0.00e+00 -1.09e-03 -7.52e-04  2.34e-03  3.98e-04]
 [ 9.45e-05  5.14e-04  8.56e-04 -2.65e-04 -1.13e-03]]
[[ 0.01 -0.05 -0.01  0.07 -0.01]
 [-0.05  0.42  0.05 -0.48  0.06]
 [-0.01  0.04 -0.07  0.05 -0.01]
 [ 0.06 -0.47  0.04  0.42 -0.05]
 [-0.01  0.06 -0.01 -0.05  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.81e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.18e-04  1.78e-03]
 [ 1.00e+00  0.00e+00  2.80e-03 -3.91e-03 -1.32e-03]
 [ 0.00e+00  5.25e-04 -4.77e-04 -5.58e-04 -9.18e-04]
 [ 1.46e-03 -5.62e-03  2.13e-04  5.48e-03 -6.50e-03]]
[[-9.32e-03  3.34e-02 -1.17e-01  1.34e-02 -2.27e-03]
 [ 3.76e-02 -1.28e-01  1.45e+00 -4.23e-02  6.20e-03]
 [-5.35e-02  1.77e-01 -2.66e+00  4.67e-02 -5.26e-03]
 [ 4.12e-02 -1.42e-01  1.48e+00 -5.96e-02  1.09e-02]
 [-1.02e-02  3.67e-02 -1.23e-01  1.85e-02 -3.76e-03]]
SymNet parameters
[[-7.73e-01  2.38e-02 -3.07e-03 -1.44e-02 -1.08e-02 -3.81e-03  1.90e-01  4.86e-03
  -9.02e-03 -9.07e-06 -2.06e-03 -2.65e-03]
 [ 8.87e-03 -1.91e-01 -2.83e-02 -6.22e-02 -2.75e-03 -1.62e-02 -2.63e-02  1.56e-02
   4.31e-02 -4.58e-03 -9.24e-03 -2.02e-03]]
SymNet parameters
[-0.13  0.29]
SymNet parameters
[[-1.33e-01  1.02e-01 -2.07e-03 -3.03e-02 -1.45e-02 -5.43e-03  2.38e+00  2.65e-04
  -2.40e-02 -2.98e-03 -2.50e-03 -2.27e-04  1.95e-02]
 [ 2.85e+00  6.20e-02  1.40e-01  2.00e-02 -2.44e-02 -1.21e-03 -1.13e-01  3.25e-03
   1.13e-02  2.11e-03  1.41e-03  3.00e-04 -2.07e-01]]
SymNet parameters
[-0.26 -0.61]
SymNet parameters
[[-1.30e-01 -1.67e-01 -1.50e-02  5.54e-04 -1.18e-02  2.97e-03  2.29e+00 -9.92e-03
  -5.21e-02 -2.78e-04  2.17e-03  1.20e-03  2.81e-02  1.31e-03]
 [ 2.14e+00  1.34e-02 -2.18e-01  1.08e-02 -1.66e-02 -1.62e-03 -8.39e-02  1.85e-03
   2.29e-03  1.53e-03  4.82e-04  1.60e-04 -2.01e-01 -4.04e-04]]
SymNet parameters
[-0.71 -0.73]
SymNet parameters
[[ 1.93e+00 -3.95e-01 -3.62e-01 -3.65e-01 -3.23e-01 -1.62e-01  1.59e+00  1.40e-01
  -5.51e-01  1.76e-03 -3.10e-02 -5.29e-02  2.13e-01  2.78e-01 -7.08e-01]
 [ 1.42e-02  1.70e+00  7.07e-01 -2.31e-01 -1.60e-01 -1.87e-01 -3.99e-02  4.13e-01
   1.96e+00 -5.08e-02 -1.07e-01 -7.49e-02 -4.41e-01 -2.82e-01  1.21e-01]]
SymNet parameters
[-0.03  0.11]
SymNet parameters
[[ 1.01e+00 -2.32e+00 -2.12e-01 -1.85e-01 -3.67e-01  3.86e-02 -1.16e+00 -1.60e-01
  -8.70e-01 -3.40e-02  3.36e-03  2.36e-04  7.59e-01 -1.34e-01  3.21e-01  3.56e-03]
 [-4.14e-01  5.53e-01 -2.36e+00  4.81e-01 -1.34e-01  6.15e-02 -7.75e-01 -1.47e-01
   1.34e+00  9.27e-03  3.80e-02  5.40e-02 -1.48e+00  7.09e-01 -2.99e-01 -2.00e-02]]
SymNet parameters
[ 0.   -0.14]
SymNet parameters
[[ 8.57e-01 -1.63e-01 -2.45e-01  7.65e-02 -1.67e-02  5.72e-02  8.61e-01 -8.93e-03
  -4.58e-02  3.31e-03  2.77e-03  6.09e-04 -1.80e+00 -9.48e-01  1.32e+00  5.71e-03
  -4.92e-03]]
SymNet parameters
[-0.59]
SymNet parameters
[[ 1.98e-01  1.57e-03  1.41e-02  9.38e-04  2.35e-03 -2.28e-03  2.36e+00 -7.64e-02
  -4.35e-02  1.40e-03  6.14e-04  1.85e-02]
 [-4.90e-01  3.64e-02  3.87e-02  2.02e-03  1.44e-02 -8.06e-03 -4.11e-01 -9.20e-02
   9.66e-01  2.62e-03  1.70e-02  1.71e-01]]
SymNet parameters
[ 0.   -0.32]
SymNet parameters
[[ 4.08e-02  1.55e-02  4.19e-02 -2.44e-03  1.36e-02  1.28e-02 -3.53e-02  2.32e+00
  -1.52e-01  3.83e-02 -3.68e-03  4.64e-02 -4.18e-02]
 [ 2.05e-01 -4.25e-02  6.97e-03  4.47e-05 -4.92e-04 -1.07e-03 -1.72e+00 -2.59e-02
  -8.55e-02  1.64e-03  3.43e-04 -1.27e-02  2.58e-02]]
SymNet parameters
[1.2  0.29]
SymNet parameters
[[-1.02e+00  1.03e-02  4.88e-04  2.00e-04 -1.70e-04 -3.13e-05  1.60e-02  4.55e-03
   3.10e-03  8.49e-04 -1.93e-03 -2.41e-03 -7.57e-03 -4.57e-03]
 [-1.06e-02 -7.95e-03 -2.40e-02  1.21e-03 -9.49e-03 -5.50e-03  3.47e-02 -1.35e+00
   6.31e-02 -2.53e-02  2.91e-02 -3.90e-02  2.40e-02 -5.51e-04]]
SymNet parameters
[-0.36  0.06]
SymNet parameters
[[ 0.37 -0.02  0.1  -0.01  0.04  0.03 -1.53 -0.49  0.33  0.11 -0.14  0.15 -0.07 -0.83
   0.54]
 [ 0.78 -0.05 -0.33  0.02 -0.16 -0.07 -1.66 -0.62  0.45 -0.33  0.34 -0.84  0.31  2.22
  -0.21]]
SymNet parameters
[0.49 0.04]
SymNet parameters
[[ 3.81e-02 -8.72e-03 -6.73e-02  2.82e-03 -2.83e-02 -1.25e-02  9.04e-01 -9.75e-02
   1.09e-01 -6.19e-02  6.26e-02 -1.46e-01  4.02e-02  4.07e-01 -3.76e-02 -1.72e-06]
 [-8.68e-01  2.51e-02 -1.30e-01  9.61e-03 -6.10e-02 -3.86e-02 -1.31e+00  6.64e-01
  -5.63e-01 -1.53e-01  1.87e-01 -2.41e-01  1.38e-01  1.17e+00 -7.56e-01  4.97e-06]]
SymNet parameters
[-0.17  0.07]
SymNet parameters
[[-0.15  0.01  0.01 -0.    0.01  0.   -0.    0.36 -0.07  0.06 -0.01  0.09 -0.27  0.06
  -0.73  0.12  0.46]]
SymNet parameters
[-0.05]
finally, finish this stage
iter:  2000    time: 11.16
Func: 1.97e-02  |g|: 2.85e-02
stableloss: 1.23e-02   dataloss: 1.33e-02   sparseloss: 9.24e+01 momentloss: 6.48e+00
current expression:
[u00*u01, u10*v00, u20, u02, u00*u01**2, u00*u11*v00, u01*u10*v00, u10*v00*v10, u00, u00*u01*v10, u01*v00**2, u00*v00**2, u01, v00, v00**2, 1, u00*v01, u00**2*u01, v11, v00*v01]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.    0.
 -0.    0.   -0.    0.   -0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, 1, u00**2*v00, u00*v00**2, u00, u00**2*v10, v10**2, v00**2*v10, v00**2*v20, v00**2*v01, v00**2]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.01 -0.   -0.   -0.    0.
  0.    0.   -0.    0.    0.    0.  ]
block:  2
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -0.48266763544780833
current stage is: block-2
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9363, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2554,  1.6915,  1.6778, 20.6860, 10.1227, 19.2761,  0.2565,  1.5775,
         1.7519, 17.9641,  9.9927, 22.4834], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 1098.70
Func: 7.16e-02  |g|: 1.58e+01
stableloss: 2.24e-02   dataloss: 5.86e-02   sparseloss: 9.24e+01 momentloss: 6.48e+00
iter:   200    time: 14.88
Func: 6.07e-02  |g|: 4.22e+00
stableloss: 2.26e-02   dataloss: 4.65e-02   sparseloss: 9.34e+01 momentloss: 7.09e+00
iter:   400    time: 14.58
Func: 5.96e-02  |g|: 1.15e+01
stableloss: 2.26e-02   dataloss: 4.54e-02   sparseloss: 1.02e+02 momentloss: 7.09e+00
iter:   600    time: 16.00
Func: 5.89e-02  |g|: 7.67e+00
stableloss: 2.26e-02   dataloss: 4.51e-02   sparseloss: 1.10e+02 momentloss: 6.93e+00
iter:   800    time: 16.37
Func: 5.86e-02  |g|: 1.24e+01
stableloss: 2.25e-02   dataloss: 4.48e-02   sparseloss: 1.13e+02 momentloss: 6.91e+00
iter:  1000    time: 14.88
Func: 5.83e-02  |g|: 4.84e+00
stableloss: 2.25e-02   dataloss: 4.46e-02   sparseloss: 1.19e+02 momentloss: 6.87e+00
iter:  1200    time: 15.46
Func: 5.82e-02  |g|: 5.73e+00
stableloss: 2.26e-02   dataloss: 4.44e-02   sparseloss: 1.25e+02 momentloss: 6.90e+00
iter:  1400    time: 16.40
Func: 5.82e-02  |g|: 2.04e+00
stableloss: 2.27e-02   dataloss: 4.44e-02   sparseloss: 1.31e+02 momentloss: 6.91e+00
iter:  1600    time: 16.32
Func: 5.82e-02  |g|: 1.89e+00
stableloss: 2.26e-02   dataloss: 4.43e-02   sparseloss: 1.39e+02 momentloss: 6.92e+00
iter:  1800    time: 16.16
Func: 5.81e-02  |g|: 3.63e+00
stableloss: 2.26e-02   dataloss: 4.42e-02   sparseloss: 1.54e+02 momentloss: 6.95e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.058072
         Iterations: 1968
         Function evaluations: 2023
         Gradient evaluations: 2015
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.73e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.52e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.83e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.09e-04  1.89e-05 -2.49e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.51e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.33e-03 -5.22e-03 -5.20e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.64e-04 -1.44e-02]
 [ 0.00e+00  6.87e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.59e-04 -9.22e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.07e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.11e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.99e-02  1.92e-02 -7.43e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.54e-03  3.33e-02 -1.65e-01  3.41e-02  7.81e-04]
 [ 5.98e-04 -6.98e-03  3.77e-02 -5.88e-03 -5.26e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.39e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.49e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.64e-04  2.30e-03  7.55e-04]
 [-9.51e-03 -4.33e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.35e-04 -1.75e-03 -1.34e-03  1.03e-03]
 [ 5.41e-03 -1.25e-03 -9.04e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.12e-03
   4.89e-03  6.35e-03 -3.80e-04  3.67e-03]
 [-5.59e-03 -4.56e-01 -5.13e-03 -1.37e-01 -1.76e-03  1.98e-02  5.70e-01  4.45e-03
   7.73e-02  2.10e-02 -7.95e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.48e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.95e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.48e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.19e-02 -7.64e-01 -1.49e-03
  -2.60e-01 -4.73e-02  3.74e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.39e-04
  -3.57e-02 -8.08e-03  3.85e-04 -2.51e-03 -2.48e-02  1.30e-04]
 [ 1.69e+00 -7.97e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01  1.91e-05
  -1.97e-01 -3.33e-02  2.86e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.21e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.35e-01
  -1.79e+00  3.40e-02  2.47e-03  8.08e-02 -2.92e+00  1.62e-01 -1.33e+00]
 [ 6.65e-01 -1.89e+00  3.57e-01 -3.27e+00 -6.40e-01  7.97e-01  4.47e+00  3.25e-01
   4.57e+00  5.05e-01  1.66e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.32e-02
  -1.49e+00 -1.55e-01 -4.02e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.56e-02
  -3.10e-01 -3.01e-01  3.74e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.89e-03
  -4.83e-01 -4.70e-02  3.11e-03 -6.95e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.74e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.11e-03  1.59e-02 -3.08e-04  3.02e-03 -1.40e-03 -1.89e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.84e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.77e-03  6.83e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.13e-02 -8.35e-03 -4.21e-04  1.53e-03  4.24e-03 -2.48e+00 -8.91e-02
  -1.60e-01  3.03e-03 -8.80e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.07e-02 -1.33e-03  2.20e-03 -4.89e-05 -1.10e-04  3.64e-02  1.22e-02
   2.96e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.43e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.85e-04 -3.57e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.15e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.60e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.63e-02  4.77e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.59e-04  4.49e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.09e-02  2.76e-03 -5.99e-02  1.57e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:  1968    time: 16.44
Func: 5.81e-02  |g|: 1.53e+01
stableloss: 2.26e-02   dataloss: 4.42e-02   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  3
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  2.7967069023502438
current stage is: block-3
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9713, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2559,  1.8058,  1.6438, 23.4210, 10.4146, 17.6700,  0.2455,  1.6420,
         1.6572, 19.5730, 10.4049, 20.2128], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.165405
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.37e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.81e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.84e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01  4.60e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  1.78e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 2428.99
Func: 1.65e-01  |g|: 2.42e+03
stableloss: 3.89e-02   dataloss: 1.45e-01   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  4
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -2.0386224858800293
current stage is: block-4
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8085, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2689,  1.7706,  1.7117, 23.1234, 10.2211, 18.7274,  0.2548,  1.6393,
         1.6807, 19.0458,  9.5923, 20.8067], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.455945
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.51e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.85e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.56e-03  3.34e-02 -1.66e-01  3.42e-02  7.64e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.22e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.27e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.83e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.88e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.02e-03 -6.79e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.19e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.32e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -2.00e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.42e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  1.39e-03
  -6.00e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.63e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.84e-05 -1.11e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.40e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.24e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01  1.74e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  5.33e-05]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 143.53
Func: 4.56e-01  |g|: 9.01e+02
stableloss: 4.02e-02   dataloss: 4.28e-01   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  5
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -0.7917040492036619
current stage is: block-5
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8406, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2497,  1.6735,  1.7039, 22.0348, 10.8208, 19.5925,  0.2500,  1.6702,
         1.7549, 19.1688, 10.7923, 21.7078], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.565940
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.64e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.83e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.79e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.86e-04 -2.51e-03 -2.48e-02  1.39e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.87e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.80e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.44e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  1.03e-03
  -5.96e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.63e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.42e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -4.50e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00 -1.77e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 146.29
Func: 5.66e-01  |g|: 4.05e+03
stableloss: 4.85e-02   dataloss: 5.31e-01   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  6
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  0.4587860132245441
current stage is: block-6
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9339, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2445,  1.6840,  1.4689, 21.7077,  9.2177, 16.3601,  0.2581,  1.7433,
         1.8320, 20.2086, 11.1440, 23.5860], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.881401
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.88e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.79e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.41e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.87e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.85e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.44e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  1.01e-03
  -5.96e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.63e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.84e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.43e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -4.78e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00 -1.12e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 143.94
Func: 8.81e-01  |g|: 9.20e+03
stableloss: 5.23e-02   dataloss: 8.40e-01   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  9
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  1.4145115459636162
current stage is: block-9
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9671, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2326,  1.5592,  1.4652, 20.3838,  8.2831, 16.0181,  0.2230,  1.4289,
         1.4803, 16.2348,  8.6857, 18.0768], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 1.852192
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.33e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.78e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.84e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -4.67e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00 -1.57e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 148.72
Func: 1.85e+00  |g|: 6.13e+04
stableloss: 5.33e-02   dataloss: 1.79e+00   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  12
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  0.1842073033743189
current stage is: block-12
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8644, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2291,  1.5531,  1.4658, 20.8347,  9.2336, 16.0996,  0.2362,  1.5831,
         1.6364, 18.3818,  9.6889, 19.8579], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 2.856200
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.32e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01  4.80e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  1.14e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 148.18
Func: 2.86e+00  |g|: 1.18e+05
stableloss: 7.91e-02   dataloss: 2.77e+00   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  15
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  1.0477664921876633
current stage is: block-15
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9077, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2533,  1.6822,  1.6632, 22.3718,  9.7890, 18.1035,  0.2669,  1.7815,
         1.8688, 20.9832, 10.9904, 23.5523], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 8.271294
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.09e-04  1.92e-05 -2.52e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.85e-03]
 [ 3.07e-02 -9.98e-02  1.90e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.56e-03  3.34e-02 -1.66e-01  3.42e-02  7.58e-04]
 [ 6.02e-04 -7.00e-03  3.77e-02 -5.90e-03 -5.21e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.54e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.20e-03  3.32e-01  2.13e-03
   4.89e-03  6.36e-03 -3.85e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.08e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.90e-04  2.80e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.32e-04
  -3.57e-02 -8.07e-03  3.84e-04 -2.51e-03 -2.48e-02  1.27e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.85e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.32e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -2.46e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.42e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  1.28e-03
  -6.00e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.63e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.82e-05 -1.11e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.37e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.24e-02 -2.05e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -7.35e-05]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00 -3.08e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 147.83
Func: 8.27e+00  |g|: 3.28e+04
stableloss: 1.75e-01   dataloss: 8.17e+00   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  18
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -0.40283254515363476
current stage is: block-18
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8386, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2503,  1.6736,  1.5893, 21.6329,  9.4903, 17.3641,  0.2469,  1.5514,
         1.5977, 18.1523,  9.0130, 20.1389], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Optimization terminated successfully.
         Current function value: inf
         Iterations: 0
         Function evaluations: 1
         Gradient evaluations: 1
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.31e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.30e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 142.56
Func: inf  |g|: 0.00e+00
stableloss: nan   dataloss: nan   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  21
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  0.19734503434675418
current stage is: block-21
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7848, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2383,  1.6169,  1.5457, 20.6285,  9.4392, 17.1537,  0.2519,  1.7833,
         1.7072, 20.9944, 11.2781, 21.4427], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 20.495518
         Iterations: 0
         Function evaluations: 15
         Gradient evaluations: 3
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.47e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.85e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.56e-03  3.34e-02 -1.65e-01  3.42e-02  7.65e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.83e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.30e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.18e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.31e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.10e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  1.10e-03
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -4.47e-04]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00 -1.61e-04]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 149.95
Func: 2.05e+01  |g|: 1.18e+06
stableloss: 3.66e+00   dataloss: 2.03e+01   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  24
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -0.8035109265673044
current stage is: block-24
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8205, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2377,  1.6858,  1.5717, 21.9572, 10.3060, 17.2166,  0.2573,  1.5957,
         1.7682, 17.8423,  9.9092, 21.4884], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Optimization terminated successfully.
         Current function value: inf
         Iterations: 0
         Function evaluations: 1
         Gradient evaluations: 1
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.31e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.30e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 142.52
Func: inf  |g|: 0.00e+00
stableloss: nan   dataloss: nan   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  27
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -1.1611793650434648
current stage is: block-27
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9247, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2505,  1.7194,  1.5927, 23.1504,  9.9967, 17.3037,  0.2706,  1.8668,
         1.9062, 21.9038, 12.2213, 23.8382], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Optimization terminated successfully.
         Current function value: inf
         Iterations: 0
         Function evaluations: 1
         Gradient evaluations: 1
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.31e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.30e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 146.20
Func: inf  |g|: 0.00e+00
stableloss: nan   dataloss: nan   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  30
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -0.17387845516376357
current stage is: block-30
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9372, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2387,  1.5847,  1.4542, 21.2460,  9.3310, 15.8579,  0.2462,  1.5715,
         1.5821, 18.0211,  9.2322, 18.8060], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Optimization terminated successfully.
         Current function value: inf
         Iterations: 0
         Function evaluations: 1
         Gradient evaluations: 1
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.31e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.30e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 144.58
Func: inf  |g|: 0.00e+00
stableloss: nan   dataloss: nan   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  35
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  1.1646039155315724
current stage is: block-35
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8774, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2519,  1.6651,  1.5501, 20.4396,  9.0992, 16.4409,  0.2414,  1.5133,
         1.6781, 17.5538,  9.9533, 21.0485], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Optimization terminated successfully.
         Current function value: inf
         Iterations: 0
         Function evaluations: 1
         Gradient evaluations: 1
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.31e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.30e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 147.41
Func: inf  |g|: 0.00e+00
stableloss: nan   dataloss: nan   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
block:  40
name:  burgers-2-upwind-sparse0-noise0.001
device:  cuda:1
generate a random number to check random seed:  -0.28060739114317423
current stage is: block-40
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9054, device='cuda:1', dtype=torch.float64)
u_obs variance
tensor([ 0.2323,  1.5322,  1.4558, 19.4417,  8.8140, 16.3211,  0.2524,  1.7063,
         1.6871, 19.6569, 10.1356, 20.1468], device='cuda:1',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
Optimization terminated successfully.
         Current function value: inf
         Iterations: 0
         Function evaluations: 1
         Gradient evaluations: 1
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.71e-04  7.41e-03 -1.31e-01]
 [ 0.00e+00 -1.44e-04  2.35e-03 -1.07e-03 -2.49e-03]
 [ 1.84e-03 -4.24e-03  8.09e-03  5.66e-03 -3.89e-02]
 [ 3.07e-02  3.63e-03 -7.33e-04 -1.58e-03 -2.68e-02]
 [-4.44e-02 -3.02e-02  1.08e-04  1.93e-05 -2.50e-04]]
[[ 0.01 -0.04  0.04 -0.09  0.02]
 [-0.07  0.24 -0.27  0.39 -0.08]
 [-0.04  0.22  0.56  0.01 -0.02]
 [-0.02  0.05 -0.04  0.19 -0.03]
 [-0.01  0.06 -0.09  0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.58e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00 -1.52e-04  4.96e-03  3.53e-04]
 [ 0.00e+00  2.33e-02 -3.98e-03  6.12e-03 -3.03e-02]
 [ 4.05e-03 -2.34e-03 -5.22e-03 -5.22e-04 -9.61e-03]
 [ 1.07e-03  5.87e-04  1.20e-03 -1.31e-02 -8.26e-03]]
[[ 0.01 -0.   -0.02  0.02 -0.01]
 [-0.04  0.09 -0.07  0.01  0.01]
 [ 0.11 -0.57 -0.38  1.07 -0.23]
 [-0.03  0.03  0.02 -0.06  0.03]
 [-0.    0.03 -0.06  0.05 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  9.86e-03 -1.07e-03]
 [ 1.00e+00  0.00e+00  1.95e-02 -5.65e-04 -1.44e-02]
 [ 0.00e+00  6.88e-04 -9.62e-03  5.70e-03  4.19e-03]
 [-9.23e-02 -3.74e-03  8.98e-03  1.50e-03 -1.73e-02]
 [-6.12e-02 -1.56e-03 -1.12e-02  5.57e-03 -1.46e-03]]
[[ 0.   -0.04  0.14 -0.04  0.01]
 [ 0.01  0.01 -0.56  0.04 -0.01]
 [-0.03  0.06 -0.38 -0.01 -0.  ]
 [ 0.03 -0.05  1.03 -0.    0.01]
 [-0.01  0.04 -0.23  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.58e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.54e-04 -9.21e-03]
 [ 0.00e+00  0.00e+00  8.44e-03  3.33e-03 -5.08e-03]
 [ 0.00e+00  2.85e-03 -3.38e-03 -4.11e-03  7.83e-03]
 [ 2.49e-02 -2.58e-03 -3.89e-03  1.04e-03 -5.59e-03]]
[[-1.14e-02  4.10e-02 -2.69e-02  3.00e-02 -7.86e-03]
 [ 3.07e-02 -9.98e-02  1.91e-02 -7.42e-02  2.45e-02]
 [-1.02e-01  1.37e+00 -2.37e+00  1.36e+00 -1.02e-01]
 [-2.55e-03  3.34e-02 -1.65e-01  3.42e-02  7.66e-04]
 [ 6.00e-04 -6.99e-03  3.77e-02 -5.90e-03 -5.23e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.38e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  3.48e-04  3.96e-03]
 [ 0.00e+00  0.00e+00 -2.34e-03 -1.56e-03  5.32e-03]
 [ 0.00e+00 -1.68e-03 -4.65e-04  2.30e-03  7.53e-04]
 [-9.51e-03 -4.32e-02  1.87e-03  4.25e-03 -3.71e-03]]
[[-0.   -0.   -0.04  0.04 -0.01]
 [-0.01  0.22  0.19 -0.41  0.05]
 [-0.08  0.39 -0.35 -0.02 -0.01]
 [ 0.11 -0.69  0.21  0.47 -0.06]
 [-0.02  0.11 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.66e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.38e-03 -1.20e-03]
 [ 1.00e+00  0.00e+00  3.96e-03  5.00e-03  2.50e-03]
 [ 0.00e+00  7.34e-04 -1.75e-03 -1.34e-03  1.04e-03]
 [ 5.41e-03 -1.25e-03 -9.03e-04 -3.68e-03 -9.39e-03]]
[[-0.01  0.04 -0.14  0.04 -0.01]
 [ 0.03 -0.14  1.55 -0.18  0.05]
 [ 0.12 -0.46 -1.81 -0.41  0.09]
 [ 0.03 -0.12  1.52 -0.16  0.05]
 [-0.01  0.03 -0.13  0.04 -0.01]]
SymNet parameters
[[-6.80e-01  3.98e-02  8.40e-02 -5.11e-02 -9.28e-03  6.21e-03  3.32e-01  2.13e-03
   4.89e-03  6.35e-03 -3.84e-04  3.67e-03]
 [-5.61e-03 -4.56e-01 -5.11e-03 -1.37e-01 -1.75e-03  1.98e-02  5.70e-01  4.47e-03
   7.73e-02  2.10e-02 -8.07e-04  9.29e-03]]
SymNet parameters
[0.37 3.23]
SymNet parameters
[[-2.77e-01  2.76e-01  5.35e-02 -4.79e-02 -1.60e-03  7.47e-03  2.37e+00  3.61e-03
   3.03e-02  3.59e-03  2.89e-04  2.81e-03  1.15e-02]
 [ 2.09e+00 -4.47e-02 -1.36e-01  1.78e-01 -1.36e-01 -5.18e-02 -7.64e-01 -1.54e-03
  -2.60e-01 -4.73e-02  3.76e-03 -1.46e-02 -4.92e-01]]
SymNet parameters
[ 0.3  -4.85]
SymNet parameters
[[-2.03e-01  2.60e-02 -1.15e-02  2.95e-02 -6.03e-03 -6.80e-03  1.29e+00  1.31e-04
  -3.57e-02 -8.08e-03  3.87e-04 -2.51e-03 -2.48e-02  1.31e-04]
 [ 1.69e+00 -7.96e-02 -5.83e-01  1.07e-01 -1.17e-01 -3.77e-02 -4.83e-01 -1.89e-05
  -1.97e-01 -3.33e-02  2.88e-03 -9.22e-03 -4.61e-01 -3.30e-03]]
SymNet parameters
[-1.17 -2.15]
SymNet parameters
[[ 1.59e+00 -5.20e+00 -6.07e-01 -1.37e+00 -1.25e+00 -2.26e-01 -9.12e-01  1.36e-01
  -1.79e+00  3.39e-02  2.49e-03  8.08e-02 -2.91e+00  1.62e-01 -1.33e+00]
 [ 6.64e-01 -1.89e+00  3.56e-01 -3.27e+00 -6.40e-01  7.96e-01  4.46e+00  3.26e-01
   4.57e+00  5.06e-01  1.63e-02  2.68e-01  2.66e+00 -8.46e-01  1.04e+00]]
SymNet parameters
[0.18 0.03]
SymNet parameters
[[-1.07e+00 -4.96e+00 -1.18e+00  3.52e-01 -5.34e-01 -1.52e-01 -3.35e+00 -5.35e-02
  -1.49e+00 -1.55e-01 -3.95e-03 -3.58e-02 -2.09e+00 -1.36e-01  4.05e-01 -3.76e-04]
 [ 3.34e-01 -1.21e+00 -2.29e+00  1.80e+00 -4.95e-01 -2.93e-01 -6.73e+00  3.53e-02
  -3.10e-01 -3.01e-01  3.75e-02 -1.22e-01 -1.24e+00  3.64e-01 -4.72e-01 -1.43e-03]]
SymNet parameters
[-0.37 -0.56]
SymNet parameters
[[-5.61e-01 -1.11e+00 -6.87e-01  1.24e-01 -2.78e-01 -1.12e-02 -3.47e+00  3.85e-03
  -4.83e-01 -4.70e-02  3.13e-03 -6.94e-03 -2.89e+00 -7.86e-01  1.40e+00  9.85e-04
  -5.95e-03]]
SymNet parameters
[-2.32]
SymNet parameters
[[-6.50e-01 -8.23e-03 -3.39e-03  1.34e-03 -1.72e-04 -1.38e-03  2.11e+00  1.37e-01
  -6.50e-02 -1.34e-03 -3.14e-03  2.38e-02]
 [-6.03e-03  1.59e-02 -2.87e-04  3.02e-03 -1.39e-03 -1.88e-02 -3.05e-01  5.87e-01
   9.46e-01  2.59e-02 -3.85e-03  1.68e-01]]
SymNet parameters
[-0.22 -0.21]
SymNet parameters
[[-6.22e-01 -7.88e-02  7.40e-02  1.76e-03  6.85e-03  1.92e-02 -3.69e-01  3.10e+00
   2.36e-01 -9.47e-02 -9.49e-02 -4.97e-02  5.98e-02]
 [-5.95e-02 -3.12e-02 -8.35e-03 -4.20e-04  1.53e-03  4.24e-03 -2.48e+00 -8.90e-02
  -1.60e-01  3.03e-03 -8.64e-05 -2.37e-02  3.32e-02]]
SymNet parameters
[1.8  0.89]
SymNet parameters
[[-1.15e+00 -2.06e-02 -1.33e-03  2.20e-03 -4.83e-05 -1.10e-04  3.64e-02  1.22e-02
   2.48e-04  1.44e-03 -1.13e-03  5.31e-03  4.62e-03  9.44e-04]
 [ 3.33e-01  4.31e-02 -3.66e-02 -4.81e-04 -3.58e-03 -1.04e-02  1.89e-01 -1.65e+00
  -1.09e-01  5.14e-02  6.47e-02  3.18e-02 -3.23e-02 -2.07e-04]]
SymNet parameters
[-1.39  0.35]
SymNet parameters
[[-0.74 -0.26  0.2  -0.01  0.02  0.1  -2.12  0.07 -0.21 -0.32 -0.28 -0.55  0.13 -1.13
   0.86]
 [ 2.76  0.71 -0.61  0.01 -0.06 -0.25 -2.49 -0.23  1.14  0.91  0.83  1.33 -0.26  3.42
  -1.09]]
SymNet parameters
[0.75 0.3 ]
SymNet parameters
[[ 6.61e-01  1.35e-01 -1.01e-01  2.18e-03 -1.22e-02 -4.70e-02  1.18e+00  1.59e-02
   2.89e-01  1.60e-01  1.48e-01  2.51e-01 -6.81e-02  6.05e-01 -1.93e-01 -2.39e-07]
 [ 1.32e-01  3.47e-01 -3.17e-01  9.78e-03 -3.33e-02 -1.37e-01 -1.31e+00 -2.61e-01
   6.59e-02  4.76e-01  4.03e-01  7.68e-01 -1.29e-01  1.66e+00 -1.26e+00  6.41e-07]]
SymNet parameters
[-0.18 -0.37]
SymNet parameters
[[-2.91e-01 -5.26e-02  3.74e-02  2.56e-04  4.50e-03  1.33e-02 -1.25e+00  1.37e+00
  -9.08e-02  2.78e-03 -5.99e-02  1.58e-03 -2.49e-01 -2.83e-01 -4.20e-01  1.40e-01
   5.39e-01]]
SymNet parameters
[0.18]
finally, finish this stage
iter:     0    time: 146.66
Func: inf  |g|: 0.00e+00
stableloss: nan   dataloss: nan   sparseloss: 1.77e+02 momentloss: 6.95e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01, u00*v00, u00*u01**2, 1, v00, u01*u10*v00, u00*u11*v00, v00**2, u10*v00*v10, u00, u00**2*u01*v00, u00*u01*v00, u01*v00, u00**2, u00**2*u01, u11]
[-0.97 -0.97  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.01
  0.01  0.01 -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u10*v00*v01, v00, v01, u01, u00, u10*v01, u00*v10, u00*v00*v10, u10*v00, u00**2*v10, u00**2*u01, u02*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.    0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.    0.  ]
u_obs.abs().max()
tensor(3.8444, device='cuda:1', dtype=torch.float64)
model(u_obs[0],T=50*dt).abs().max()
tensor(nan, device='cuda:1', dtype=torch.float64)
model(u_obs[0],T=100*dt).abs().max()
tensor(nan, device='cuda:1', dtype=torch.float64)
{'--name': 'burgers-2-central-sparse0.005-noise0.001', '--dtype': 'double', '--device': 'cuda:2', '--constraint': '2', '--dt': 0.01, '--cell_num': 1, '--eps': 6.283185307179586, '--blocks': [0, 1, 2, 3, 4, 5, 6, 9, 12, 15, 18, 21, 24, 27, 30, 35, 40], '--kernel_size': 5, '--max_order': 2, '--dx': 0.19634954084936207, '--hidden_layers': 5, '--scheme': 'upwind', '--dataname': 'burgers', '--viscosity': 0.05, '--zoom': 4, '--max_dt': 0.000625, '--batch_size': 28, '--data_timescheme': 'rk2', '--channel_names': 'u,v', '--freq': 4, '--data_start_time': 1.0, '--start_noise': 0.001, '--end_noise': 0.001, '--stablize': 0.0, '--sparsity': 0.005, '--momentsparsity': 0.001, '--npseed': -1, '--torchseed': -1, '--maxiter': 2000, '--recordfile': 'None', '--recordcycle': 200, '--savecycle': -1, '--start_from': -1}
block:  0
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -0.6490644258691975
current stage is: warmup
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8377, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2520,  2.0618,  1.9348, 19.0724,  9.7597, 17.0576,  0.2592,  2.0135,
         2.2052, 17.5347, 10.0222, 20.4489], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 13.06
Func: 6.49e+00  |g|: 1.90e+00
stableloss: 2.80e-04   dataloss: 6.49e+00   sparseloss: 2.49e+01 momentloss: 7.27e+00
iter:   200    time: 11.18
Func: 4.96e-02  |g|: 4.38e-02
stableloss: 1.46e-02   dataloss: 4.96e-02   sparseloss: 5.52e+01 momentloss: 7.27e+00
iter:   400    time: 10.74
Func: 4.58e-02  |g|: 1.24e-02
stableloss: 1.42e-02   dataloss: 4.58e-02   sparseloss: 7.14e+01 momentloss: 7.27e+00
iter:   600    time: 15.28
Func: 4.36e-02  |g|: 2.57e-02
stableloss: 1.45e-02   dataloss: 4.36e-02   sparseloss: 8.56e+01 momentloss: 7.27e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.043131
         Iterations: 761
         Function evaluations: 839
         Gradient evaluations: 831
convolution moment and kernels
[[1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 0.    1.    0.   -0.33 -0.25]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 2.78e-17  3.33e-16 -1.50e+00  2.00e+00 -5.00e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[ 0.    0.    0.    0.    0.  ]
 [ 1.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [-0.33  0.    0.    0.    0.  ]
 [-0.25  0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  2.78e-17  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  3.33e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.50e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -5.00e-01  0.00e+00  0.00e+00]]
[[0.   0.   1.   0.   0.08]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [-2.22e-16  1.00e+00 -2.00e+00  1.00e+00 -1.53e-16]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 6.94e-03 -5.56e-02  9.25e-18  5.56e-02 -6.94e-03]
 [-5.56e-02  4.44e-01 -7.40e-17 -4.44e-01  5.56e-02]
 [ 9.25e-18 -7.40e-17  1.23e-32  7.40e-17 -9.25e-18]
 [ 5.56e-02 -4.44e-01  7.40e-17  4.44e-01 -5.56e-02]
 [-6.94e-03  5.56e-02 -9.25e-18 -5.56e-02  6.94e-03]]
[[0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [1.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.08 0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00 -2.22e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.53e-16  0.00e+00  0.00e+00]]
SymNet parameters
[[ 6.34e-02  3.04e-04 -3.34e-02  6.36e-03  1.52e-03  4.56e-03  1.37e-01 -6.87e-03
   5.67e-04  7.92e-04  2.45e-03  1.42e-03]
 [ 2.45e+00 -2.39e-01  3.92e-01  4.19e-01 -3.07e-01  7.67e-02 -1.42e+00  2.67e-01
   1.41e-01 -2.28e-02 -4.65e-03 -4.67e-02]]
SymNet parameters
[0.17 0.3 ]
SymNet parameters
[[ 1.45e+00 -4.08e-02  3.94e-01  6.48e-02  3.54e-02  1.45e-02  3.30e-01  2.87e-02
   5.71e-03  4.66e-03  1.32e-03 -2.67e-05  6.04e-02]
 [ 1.64e-01 -6.99e-02 -2.27e-02  6.92e-02  2.92e-02  7.10e-03 -1.26e+00  3.15e-02
  -1.81e-02  2.99e-03 -3.86e-03  3.02e-03 -1.47e-02]]
SymNet parameters
[-0.44  0.09]
SymNet parameters
[[-1.83e-01 -3.44e-01 -7.85e-02 -7.43e-02 -4.02e-02 -1.34e-03  1.58e+00 -3.36e-02
   3.52e-02 -3.05e-03  8.35e-03 -4.30e-03 -3.70e-02 -1.34e-02]
 [-1.09e+00 -3.56e-02  4.86e-02 -3.50e-02 -1.82e-02 -8.57e-03 -2.19e-01 -1.84e-02
  -1.18e-02 -2.32e-03 -1.14e-03  9.28e-04 -5.15e-02 -5.48e-03]]
SymNet parameters
[0.59 0.6 ]
SymNet parameters
[[ 0.56  1.37 -0.01 -1.14 -0.28 -0.05  0.02 -0.46  0.54 -0.03  0.12 -0.01  0.68 -0.1
  -0.09]
 [ 0.19  0.83 -1.18 -0.05 -0.08 -0.03  1.12 -0.03 -0.05 -0.02 -0.03 -0.   -0.14  0.11
  -0.16]]
SymNet parameters
[ 0.62 -0.7 ]
SymNet parameters
[[ 2.03 -1.14  0.24 -0.1  -0.07  0.05 -0.29 -0.15 -0.23  0.01  0.01  0.06 -0.96 -0.08
  -0.05 -0.02]
 [-1.18  1.8  -0.7   0.1   0.1   0.22  0.11 -0.08  0.14  0.04  0.13  0.07 -0.06 -0.55
   0.35 -0.03]]
SymNet parameters
[ 0.18 -0.03]
SymNet parameters
[[-1.07e+00 -4.07e-01 -9.48e-02  1.48e-02 -4.79e-02  3.40e-02  4.10e-01 -1.66e-02
   2.00e-03 -3.48e-03 -1.09e-03 -2.81e-03 -3.20e-01  1.38e+00 -1.53e+00 -2.85e-02
  -2.49e-02]]
SymNet parameters
[0.58]
SymNet parameters
[[-3.62e-01 -1.51e-02  1.81e-03 -3.57e-03 -6.42e-03 -2.30e-03 -1.16e+00 -5.86e-02
  -1.04e-01 -9.04e-03  7.46e-03 -4.48e-02]
 [-7.45e-03  2.71e-02 -1.01e-02  1.66e-02  2.77e-02  1.08e-02  2.02e+00 -1.12e-01
  -9.27e-01  4.49e-02 -3.20e-02  2.11e-01]]
SymNet parameters
[-0.4   0.86]
SymNet parameters
[[ 3.67e-01  3.36e-04  5.79e-03  4.64e-04  3.21e-03  1.37e-03  1.61e+00 -1.44e+00
   2.39e-01  1.38e-02 -3.04e-02  1.52e-02  1.30e-02]
 [-9.26e-01 -9.69e-04 -6.48e-03 -1.60e-03 -3.45e-03 -1.64e-03 -9.45e-02 -7.99e-03
  -1.92e-02 -3.18e-03  6.00e-03 -2.57e-02 -6.73e-03]]
SymNet parameters
[-0.44  1.1 ]
SymNet parameters
[[ 2.52  0.07  0.27  0.02  0.01  0.02  0.11 -0.05  0.05 -0.03 -0.01  0.05  0.07 -0.01]
 [ 0.55  0.08 -0.06  0.06  0.12  0.06  0.21  3.12 -0.02 -0.01  0.61  0.67 -0.06 -0.06]]
SymNet parameters
[-0.23  0.34]
SymNet parameters
[[ 1.35e+00  4.50e-02 -4.05e-03  1.63e-02  2.92e-02  1.13e-02  1.82e+00  1.89e-01
   5.03e-01  4.25e-02 -3.56e-02  2.23e-01  1.26e-02  5.27e-02 -7.54e-03]
 [-6.60e-01 -1.10e-02 -1.17e-02 -9.54e-03 -1.51e-02 -6.50e-03 -3.11e+00  4.11e-01
   3.83e-01 -2.86e-02  2.33e-02 -9.71e-02  2.57e-02  3.74e-02 -2.84e-03]]
SymNet parameters
[0.03 0.32]
SymNet parameters
[[ 1.03  0.51  0.56  0.39  0.28 -0.08 -0.38 -0.72  2.23  1.34 -0.17 -1.71  0.16  1.07
   0.17 -0.16]
 [ 0.98 -2.68 -0.07  0.23 -0.04 -0.08 -0.78  0.88 -0.81  0.08 -0.08 -0.51  0.02 -0.52
   0.08  0.5 ]]
SymNet parameters
[-0.11 -0.03]
SymNet parameters
[[ 3.04e-01 -2.04e-02  7.73e-03 -8.03e-03 -1.12e-02 -3.00e-03 -7.50e-04 -1.30e+00
   3.81e-01  2.29e-02 -1.11e-02 -4.23e-02 -7.44e-01 -8.15e-01  1.04e-02  3.24e-01
  -6.52e-04]]
SymNet parameters
[-0.65]
finally, finish this stage
iter:   761    time: 15.60
Func: 4.31e-02  |g|: 1.59e-02
stableloss: 1.46e-02   dataloss: 4.31e-02   sparseloss: 1.00e+02 momentloss: 7.27e+00
current expression:
[u00*u01, u10*v00, u00, u02, u20, u00**3, u00**2, u00*u01**2, u01*u10*v00, u00**2*u02, u00*u11*v00, u00*v00, 1, u00*u10, u00*u02, u00*v01, u10, v00, u01*u02, u10*v00*v10]
[-0.88 -0.88  0.06  0.04  0.04 -0.02  0.01  0.01  0.01 -0.01  0.01  0.01 -0.01 -0.01
  0.01  0.01  0.01 -0.    0.    0.  ]
[u00*v01, v00*v10, v00, v20, v02, v00**3, u00, v00**2*v20, u00*v00, u00*v00*v11, v00**2, v00*v10**2, v01, u00*v01*v10, 1, v00*v01, u00**2, u00*u01*v01, v10, u10*v00*v01]
[-0.89 -0.89  0.07  0.05  0.03 -0.02  0.01 -0.01 -0.01  0.01 -0.01  0.01 -0.01  0.01
  0.01  0.01 -0.01  0.   -0.    0.  ]
block:  1
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -1.3086304292204716
current stage is: block-1
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7667, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2550,  2.1394,  1.8602, 19.7978, 10.1213, 15.8581,  0.2677,  2.0431,
         2.2087, 17.5398, 10.2316, 20.5063], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 1114.04
Func: 5.49e-01  |g|: 1.46e+00
stableloss: 9.25e-03   dataloss: 4.03e-02   sparseloss: 1.00e+02 momentloss: 7.27e+00
iter:   200    time: 10.86
Func: 9.40e-02  |g|: 9.64e-02
stableloss: 9.13e-03   dataloss: 1.92e-02   sparseloss: 1.36e+01 momentloss: 6.86e+00
iter:   400    time: 11.03
Func: 9.00e-02  |g|: 1.58e-02
stableloss: 9.10e-03   dataloss: 1.93e-02   sparseloss: 1.28e+01 momentloss: 6.87e+00
iter:   600    time: 11.30
Func: 8.73e-02  |g|: 6.10e-03
stableloss: 9.27e-03   dataloss: 2.02e-02   sparseloss: 1.21e+01 momentloss: 6.83e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.087230
         Iterations: 785
         Function evaluations: 855
         Gradient evaluations: 844
convolution moment and kernels
[[ 1.00e+00  0.00e+00  1.74e-03  7.19e-04 -5.07e-02]
 [ 0.00e+00 -5.05e-04  8.67e-03  1.42e-03 -1.26e-02]
 [-1.50e-03  7.09e-04  5.09e-03 -2.86e-03  6.70e-04]
 [ 5.61e-03 -1.11e-03 -2.63e-03 -1.31e-03  1.33e-03]
 [-6.95e-02 -5.46e-03 -1.59e-02  8.42e-04  4.12e-03]]
[[ 0.   -0.02 -0.02 -0.03  0.  ]
 [-0.    0.08  0.09  0.13 -0.02]
 [-0.03  0.    0.69 -0.07 -0.01]
 [-0.03  0.19 -0.08  0.23 -0.04]
 [ 0.01 -0.04  0.01 -0.05  0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.26e-01 -1.05e-01]
 [ 0.00e+00  0.00e+00 -3.35e-03  4.07e-03 -9.42e-03]
 [ 0.00e+00  3.17e-03 -1.20e-02  2.58e-03 -2.90e-02]
 [-5.94e-04  6.74e-03  6.45e-03 -1.20e-03 -9.25e-04]
 [ 4.33e-03 -8.84e-03 -8.91e-03 -4.10e-03 -4.86e-03]]
[[-1.17e-03  8.10e-04  1.65e-02 -9.07e-03 -2.47e-03]
 [-2.03e-02  7.80e-02 -1.72e-01  1.08e-01 -1.21e-02]
 [ 9.71e-02 -5.68e-01 -2.85e-01  9.98e-01 -2.16e-01]
 [-3.46e-02  1.14e-01 -1.91e-01  1.11e-01 -1.63e-02]
 [ 3.87e-04  1.22e-03  2.27e-03  4.07e-03 -3.91e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00 -6.76e-03  6.99e-03]
 [ 1.00e+00  0.00e+00  1.05e-02  1.86e-02 -7.31e-03]
 [ 0.00e+00 -3.71e-03 -2.85e-02  2.13e-03 -2.53e-03]
 [-1.46e-01  1.52e-03  1.06e-03 -3.98e-03 -1.62e-02]
 [-9.17e-02 -6.96e-03 -3.82e-02  1.69e-04 -9.41e-03]]
[[-1.11e-03 -3.21e-02  1.43e-01 -4.91e-02  3.65e-03]
 [ 2.30e-02  2.33e-02 -5.82e-01  8.43e-02  4.67e-03]
 [-2.71e-02 -2.80e-02 -4.13e-01 -4.91e-02 -3.27e-02]
 [ 2.80e-02 -1.68e-02  1.15e+00 -2.54e-02  4.30e-02]
 [-1.24e-02  1.89e-02 -2.58e-01  1.81e-02 -1.50e-02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.59e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.52e-03  6.45e-04]
 [ 0.00e+00  0.00e+00  3.54e-03 -1.82e-03 -1.51e-03]
 [ 0.00e+00 -2.25e-04  1.47e-03 -8.90e-04 -1.48e-03]
 [ 4.14e-02 -2.61e-03 -2.72e-03  2.36e-03 -8.87e-03]]
[[-0.01  0.03  0.    0.02 -0.01]
 [ 0.04 -0.12 -0.02 -0.08  0.02]
 [-0.13  1.49 -2.43  1.43 -0.11]
 [ 0.04 -0.14  0.01 -0.1   0.03]
 [-0.01  0.04 -0.01  0.03 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.57e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -1.48e-04  8.36e-05]
 [ 0.00e+00  0.00e+00  7.53e-05  5.05e-06 -9.37e-05]
 [ 0.00e+00 -7.49e-05  7.44e-05  8.33e-06 -1.51e-04]
 [ 5.61e-04 -6.31e-05 -1.09e-04 -8.70e-05 -1.92e-04]]
[[ 6.91e-03 -5.54e-02  3.32e-04  5.58e-02 -7.08e-03]
 [-5.54e-02  4.44e-01 -1.15e-03 -4.46e-01  5.62e-02]
 [-4.53e-04  1.63e-03  9.08e-04  2.20e-03 -9.25e-04]
 [ 5.63e-02 -4.47e-01  1.70e-03  4.42e-01 -5.46e-02]
 [-7.18e-03  5.65e-02 -8.44e-04 -5.46e-02  6.66e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.46e-02]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.40e-03  1.19e-03]
 [ 1.00e+00  0.00e+00  3.46e-03 -1.47e-03 -1.37e-03]
 [ 0.00e+00 -7.85e-05  1.61e-03 -1.11e-03 -1.64e-03]
 [ 8.96e-03 -2.25e-03 -2.18e-03  1.56e-03 -1.21e-02]]
[[-0.01  0.04 -0.13  0.04 -0.01]
 [ 0.05 -0.17  1.52 -0.14  0.04]
 [-0.01  0.01 -2.42 -0.03  0.01]
 [ 0.05 -0.19  1.56 -0.17  0.04]
 [-0.01  0.05 -0.15  0.05 -0.01]]
SymNet parameters
[[-2.71e-11  2.39e-11 -5.84e-12  4.10e-11 -1.26e-12  1.56e-10 -5.57e-12  7.09e-11
   3.52e-11  5.12e-11  2.24e-11  5.71e-11]
 [ 6.02e-12  2.54e-11 -1.47e-12 -4.85e-11 -2.28e-11  1.85e-12  8.00e-12 -1.77e-11
  -2.54e-12  1.57e-13  1.98e-11 -3.66e-11]]
SymNet parameters
[-1.11e-11 -1.57e-11]
SymNet parameters
[[ 6.21e-05 -3.13e-04  9.88e-01 -6.43e-04  1.52e-04 -9.44e-05 -3.91e-04  1.46e-04
  -4.02e-04  6.14e-05  5.82e-04 -1.41e-04  5.73e-11]
 [ 2.10e-04  1.36e-04  4.05e-04  1.47e-04 -5.06e-04 -1.47e-04 -9.88e-01 -1.46e-04
  -2.04e-04 -1.47e-05  8.03e-05  6.56e-04 -2.06e-12]]
SymNet parameters
[4.55e-05 8.92e-05]
SymNet parameters
[[-5.01e-04 -9.91e-01  2.24e-04 -4.44e-04  1.42e-04 -5.93e-04 -5.44e-05  1.54e-05
   5.23e-04  2.43e-04 -8.71e-05 -1.32e-05 -2.22e-12  7.29e-04]
 [-9.79e-01 -7.22e-04  1.28e-04 -1.12e-03 -5.32e-05  1.48e-03  3.22e-04 -7.62e-04
   2.52e-04  3.45e-04  2.83e-04 -4.46e-04  5.12e-11 -1.01e-02]]
SymNet parameters
[8.93e-04 8.90e-07]
SymNet parameters
[[ 2.02e-11 -3.60e-12 -4.61e-12  8.12e-12 -3.27e-11  2.46e-11  4.40e-12 -3.81e-11
  -1.29e-11  1.84e-11 -4.71e-11  1.39e-11  3.75e-11  1.29e-11  3.43e-11]
 [-2.62e-11  2.65e-12 -3.77e-11 -5.31e-11 -9.39e-12  3.34e-11  3.28e-12 -3.34e-11
  -1.34e-11  4.32e-11 -3.06e-11 -1.14e-11 -3.31e-11 -6.04e-11  6.13e-12]]
SymNet parameters
[2.40e-11 1.26e-11]
SymNet parameters
[[ 3.59e-12  1.36e-11  2.64e-11  1.44e-11  4.37e-12 -1.69e-12 -7.49e-11 -5.08e-12
   8.31e-11  1.26e-12 -7.88e-11 -1.31e-11 -9.03e-12 -2.42e-11 -1.64e-11  2.16e-12]
 [ 1.20e-11  5.97e-13  2.00e-11 -3.16e-11  2.07e-11 -4.54e-12  6.60e-12 -9.09e-12
   5.98e-11 -1.79e-11 -6.70e-11  7.88e-12  2.68e-11  1.93e-11  4.62e-11 -1.59e-11]]
SymNet parameters
[ 4.98e-11 -5.21e-11]
SymNet parameters
[[ 9.08e-04  3.09e-07  9.40e-05  4.84e-02  1.01e-03  5.10e-02 -4.37e-05  6.39e-04
   3.92e-04 -5.26e-04  2.73e-04  5.53e-04 -2.80e-11  9.79e-01 -9.93e-01  1.65e-10
   9.00e-11]]
SymNet parameters
[-5.57e-05]
SymNet parameters
[[ 6.18e-04 -2.11e-04 -7.70e-04  1.20e-04  1.98e-04 -2.36e-04 -9.86e-01  5.40e-05
   4.95e-04  8.90e-05 -1.24e-05 -8.22e-04]
 [ 2.50e-04 -1.61e-04 -3.00e-04  1.86e-04 -4.05e-04 -4.62e-04 -4.34e-04  4.67e-06
  -9.85e-01  1.00e-03  6.60e-04  5.87e-05]]
SymNet parameters
[5.91e-05 8.05e-04]
SymNet parameters
[[ 5.36e-04  4.38e-04  8.90e-06 -2.30e-04 -4.77e-04 -1.36e-04  2.53e-04 -9.84e-01
   5.93e-04  1.02e-03  1.79e-03  2.74e-05 -6.19e-04]
 [-9.86e-01 -1.12e-04  3.95e-04  2.58e-04  2.55e-04  3.58e-04  5.69e-06 -2.55e-04
   6.77e-05 -1.25e-04 -8.71e-04  4.68e-07  1.25e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 5.44e-11  1.61e-11  1.27e-11 -4.05e-12  6.23e-11  1.86e-11 -4.52e-11 -2.33e-11
   1.56e-11 -4.81e-11 -3.38e-11 -9.95e-13  3.87e-11  1.42e-11]
 [ 2.12e-11 -1.35e-11  3.05e-11 -9.58e-13  4.65e-12  3.22e-11 -5.97e-11  1.64e-11
  -3.73e-11 -2.31e-11  6.86e-12  5.89e-12 -1.14e-11  4.09e-11]]
SymNet parameters
[4.71e-11 1.64e-11]
SymNet parameters
[[-3.23e-12  7.49e-12 -1.01e-11 -4.97e-11  1.49e-10 -9.98e-11  2.75e-11 -3.87e-12
   8.20e-12 -7.03e-11 -1.09e-10 -1.39e-10  7.01e-11 -1.19e-10 -5.81e-11]
 [ 3.93e-11 -9.89e-12  3.32e-11 -3.28e-12 -7.51e-11 -6.21e-11 -4.73e-12 -1.80e-11
   6.44e-11  2.00e-11  2.49e-11  4.08e-11  4.87e-11  1.94e-11  1.17e-11]]
SymNet parameters
[-3.82e-12 -8.18e-13]
SymNet parameters
[[-5.92e-12 -2.32e-11 -1.40e-11 -2.67e-11  5.71e-12 -3.59e-11  1.38e-11 -2.44e-12
   5.46e-12 -2.40e-12  2.90e-12  2.14e-11 -8.49e-12 -1.31e-11  1.97e-11 -1.68e-11]
 [-6.44e-12  5.78e-12 -5.35e-11  2.64e-12 -2.47e-11 -1.26e-11  1.97e-11  9.69e-12
   1.48e-11 -5.13e-12  1.88e-11 -3.13e-12  3.12e-11  5.44e-11  6.64e-11 -2.51e-11]]
SymNet parameters
[-8.57e-12 -3.00e-11]
SymNet parameters
[[ 3.39e-04 -5.34e-04 -1.51e-04 -1.95e-05  2.58e-04  2.25e-06  8.28e-04 -2.44e-04
   6.19e-05  4.91e-02  1.63e-03  4.87e-02 -9.86e-01 -9.89e-01 -1.29e-10 -4.10e-11
   2.93e-10]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   785    time: 11.61
Func: 8.72e-02  |g|: 1.39e-08
stableloss: 9.26e-03   dataloss: 2.02e-02   sparseloss: 1.20e+01 momentloss: 6.83e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u01*u20, u01*u02, u11, u01*v01, u01**2, u00*u10*v00, v01, u10*v20, u02*v00, u01*v00, u00*u20, v00*v11, v20, v02]
[-9.63e-01 -9.55e-01  5.10e-02  4.84e-02  9.68e-03  1.78e-03  1.45e-03 -1.11e-03
  1.01e-03 -7.50e-04 -7.11e-04 -6.86e-04  6.40e-04  6.34e-04  6.22e-04  6.19e-04
 -5.75e-04 -5.63e-04  5.53e-04 -5.27e-04]
[u00*v01, v00*v10, v02, v20, u00*v11, v11, v00, v00*v01*v10, u00*v10, u00*v02, v00*v02, v01*v11, v10*v20, u10*v10, u00, v00*v11, u00*v00*v10, u01, u00**2, u00*v00]
[-9.60e-01 -9.57e-01  4.91e-02  4.87e-02  1.74e-03  1.63e-03  1.61e-03  1.18e-03
  1.18e-03  9.90e-04  9.72e-04 -8.48e-04 -7.99e-04 -7.48e-04  6.63e-04  6.41e-04
 -5.87e-04 -5.34e-04  5.23e-04  4.90e-04]
block:  2
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -1.7472903247749594
current stage is: block-2
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8901, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2362,  1.6681,  1.6298, 20.9881,  9.6167, 17.8687,  0.2494,  1.6930,
         1.8351, 18.7424, 10.6000, 21.7831], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 9.48
Func: 2.26e-01  |g|: 2.08e+00
stableloss: 2.73e-02   dataloss: 9.20e-02   sparseloss: 1.21e+01 momentloss: 6.83e+00
iter:   200    time: 16.20
Func: 2.15e-01  |g|: 2.59e-03
stableloss: 2.68e-02   dataloss: 7.92e-02   sparseloss: 1.22e+01 momentloss: 7.35e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.215401
         Iterations: 219
         Function evaluations: 295
         Gradient evaluations: 286
convolution moment and kernels
[[ 1.00e+00  0.00e+00  2.15e-03  6.43e-02 -2.23e-02]
 [ 0.00e+00 -1.04e-03 -6.46e-03 -3.48e-03 -3.72e-02]
 [ 6.18e-04  7.91e-03  3.30e-03 -3.95e-03  7.56e-03]
 [ 1.15e-01 -2.83e-03  1.22e-04  6.54e-03 -2.39e-03]
 [-6.72e-02  4.17e-02 -6.05e-03  4.51e-03  6.73e-03]]
[[ 0.01 -0.05 -0.08  0.    0.  ]
 [-0.    0.11  0.34 -0.07  0.01]
 [-0.03 -0.11  0.7  -0.    0.03]
 [-0.04  0.26 -0.14  0.12 -0.04]
 [ 0.01 -0.06  0.05 -0.02  0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.05e-01 -1.07e-01]
 [ 0.00e+00  0.00e+00 -1.47e-02  6.06e-04 -1.52e-02]
 [ 0.00e+00  6.51e-03 -3.35e-02  2.73e-03 -6.87e-02]
 [ 9.76e-03  2.03e-03 -2.95e-03 -2.78e-02 -5.32e-03]
 [ 6.84e-03 -1.05e-02  1.06e-03 -2.16e-02 -1.56e-02]]
[[-0.01  0.04 -0.06  0.04 -0.01]
 [-0.05  0.07 -0.06  0.02  0.01]
 [ 0.16 -0.62 -0.36  1.09 -0.23]
 [-0.08  0.15 -0.1  -0.02  0.03]
 [ 0.01  0.02 -0.06  0.08 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  5.20e-04 -4.16e-03]
 [ 1.00e+00  0.00e+00  1.54e-02  9.26e-03 -1.35e-02]
 [ 0.00e+00 -2.96e-03 -1.15e-02 -6.90e-04  6.73e-03]
 [-1.13e-01 -2.32e-04  2.30e-02 -5.15e-03 -4.57e-03]
 [-1.13e-01  7.93e-03 -4.75e-02  8.26e-03 -6.76e-03]]
[[-0.01 -0.04  0.13 -0.06  0.  ]
 [ 0.04  0.07 -0.55  0.11  0.01]
 [-0.06 -0.08 -0.41 -0.11 -0.02]
 [ 0.03  0.09  1.02  0.09  0.01]
 [-0.01 -0.01 -0.21 -0.01 -0.  ]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  9.31e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  4.30e-03 -6.50e-05]
 [ 0.00e+00  0.00e+00  6.69e-03  1.09e-03  4.70e-03]
 [ 0.00e+00 -4.12e-04 -1.98e-03 -1.34e-03 -4.79e-03]
 [ 9.23e-03  1.40e-04  2.63e-03  2.43e-03 -2.57e-02]]
[[-0.03  0.1  -0.14  0.1  -0.02]
 [ 0.11 -0.43  0.6  -0.41  0.1 ]
 [-0.25  1.97 -3.38  1.95 -0.23]
 [ 0.12 -0.46  0.64 -0.45  0.11]
 [-0.03  0.12 -0.16  0.11 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.47e-03]
 [ 0.00e+00  1.00e+00  0.00e+00 -7.49e-04  4.10e-05]
 [ 0.00e+00  0.00e+00 -1.20e-03 -4.13e-04  3.63e-04]
 [ 0.00e+00  1.58e-04  3.65e-04  2.65e-05  6.23e-04]
 [-6.93e-04 -9.15e-04 -1.01e-05  5.98e-04 -9.78e-05]]
[[ 6.15e-03 -5.27e-02 -3.08e-03  5.60e-02 -7.01e-03]
 [-5.25e-02  4.32e-01  1.46e-02 -4.47e-01  5.56e-02]
 [-6.98e-03  2.81e-02 -3.53e-02  1.15e-02 -1.44e-03]
 [ 5.80e-02 -4.54e-01  9.26e-03  4.47e-01 -5.71e-02]
 [-7.21e-03  5.65e-02 -2.95e-04 -5.72e-02  7.53e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.14e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  4.73e-03  2.28e-04]
 [ 1.00e+00  0.00e+00  7.29e-03  2.42e-03  4.21e-03]
 [ 0.00e+00 -6.16e-04 -2.68e-03 -1.48e-03 -4.22e-03]
 [ 1.89e-01  2.94e-03  2.20e-03 -8.30e-04 -9.20e-03]]
[[-0.01  0.03  0.05  0.04 -0.01]
 [ 0.04 -0.14  0.81 -0.16  0.04]
 [ 0.06 -0.22 -1.06 -0.18  0.04]
 [ 0.04 -0.16  0.85 -0.2   0.05]
 [-0.01  0.04  0.04  0.05 -0.01]]
SymNet parameters
[[ 1.15e-07  1.39e-07  6.01e-08 -1.96e-06  1.21e-06  3.72e-07 -2.92e-07 -1.04e-07
  -5.08e-08  8.57e-07  3.31e-08  5.26e-07]
 [ 3.67e-08 -3.91e-07  1.86e-08  1.28e-06 -1.63e-09  5.88e-07 -4.28e-08 -3.53e-08
   1.26e-07  5.11e-07  2.88e-07  4.24e-07]]
SymNet parameters
[ 6.06e-09 -2.57e-09]
SymNet parameters
[[ 9.85e-05  4.74e-04  9.91e-01 -6.97e-05  3.49e-04 -9.06e-04  1.25e-03 -2.98e-03
  -6.93e-04 -4.25e-04 -4.73e-04  3.33e-04 -4.49e-08]
 [ 1.83e-05 -9.85e-04 -4.09e-04  6.53e-05  5.48e-04  4.09e-05 -9.88e-01 -2.36e-04
  -6.59e-03 -3.72e-04  8.51e-05  8.14e-04 -1.99e-07]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-3.83e-04 -9.93e-01  1.08e-05  1.49e-03 -1.88e-03  3.10e-04 -1.72e-04  6.39e-04
   6.25e-05  2.80e-04 -4.15e-04  7.78e-04  1.38e-06 -3.44e-04]
 [-9.80e-01 -2.16e-04 -6.05e-03 -1.09e-03 -1.47e-04  6.40e-04 -7.02e-04 -4.76e-04
   6.49e-04  2.11e-04 -8.53e-04 -1.63e-04 -1.05e-06 -9.49e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-8.39e-09  5.14e-08 -5.02e-09  8.74e-07 -8.17e-08 -1.09e-07  2.55e-09 -9.27e-09
   1.66e-07 -1.94e-07  6.81e-09  1.16e-07 -1.17e-08  5.39e-08 -5.02e-08]
 [ 1.10e-08  1.61e-07  9.05e-09 -1.81e-07 -2.76e-08 -3.75e-08 -1.69e-08  5.18e-09
  -7.43e-08  4.78e-08 -2.34e-09  1.40e-07  1.03e-08  2.57e-08  8.13e-08]]
SymNet parameters
[-1.32e-08  3.01e-09]
SymNet parameters
[[-5.85e-09  1.17e-07 -1.53e-08  2.44e-07 -2.14e-08 -1.05e-09  1.23e-08  2.67e-08
  -5.13e-08 -7.33e-09  6.92e-08  5.77e-08  2.83e-09 -8.35e-08  5.83e-08 -6.95e-10]
 [ 1.19e-09 -3.38e-08 -6.42e-09 -1.62e-07 -1.19e-08  7.26e-09  3.26e-09  5.08e-09
  -8.03e-09  4.45e-08  6.83e-08  8.60e-09 -8.37e-09 -9.27e-08  9.71e-09  4.97e-09]]
SymNet parameters
[-1.51e-08  2.07e-08]
SymNet parameters
[[ 3.53e-03  6.01e-04  9.91e-04  4.97e-02 -6.13e-03  5.31e-02 -4.80e-04 -5.61e-04
  -2.53e-04 -1.34e-04 -1.03e-03 -1.14e-03  5.88e-07  9.88e-01 -9.99e-01 -1.38e-08
  -4.95e-08]]
SymNet parameters
[-0.]
SymNet parameters
[[ 2.57e-04 -1.95e-04 -1.92e-03 -5.31e-04  1.43e-04  7.09e-04 -9.86e-01  1.75e-04
  -5.59e-03 -5.00e-05  2.13e-04 -6.80e-04]
 [ 2.13e-05 -4.57e-04  3.51e-05  7.22e-04 -9.91e-05 -4.71e-05  3.79e-04 -1.63e-04
  -9.92e-01  3.68e-04  5.10e-04  7.02e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-1.44e-03  2.40e-04 -9.35e-04  7.22e-04  2.50e-04  4.23e-04  2.34e-05 -9.91e-01
   5.00e-04  1.16e-04 -9.04e-04  1.40e-04 -1.93e-04]
 [-9.82e-01 -4.12e-04 -7.28e-03  4.51e-04  3.73e-04  5.15e-04 -1.96e-04  4.36e-05
   2.08e-04  3.77e-04 -1.09e-03 -6.37e-04 -3.73e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.50e-08 -8.77e-08  2.50e-08  1.13e-08 -1.79e-08  7.94e-08  1.68e-08  5.06e-09
  -8.99e-09 -5.51e-08  5.88e-08 -9.54e-08  1.99e-07  1.09e-07]
 [-5.92e-09 -5.67e-08  2.28e-08 -1.19e-07 -8.27e-10 -3.04e-08  2.73e-08 -3.42e-09
  -2.01e-07 -1.33e-07  2.64e-08 -2.46e-07 -1.45e-07 -2.04e-08]]
SymNet parameters
[-6.90e-09  7.04e-09]
SymNet parameters
[[ 2.98e-09 -1.01e-08  2.79e-09 -5.07e-08 -5.16e-08 -3.02e-08 -4.90e-09  3.01e-09
  -5.90e-08 -1.39e-07 -2.86e-08 -1.26e-07 -1.38e-07  2.04e-08  1.82e-08]
 [-1.14e-08  2.77e-08 -2.11e-08 -9.98e-08  1.91e-10 -1.18e-07  7.65e-10  7.33e-09
  -1.83e-08 -2.12e-07 -7.98e-08 -3.29e-07 -1.39e-09 -2.36e-09 -3.65e-09]]
SymNet parameters
[1.81e-09 1.17e-10]
SymNet parameters
[[ 9.71e-09  1.68e-07 -6.12e-08 -1.48e-08 -3.03e-08 -9.08e-08 -3.28e-08  1.36e-08
   5.10e-07  1.70e-07  4.07e-08  3.02e-07  4.07e-07  1.22e-07 -6.14e-09  5.29e-09]
 [ 7.60e-10 -2.82e-08  2.00e-08  2.59e-07 -2.23e-09  3.17e-07 -2.25e-09 -6.98e-09
  -7.47e-08 -5.00e-08  9.46e-08 -6.12e-07  6.31e-08  5.61e-08 -2.08e-08  7.85e-09]]
SymNet parameters
[-4.38e-09  1.71e-08]
SymNet parameters
[[-4.82e-04  5.59e-04  2.93e-04 -5.24e-04 -1.26e-03 -5.40e-04  5.05e-03 -2.77e-04
  -2.38e-04  5.11e-02 -6.71e-03  5.31e-02 -9.91e-01 -9.95e-01 -7.57e-09  3.58e-07
  -1.29e-07]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   219    time: 4.77
Func: 2.15e-01  |g|: 8.79e-05
stableloss: 2.68e-02   dataloss: 7.92e-02   sparseloss: 1.22e+01 momentloss: 7.35e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u01*u10, u10*v10, u11, u00, v00*v01, u10, u00*u11, u00*u02, v00**2, u01, u01*v00, v20, u01*u02, v11, v00]
[-9.72e-01 -9.67e-01  5.31e-02  4.97e-02  9.22e-03 -6.98e-03 -6.44e-03 -6.13e-03
  4.55e-03  2.91e-03  1.95e-03 -1.84e-03  1.46e-03 -1.22e-03  1.19e-03 -1.16e-03
 -1.14e-03 -1.08e-03 -1.03e-03 -9.27e-04]
[v00*v10, u00*v01, v20, v02, u10*v01, v11, v00, v10**2, v00*v01*v10, 1, u10*v10, u00**2, u11, v01*v11, u00, u00*u10, u00*v11, u00*v10, u02*v00, u00*u02]
[-9.70e-01 -9.68e-01  5.31e-02  5.11e-02 -7.18e-03 -6.71e-03  6.00e-03 -5.50e-03
 -3.60e-03 -2.28e-03 -1.89e-03 -1.41e-03 -1.26e-03 -1.08e-03 -9.44e-04 -9.24e-04
 -8.85e-04  7.42e-04  7.06e-04  7.06e-04]
block:  3
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  1.6179397403162954
current stage is: block-3
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7018, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2578,  1.7468,  1.6179, 23.0806,  9.7366, 14.0216,  0.2765,  1.7550,
         1.8306, 20.1816, 10.6055, 16.3075], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 12.44
Func: 4.61e-01  |g|: 3.00e+00
stableloss: 3.24e-02   dataloss: 2.56e-01   sparseloss: 1.22e+01 momentloss: 7.35e+00
iter:   200    time: 20.87
Func: 4.21e-01  |g|: 1.07e-02
stableloss: 3.42e-02   dataloss: 2.12e-01   sparseloss: 1.22e+01 momentloss: 8.55e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.421381
         Iterations: 237
         Function evaluations: 322
         Gradient evaluations: 314
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -1.72e-03  1.19e-01 -9.86e-02]
 [ 0.00e+00  2.84e-04 -1.13e-03  1.24e-03  1.01e-01]
 [-3.24e-03 -5.12e-03  1.09e-02 -9.13e-05 -5.22e-02]
 [ 3.75e-02 -5.34e-03 -1.57e-01 -3.12e-03 -3.16e-02]
 [-1.31e-01  1.67e-02 -9.20e-02  3.88e-03 -4.16e-02]]
[[-0.01  0.03 -0.19  0.04 -0.01]
 [-0.02  0.34 -0.02  0.28 -0.02]
 [-0.23  0.16  0.37  0.03 -0.11]
 [ 0.15 -0.03  0.31 -0.1   0.15]
 [-0.05  0.01 -0.05  0.02 -0.05]]
[[ 0.    1.    0.   -0.1  -0.1 ]
 [ 0.    0.   -0.02  0.02  0.  ]
 [ 0.    0.03 -0.05  0.05 -0.04]
 [ 0.01  0.01 -0.09 -0.04 -0.06]
 [-0.01  0.01 -0.01  0.01 -0.  ]]
[[ 0.01 -0.04  0.07 -0.09  0.04]
 [-0.08  0.22 -0.3   0.3  -0.1 ]
 [ 0.16 -0.67 -0.32  0.99 -0.2 ]
 [-0.04  0.09  0.01 -0.1   0.06]
 [-0.01  0.02 -0.05  0.08 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  1.23e-02 -9.67e-03]
 [ 1.00e+00  0.00e+00  3.54e-02  1.88e-02 -6.45e-03]
 [ 0.00e+00  8.44e-04  7.04e-03  2.59e-03 -8.40e-03]
 [-1.09e-01 -2.01e-03  7.48e-02 -4.11e-03  6.82e-03]
 [-1.16e-01  6.45e-04 -1.84e-02 -1.01e-03 -2.10e-03]]
[[-1.96e-03 -4.85e-02  1.24e-01 -5.12e-02  1.70e-04]
 [ 1.41e-03  1.39e-01 -5.99e-01  1.52e-01 -7.15e-03]
 [ 9.67e-03 -1.67e-01 -3.82e-01 -1.64e-01  9.14e-03]
 [-2.86e-02  1.22e-01  1.08e+00  7.43e-02 -4.55e-03]
 [ 3.65e-03  5.85e-03 -2.77e-01  1.50e-02 -1.13e-03]]
[[ 0.    0.    1.    0.    0.01]
 [ 0.    0.    0.   -0.   -0.  ]
 [ 0.    0.    0.01 -0.    0.01]
 [ 0.    0.   -0.   -0.    0.  ]
 [ 0.29  0.01 -0.01 -0.   -0.08]]
[[-0.08  0.33 -0.21  0.34 -0.09]
 [ 0.34 -1.32  0.84 -1.35  0.35]
 [-0.58  3.25 -3.67  3.3  -0.59]
 [ 0.33 -1.26  0.76 -1.3   0.33]
 [-0.08  0.31 -0.18  0.32 -0.08]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.86e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  1.32e-03 -9.61e-02]
 [ 0.00e+00  0.00e+00  4.34e-04  5.85e-04 -2.20e-03]
 [ 0.00e+00  6.78e-04 -3.68e-03 -1.02e-03  9.58e-03]
 [ 6.17e-03  1.38e-03 -6.10e-03 -1.36e-03  1.55e-02]]
[[ 0.01 -0.07  0.03  0.04 -0.  ]
 [-0.05  0.44 -0.02 -0.46  0.07]
 [ 0.1  -0.45  0.71 -0.42  0.09]
 [-0.09  0.16 -0.93  1.02 -0.19]
 [ 0.02 -0.07  0.2  -0.18  0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.76e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.09e-03 -6.10e-02]
 [ 1.00e+00  0.00e+00  5.12e-02 -4.75e-03  5.03e-03]
 [ 0.00e+00  4.22e-03 -4.70e-03 -2.11e-03  9.52e-03]
 [ 8.23e-03  5.33e-03 -8.15e-03 -5.38e-04 -4.81e-03]]
[[-0.01  0.05 -0.14  0.05 -0.01]
 [ 0.07 -0.17  1.52 -0.18  0.07]
 [ 0.15 -0.79 -1.2  -0.76  0.15]
 [-0.03  0.25  0.89  0.22 -0.03]
 [ 0.01 -0.04 -0.01 -0.03  0.  ]]
SymNet parameters
[[-4.31e-07  1.55e-06  3.83e-07 -2.46e-06 -3.40e-06  1.42e-06 -8.44e-07 -3.91e-07
  -2.90e-07  1.35e-06  2.46e-08  6.22e-07]
 [ 9.36e-08  7.85e-07 -2.33e-08  2.58e-08  1.10e-06  4.80e-07 -2.14e-10 -4.43e-07
   2.33e-08 -1.87e-06 -2.00e-07  5.45e-07]]
SymNet parameters
[5.81e-09 1.42e-08]
SymNet parameters
[[ 9.06e-04 -3.22e-04  9.93e-01  7.38e-04  3.46e-03  1.53e-03 -5.44e-04  1.86e-03
   8.49e-05 -6.62e-04  9.63e-04 -5.91e-04 -5.44e-07]
 [-7.15e-04 -2.40e-04  5.15e-04  5.43e-04 -6.40e-04  1.39e-04 -9.84e-01 -1.03e-02
  -5.80e-03  8.00e-04  3.06e-04  1.26e-03  6.76e-07]]
SymNet parameters
[5.59e-06 6.45e-04]
SymNet parameters
[[-4.21e-04 -9.85e-01 -5.03e-04 -6.49e-04 -9.44e-03 -7.85e-04 -2.27e-03  1.52e-03
   6.10e-04 -1.39e-04  9.56e-04  6.22e-04 -9.29e-07  4.43e-04]
 [-9.83e-01 -1.09e-02 -4.82e-04 -1.64e-04 -1.22e-04  1.83e-03  4.59e-04  4.06e-04
   6.83e-04 -2.57e-04  2.96e-04 -4.96e-06  1.90e-06 -1.01e-02]]
SymNet parameters
[0.01 0.  ]
SymNet parameters
[[-4.25e-09  3.00e-08 -2.04e-09  4.47e-07 -4.17e-08 -5.79e-08  1.13e-09 -3.79e-09
   8.29e-08 -1.04e-07  4.06e-09  5.98e-08 -5.85e-09  2.88e-08 -1.45e-08]
 [ 5.48e-09  7.73e-08  4.50e-09 -2.20e-07  1.91e-09 -1.32e-08 -8.51e-09  6.93e-10
  -3.92e-08  8.73e-08 -1.29e-08  6.81e-08  5.14e-09  1.03e-08  4.11e-08]]
SymNet parameters
[-6.55e-09  1.82e-09]
SymNet parameters
[[-2.92e-09  5.87e-08 -7.65e-09  1.23e-07 -1.08e-08 -6.75e-10  6.12e-09  1.34e-08
  -2.55e-08 -4.14e-09  3.46e-08  2.91e-08  1.41e-09 -4.17e-08  2.91e-08 -3.46e-10]
 [ 5.99e-10 -1.68e-08 -3.20e-09 -8.18e-08 -5.87e-09  3.88e-09  1.63e-09  2.51e-09
  -4.01e-09  2.27e-08  3.40e-08  4.05e-09 -4.17e-09 -4.63e-08  4.93e-09  2.48e-09]]
SymNet parameters
[-7.52e-09  1.03e-08]
SymNet parameters
[[ 9.90e-04  8.22e-04  6.51e-04  5.14e-02 -2.13e-03  5.30e-02  1.60e-05 -3.55e-03
  -2.00e-03 -5.28e-04  2.18e-04  5.77e-07  5.65e-07  9.93e-01 -1.01e+00  8.18e-08
  -3.67e-09]]
SymNet parameters
[-0.]
SymNet parameters
[[-7.91e-04  5.65e-04  1.67e-03  6.01e-04 -3.09e-05 -2.53e-04 -9.89e-01 -9.84e-04
  -6.91e-03  5.03e-04  9.15e-05 -2.97e-04]
 [ 3.66e-05  3.19e-04 -1.20e-03  2.99e-04 -5.93e-04  4.81e-04 -6.52e-04 -9.53e-04
  -9.93e-01 -9.58e-04 -9.96e-04 -1.23e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 2.94e-05 -1.88e-03 -9.83e-04 -2.62e-04  9.68e-04  9.26e-04  3.97e-06 -9.92e-01
  -6.40e-04 -2.07e-04 -8.72e-03  4.66e-04  4.34e-04]
 [-9.74e-01 -9.46e-03 -7.42e-03  8.62e-04  1.69e-04  1.72e-03 -1.01e-03  5.53e-04
  -6.61e-03 -2.05e-04 -7.87e-04 -1.10e-04 -3.04e-03]]
SymNet parameters
[-5.58e-05  9.87e-04]
SymNet parameters
[[-7.49e-09 -4.38e-08  1.25e-08  5.03e-09 -8.99e-09  3.92e-08  8.28e-09  2.49e-09
  -3.73e-09 -2.68e-08  2.95e-08 -5.02e-08  9.98e-08  5.51e-08]
 [-2.94e-09 -2.88e-08  1.15e-08 -6.05e-08 -3.96e-10 -1.48e-08  1.37e-08 -1.65e-09
  -1.02e-07 -6.60e-08  1.33e-08 -1.23e-07 -7.17e-08 -9.48e-09]]
SymNet parameters
[-3.42e-09  3.55e-09]
SymNet parameters
[[ 1.45e-09 -2.81e-09  1.19e-09 -8.21e-09 -2.59e-08 -4.48e-09 -2.15e-09  1.51e-09
  -2.97e-08 -9.37e-08 -8.92e-09 -2.34e-08 -6.68e-08  7.32e-09  9.07e-09]
 [-5.64e-09  1.64e-08 -1.11e-08 -3.70e-08 -2.82e-10 -5.60e-08  1.25e-09  3.66e-09
  -1.66e-08 -1.22e-07 -3.60e-08 -1.53e-07 -2.80e-09 -1.60e-09 -1.82e-09]]
SymNet parameters
[ 6.47e-10 -1.19e-12]
SymNet parameters
[[ 4.89e-09  8.28e-08 -3.16e-08 -2.12e-08 -1.47e-08 -4.45e-08 -1.64e-08  6.75e-09
   2.53e-07  1.06e-07  2.00e-08  1.24e-07  2.02e-07  6.53e-08 -3.06e-09  2.64e-09]
 [ 5.47e-10 -1.50e-08  1.06e-08  1.37e-07 -1.24e-09  1.61e-07 -1.24e-10 -3.03e-09
  -4.69e-08 -3.74e-08  4.87e-08 -2.92e-07  2.57e-08  2.16e-08 -1.03e-08  3.91e-09]]
SymNet parameters
[-2.00e-09  8.52e-09]
SymNet parameters
[[-6.05e-05  2.99e-04  4.02e-04 -1.04e-04  3.93e-07  1.24e-05  5.19e-03  1.66e-03
   1.60e-04  5.23e-02 -2.51e-03  5.18e-02 -9.97e-01 -1.01e+00 -1.69e-08  1.75e-07
  -2.65e-08]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   237    time: 10.80
Func: 4.21e-01  |g|: 2.50e-04
stableloss: 3.42e-02   dataloss: 2.12e-01   sparseloss: 1.22e+01 momentloss: 8.53e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01**2, u10*v01, u01*u10*v00, u00*u11, u00, u10*v10, v01, u11*v00, u00*v00, u11, v10, v00*v01, u01*u20, u01, u00*v01, u20*v00]
[-0.98 -0.97  0.05  0.05 -0.01 -0.01  0.01 -0.01  0.01 -0.01 -0.   -0.   -0.   -0.
 -0.   -0.    0.    0.    0.   -0.  ]
[v00*v10, u00*v01, v02, v20, u01*v01, u00*v11, v01*v10, u10*v01, v10**2, v00, v00*v01*v10, v01, v11, v00*v01, u00*u01, u20*v01, u10*v10, u00*v10, v00*v20, u10*v00]
[-0.98 -0.97  0.05  0.05 -0.01 -0.01 -0.01 -0.01 -0.01  0.01 -0.    0.   -0.   -0.
 -0.    0.    0.   -0.   -0.   -0.  ]
block:  4
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  1.824366988998533
current stage is: block-4
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9681, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2659,  1.8765,  1.7756, 22.7321, 10.9948, 18.7368,  0.2306,  1.5793,
         1.7711, 17.6896, 10.5326, 20.3571], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 12.94
Func: 8.43e-01  |g|: 7.20e+00
stableloss: 6.85e-02   dataloss: 5.64e-01   sparseloss: 1.22e+01 momentloss: 8.53e+00
iter:   200    time: 29.30
Func: 7.53e-01  |g|: 2.82e-03
stableloss: 6.59e-02   dataloss: 4.73e-01   sparseloss: 1.22e+01 momentloss: 8.71e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.752582
         Iterations: 291
         Function evaluations: 376
         Gradient evaluations: 365
convolution moment and kernels
[[ 1.00e+00  0.00e+00  4.76e-04  6.38e-03 -8.14e-02]
 [ 0.00e+00  4.95e-04  2.69e-03  3.30e-03 -1.19e-02]
 [ 4.22e-03 -1.02e-03  6.41e-02 -1.32e-01  3.71e-03]
 [-2.90e-02  3.98e-03  3.85e-03 -8.81e-04 -1.98e-02]
 [-6.22e-02  1.33e-01 -9.39e-03  5.77e-02 -3.00e-03]]
[[-1.68e-02 -6.26e-02  2.65e-02 -2.59e-02  3.07e-02]
 [ 1.55e-01  9.12e-02 -5.66e-02  2.02e-01 -1.66e-01]
 [-3.65e-01  2.93e-01  5.05e-01 -1.07e-04  1.83e-01]
 [ 1.75e-01  2.04e-03  1.54e-01  9.04e-02 -1.38e-01]
 [-3.38e-02  9.10e-03 -1.18e-01  5.38e-02  1.16e-02]]
[[ 0.    1.    0.   -0.11 -0.14]
 [ 0.    0.   -0.01 -0.01 -0.02]
 [ 0.    0.06 -0.02  0.09 -0.04]
 [ 0.01 -0.02 -0.02 -0.03 -0.01]
 [-0.01  0.01  0.01  0.02 -0.  ]]
[[-0.01  0.02 -0.03 -0.01  0.01]
 [-0.05  0.09 -0.05  0.08 -0.03]
 [ 0.12 -0.46 -0.63  1.18 -0.25]
 [-0.07  0.12 -0.1   0.08 -0.01]
 [-0.    0.03 -0.04  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  2.51e-02  6.77e-04]
 [ 1.00e+00  0.00e+00  2.89e-02  1.17e-02 -1.08e-02]
 [ 0.00e+00 -1.20e-02 -4.33e-02 -1.77e-02  1.26e-02]
 [-1.10e-01  9.22e-03  3.72e-02 -3.38e-02 -1.29e-02]
 [-1.27e-01  2.49e-03 -4.90e-02 -7.34e-03  1.99e-03]]
[[ 0.01 -0.1   0.2  -0.12  0.02]
 [ 0.01  0.17 -0.64  0.22 -0.03]
 [-0.01 -0.18 -0.41 -0.17  0.01]
 [-0.02  0.17  1.07  0.03  0.03]
 [ 0.01 -0.05 -0.22  0.01 -0.01]]
[[ 0.    0.    1.    0.    0.01]
 [ 0.    0.    0.    0.01  0.  ]
 [ 0.    0.    0.01 -0.    0.05]
 [ 0.    0.01  0.   -0.01  0.  ]
 [ 0.31 -0.    0.    0.   -0.06]]
[[-0.07  0.27 -0.08  0.24 -0.06]
 [ 0.32 -1.25  0.56 -1.16  0.28]
 [-0.57  3.25 -3.43  3.17 -0.53]
 [ 0.3  -1.21  0.56 -1.2   0.3 ]
 [-0.06  0.25 -0.07  0.26 -0.06]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.65e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  8.23e-04 -4.92e-03]
 [ 0.00e+00  0.00e+00  4.55e-03 -3.26e-03  3.15e-03]
 [ 0.00e+00  8.04e-05 -1.58e-03 -6.56e-04  4.65e-03]
 [-4.76e-03  1.06e-01 -7.09e-04 -7.15e-03 -9.36e-03]]
[[ 0.01 -0.08 -0.08  0.18 -0.03]
 [-0.05  0.56  0.3  -0.94  0.15]
 [ 0.   -0.2  -0.41  0.72 -0.14]
 [ 0.04 -0.26  0.2   0.02  0.03]
 [-0.    0.   -0.04  0.05 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.49e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  7.17e-03  2.30e-03]
 [ 1.00e+00  0.00e+00  1.24e-01  1.05e-03  5.85e-03]
 [ 0.00e+00  4.81e-02  3.65e-03 -9.96e-03  2.34e-03]
 [ 7.14e-03  2.63e-03  4.91e-03 -8.36e-04 -6.09e-03]]
[[-1.11e-02  3.94e-02 -1.03e-01  1.59e-03 -2.84e-03]
 [ 2.86e-02  3.29e-02  1.13e+00  1.03e-01  1.24e-02]
 [ 4.26e-01 -1.98e+00  6.33e-01 -1.95e+00  4.16e-01]
 [ 4.84e-03  1.23e-01  1.14e+00  6.05e-03  3.41e-02]
 [ 1.79e-04 -6.74e-03 -1.01e-01  4.18e-02 -1.08e-02]]
SymNet parameters
[[ 1.81e-10 -3.09e-10 -6.56e-10  8.53e-11  1.93e-10  6.47e-10 -6.80e-10  9.52e-12
  -3.84e-10 -1.51e-10  6.24e-10 -2.00e-10]
 [ 4.46e-10 -2.98e-10 -3.78e-11 -1.05e-10  3.87e-11  8.01e-10  3.75e-10 -7.25e-12
  -5.42e-11 -2.43e-10  1.68e-10  1.80e-10]]
SymNet parameters
[3.41e-11 2.39e-11]
SymNet parameters
[[ 2.39e-05  2.35e-04  9.86e-01 -6.34e-04  1.34e-02 -3.73e-06  1.34e-03  2.38e-03
  -6.27e-04 -5.47e-04  1.51e-04 -4.82e-05 -4.40e-10]
 [-9.54e-04  3.50e-03 -3.42e-04  3.43e-04 -7.76e-04 -5.80e-04 -9.90e-01 -7.18e-03
  -5.91e-04  5.38e-04  1.56e-05  2.65e-04 -2.99e-10]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 4.85e-03 -9.86e-01 -7.65e-04  5.38e-04 -1.82e-03 -1.87e-04 -1.64e-05  9.71e-04
  -3.12e-03  1.49e-04  7.95e-04  3.05e-04  1.98e-10  9.22e-04]
 [-9.86e-01 -6.00e-03  7.81e-04 -6.49e-04 -2.52e-04  1.55e-04 -6.08e-04  2.76e-03
  -4.04e-04 -1.76e-04  3.94e-04  2.87e-05 -7.85e-12 -1.06e-02]]
SymNet parameters
[0.01 0.  ]
SymNet parameters
[[ 8.15e-13 -5.16e-12  4.15e-13 -8.50e-11  7.77e-12  9.97e-12 -2.19e-13  1.00e-12
  -1.61e-11  2.04e-11 -3.58e-13 -1.16e-11  1.14e-12 -5.68e-12  4.04e-12]
 [-1.05e-12 -1.53e-11 -8.39e-13  3.95e-11 -1.23e-12  5.89e-12  1.66e-12 -3.64e-13
   7.67e-12 -1.79e-11  1.59e-12 -1.24e-11 -9.98e-13 -1.85e-12 -7.49e-12]]
SymNet parameters
[ 1.26e-12 -3.31e-13]
SymNet parameters
[[ 5.67e-13 -1.14e-11  1.48e-12 -2.38e-11  2.10e-12  1.04e-13 -1.19e-12 -2.59e-12
   4.97e-12  8.52e-13 -6.72e-12 -5.65e-12 -2.74e-13  8.10e-12 -5.65e-12  6.72e-14]
 [-1.16e-13  3.28e-12  6.19e-13  1.59e-11  1.12e-12 -7.08e-13 -3.14e-13 -4.87e-13
   7.88e-13 -4.48e-12 -6.59e-12 -7.73e-13  8.10e-13  8.99e-12 -9.30e-13 -4.81e-13]]
SymNet parameters
[ 1.46e-12 -2.00e-12]
SymNet parameters
[[ 9.96e-04  1.64e-04  7.06e-04  5.66e-02 -1.74e-03  5.34e-02 -4.44e-04 -2.21e-04
  -3.41e-03  5.47e-04 -6.18e-04  3.26e-04 -4.24e-10  9.93e-01 -1.01e+00 -1.04e-11
   1.16e-12]]
SymNet parameters
[-0.]
SymNet parameters
[[ 7.42e-04  5.79e-05 -5.03e-04  2.76e-04 -1.81e-04  1.54e-04 -9.92e-01 -9.11e-03
   5.79e-04  9.54e-04 -4.17e-04 -9.32e-04]
 [-3.12e-03  1.19e-03  5.75e-04  1.91e-04 -4.06e-04 -2.77e-05 -1.12e-05  4.67e-04
  -9.85e-01 -2.56e-04 -1.38e-02  8.68e-05]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-1.03e-03  2.29e-06 -5.41e-04 -2.67e-04  8.29e-05 -3.58e-04 -9.31e-04 -9.88e-01
   8.73e-04 -4.00e-04 -1.02e-03 -1.32e-03 -4.05e-03]
 [-9.88e-01 -7.14e-03  3.97e-05  3.46e-04 -2.54e-04 -4.88e-05  4.55e-04  6.12e-04
  -1.61e-04 -1.39e-04 -4.94e-04  1.23e-04 -3.03e-04]]
SymNet parameters
[-2.68e-05  9.82e-04]
SymNet parameters
[[ 1.45e-12  8.51e-12 -2.43e-12 -9.95e-13  1.73e-12 -7.62e-12 -1.61e-12 -4.85e-13
   7.90e-13  5.21e-12 -5.76e-12  9.92e-12 -1.93e-11 -1.07e-11]
 [ 5.71e-13  5.56e-12 -2.22e-12  1.18e-11  7.50e-14  2.87e-12 -2.67e-12  3.22e-13
   1.97e-11  1.28e-11 -2.61e-12  2.40e-11  1.40e-11  1.86e-12]]
SymNet parameters
[ 6.64e-13 -6.88e-13]
SymNet parameters
[[-2.74e-13  7.52e-13 -1.39e-13  1.66e-12  5.45e-12  1.07e-12  4.28e-13 -2.88e-13
   5.71e-12  1.77e-11  2.32e-12  1.81e-12  1.28e-11 -1.46e-12 -1.76e-12]
 [ 1.10e-12 -2.96e-12  2.17e-12  7.44e-12  3.67e-13  1.10e-11 -2.36e-13 -7.14e-13
   2.33e-12  2.33e-11  7.41e-12  2.85e-11  5.29e-13  1.87e-13  3.53e-13]]
SymNet parameters
[-1.41e-13 -7.38e-15]
SymNet parameters
[[-9.56e-13 -1.62e-11  6.11e-12  4.09e-12  2.49e-12  7.84e-12  3.18e-12 -1.31e-12
  -4.95e-11 -1.98e-11 -4.34e-12 -2.03e-11 -3.83e-11 -1.19e-11  5.94e-13 -5.12e-13]
 [-1.09e-13  2.79e-12 -1.96e-12 -2.59e-11  6.63e-13 -3.09e-11  2.69e-14  6.35e-13
   6.93e-12  7.34e-12 -9.31e-12  5.49e-11 -7.07e-12 -5.33e-12  2.01e-12 -7.60e-13]]
SymNet parameters
[ 4.03e-13 -1.66e-12]
SymNet parameters
[[-2.33e-05 -1.10e-04 -1.01e-04  3.96e-04 -1.00e-03  2.47e-04  8.47e-03  2.80e-03
   5.88e-04  5.65e-02 -2.37e-03  5.26e-02 -1.00e+00 -9.97e-01  3.23e-12 -3.27e-11
  -1.31e-12]]
SymNet parameters
[0.]
finally, finish this stage
iter:   291    time: 20.90
Func: 7.53e-01  |g|: 1.75e-07
stableloss: 6.59e-02   dataloss: 4.73e-01   sparseloss: 1.22e+01 momentloss: 8.71e+00
current expression:
[u00*u01, u10*v00, u02, u20, u11*v00, u01*u10*v00, u00, u10*v01, u01**2, u00**2, u01*u10, 1, v10, u00*v10, u01*v01, v00*v01, u00*u11, u11, u00*u10, u10]
[-0.98 -0.97  0.06  0.05 -0.01  0.01  0.01 -0.01 -0.01  0.    0.   -0.   -0.   -0.
  0.   -0.   -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v11, v00, v01*v10, u01*v01, u00*v00, u00*v00*v10, v01, v11, u00*v10, 1, u00*v20, u01*v00, v10, u00**2, u11, u00*v11]
[-0.98 -0.97  0.06  0.05 -0.01  0.01 -0.01 -0.01 -0.   -0.    0.   -0.    0.    0.
 -0.    0.    0.   -0.   -0.   -0.  ]
block:  5
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  0.6859067935626687
current stage is: block-5
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9457, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2478,  1.6073,  1.6550, 19.6570,  9.6384, 17.9210,  0.2494,  1.5290,
         1.6480, 17.5723,  9.3193, 17.7741], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 13.62
Func: 1.02e+00  |g|: 1.23e+01
stableloss: 4.32e-02   dataloss: 6.72e-01   sparseloss: 1.22e+01 momentloss: 8.71e+00
iter:   200    time: 30.34
Func: 8.59e-01  |g|: 6.58e-02
stableloss: 4.99e-02   dataloss: 5.11e-01   sparseloss: 1.22e+01 momentloss: 8.74e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.859149
         Iterations: 263
         Function evaluations: 348
         Gradient evaluations: 334
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.55e-03 -3.57e-03 -1.04e-01]
 [ 0.00e+00 -2.68e-03 -2.74e-02 -1.23e-03 -5.96e-02]
 [ 6.85e-04 -1.99e-04  2.87e-02  2.75e-03 -5.77e-02]
 [ 5.55e-03 -2.63e-03  2.70e-03  1.72e-03 -1.38e-02]
 [-4.99e-02 -3.16e-03 -6.76e-03  2.60e-03 -1.62e-02]]
[[-0.01  0.02 -0.08  0.02 -0.01]
 [ 0.01  0.05  0.07  0.07  0.  ]
 [-0.05  0.09  0.65  0.06 -0.04]
 [-0.04  0.19 -0.14  0.23 -0.05]
 [-0.01  0.05 -0.11  0.04 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.22e-02 -1.03e-01]
 [ 0.00e+00  0.00e+00 -1.43e-02 -3.57e-02 -5.06e-04]
 [ 0.00e+00  5.46e-02 -4.79e-02  9.53e-02 -6.72e-02]
 [ 1.48e-03 -4.36e-02 -3.74e-02 -5.21e-02 -1.39e-02]
 [-6.96e-03  2.20e-02 -1.68e-02  2.18e-02 -1.86e-02]]
[[-2.16e-02  4.11e-02 -5.56e-02  1.96e-02  8.78e-03]
 [-3.76e-02  1.34e-01 -8.36e-02  3.27e-02 -1.63e-02]
 [ 1.35e-01 -6.54e-01 -3.65e-01  1.07e+00 -2.30e-01]
 [-3.61e-02  9.83e-02 -6.29e-02 -2.16e-04  2.73e-02]
 [-1.31e-02  3.27e-02 -4.96e-02  4.54e-02 -2.16e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  2.14e-03  4.32e-03]
 [ 1.00e+00  0.00e+00  3.78e-02  6.76e-03 -8.80e-03]
 [ 0.00e+00 -4.44e-04 -3.72e-02 -7.50e-03 -3.50e-03]
 [-9.72e-02  1.10e-02  7.11e-02  1.31e-02 -4.79e-03]
 [-9.66e-02  1.94e-02 -4.62e-02  5.62e-03 -8.98e-03]]
[[ 3.14e-04 -8.17e-02  1.82e-01 -6.35e-02 -1.77e-03]
 [ 2.36e-02  1.33e-01 -6.36e-01  9.13e-02  1.09e-02]
 [-4.30e-02 -1.06e-01 -3.64e-01 -5.87e-02 -7.93e-03]
 [ 3.59e-02  1.66e-02  1.11e+00 -2.00e-02  9.60e-03]
 [-1.35e-02  2.28e-02 -2.64e-01  3.15e-02 -5.40e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  6.03e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.05e-03 -7.45e-04]
 [ 0.00e+00  0.00e+00  1.53e-01 -7.05e-03  8.63e-02]
 [ 0.00e+00  4.59e-03  3.69e-03 -3.64e-03 -5.20e-03]
 [ 1.44e-01 -3.27e-03  7.94e-03 -4.30e-03 -4.33e-04]]
[[-0.    0.01  0.13  0.01 -0.  ]
 [ 0.1  -0.22 -0.34 -0.21  0.1 ]
 [-0.27  1.74 -2.07  1.73 -0.27]
 [ 0.1  -0.25 -0.27 -0.27  0.11]
 [-0.01  0.03  0.09  0.04 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.29e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  9.62e-04 -2.38e-01]
 [ 0.00e+00  0.00e+00 -2.92e-03 -2.67e-06  3.94e-03]
 [ 0.00e+00  1.18e-03 -2.37e-04 -2.78e-06  4.69e-03]
 [-3.43e-01  1.64e-01  1.25e-03 -6.33e-03  2.26e-03]]
[[ 0.   -0.09 -0.47  0.25 -0.04]
 [ 0.04  0.26  2.35 -1.56  0.28]
 [ 0.1  -0.66 -2.11  0.72 -0.1 ]
 [-0.18  0.68  0.39  0.64 -0.15]
 [ 0.03 -0.16 -0.2  -0.03  0.01]]
[[ 0.    0.    0.    0.    0.11]
 [ 0.    0.    0.    0.    0.  ]
 [ 1.    0.    0.13 -0.01  0.01]
 [ 0.    0.    0.   -0.   -0.01]
 [ 0.01 -0.02  0.12  0.   -0.  ]]
[[-0.01  0.16 -0.34  0.12 -0.01]
 [ 0.06 -0.53  2.13 -0.38  0.02]
 [ 0.01  0.35 -3.01  0.15  0.05]
 [ 0.07 -0.6   2.26 -0.48  0.05]
 [-0.02  0.19 -0.39  0.17 -0.02]]
SymNet parameters
[[-1.38e-06  1.98e-07 -1.38e-06  1.34e-07 -3.65e-08  3.75e-07  5.32e-07 -3.68e-07
   9.41e-07  8.25e-07  1.14e-06 -1.10e-06]
 [-4.46e-07 -8.06e-07  3.32e-07 -9.44e-07 -4.02e-07  7.17e-07 -1.01e-06  1.01e-06
  -2.69e-08  8.18e-07  1.65e-06  5.55e-07]]
SymNet parameters
[-1.61e-08 -2.46e-08]
SymNet parameters
[[-1.65e-04 -4.27e-04  9.89e-01  1.98e-05  5.37e-03 -1.10e-03 -2.66e-04  2.25e-03
   1.09e-03  5.25e-04  3.57e-04  1.53e-04  6.78e-07]
 [ 1.53e-04  6.53e-04 -1.57e-04 -5.07e-04 -6.84e-04  8.58e-05 -9.95e-01 -2.21e-03
  -5.79e-04  9.93e-04 -4.02e-04 -3.26e-05  8.39e-07]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 3.52e-04 -9.90e-01  1.25e-04 -1.09e-03  4.47e-03 -1.00e-03  1.31e-04  1.78e-03
  -1.01e-03  6.64e-04  2.31e-04  1.42e-04  3.39e-08  8.13e-04]
 [-9.87e-01 -2.98e-03  6.64e-04 -5.54e-04 -4.49e-04  6.90e-04  2.39e-03  8.39e-04
   2.49e-04  7.27e-04 -1.11e-04  2.26e-04  6.71e-07 -7.35e-03]]
SymNet parameters
[1.03e-03 2.60e-06]
SymNet parameters
[[-1.20e-10  2.21e-09 -1.21e-10  1.08e-08 -4.05e-09 -2.45e-09  1.71e-11  2.86e-10
   2.41e-09 -3.01e-09  2.27e-09  1.52e-09 -2.01e-10  1.80e-09  2.39e-09]
 [ 1.33e-10  1.88e-09  2.58e-10 -4.88e-10  1.17e-09  2.49e-10 -2.69e-10 -7.33e-10
  -9.35e-10  5.86e-10 -6.41e-09  1.20e-09  1.76e-10 -2.37e-09 -4.35e-10]]
SymNet parameters
[-2.64e-10  1.28e-10]
SymNet parameters
[[-1.01e-10  1.99e-09 -2.51e-10  4.38e-09 -3.24e-10  1.79e-11  2.12e-10  4.17e-10
  -9.21e-10 -2.07e-10  1.07e-09  9.84e-10  4.84e-11 -1.48e-09  1.02e-09 -1.19e-11]
 [ 2.28e-11 -6.71e-10 -9.39e-11 -2.94e-09 -2.07e-10  5.52e-11  5.81e-11  7.12e-11
  -1.90e-10  8.07e-10  1.38e-09  1.98e-10 -1.43e-10 -1.55e-09  1.40e-10  8.49e-11]]
SymNet parameters
[-2.56e-10  3.52e-10]
SymNet parameters
[[ 7.23e-03  7.75e-06  1.94e-04  5.13e-02  3.38e-03  5.16e-02  1.40e-03  4.41e-04
   7.03e-04 -2.04e-05  5.58e-04  2.38e-05 -4.10e-07  9.92e-01 -1.00e+00 -2.96e-08
  -3.34e-09]]
SymNet parameters
[0.]
SymNet parameters
[[ 1.06e-03 -4.42e-04  1.67e-03 -1.03e-04 -5.55e-04 -4.35e-05 -9.96e-01 -3.82e-04
   5.37e-04  8.81e-04 -3.53e-04 -6.52e-04]
 [-1.18e-04  2.16e-03  4.93e-04 -5.35e-04 -1.09e-03  6.05e-04  9.78e-06  9.58e-04
  -9.87e-01  6.28e-05 -5.91e-03  1.61e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 1.23e-03  5.27e-04  5.21e-04  8.03e-04  1.95e-03 -3.44e-04 -5.79e-05 -9.86e-01
   5.49e-04 -1.32e-03  4.61e-03 -1.03e-03 -1.31e-03]
 [-9.92e-01 -1.44e-03 -1.06e-03  9.94e-04 -7.23e-05 -3.64e-05  9.29e-04 -2.75e-05
  -2.45e-04  8.46e-06  1.53e-04  6.44e-05  2.68e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-2.54e-10 -1.68e-09  4.39e-10  4.82e-10 -6.46e-10  9.44e-10  2.60e-10  7.94e-11
   4.81e-10 -6.62e-10 -4.03e-10 -3.39e-09  4.68e-09  2.30e-09]
 [-1.13e-10 -1.12e-09  3.05e-10 -2.32e-09 -3.45e-10 -6.72e-10  5.13e-10 -5.71e-11
  -4.45e-09 -2.03e-09 -9.04e-11 -4.83e-09 -2.67e-09 -1.79e-10]]
SymNet parameters
[-1.16e-10  1.29e-10]
SymNet parameters
[[ 5.99e-11  2.64e-09  1.04e-09 -5.96e-10  5.88e-09  6.98e-09 -1.38e-10  1.47e-10
  -1.31e-09 -6.00e-09  2.23e-08  2.76e-08 -7.81e-09  1.66e-09  3.11e-10]
 [-1.52e-10  2.41e-09 -7.25e-10 -1.78e-09  1.60e-09 -6.53e-10  3.24e-10  1.12e-10
  -5.81e-09 -3.75e-09  1.39e-09 -4.48e-09 -4.64e-09 -5.36e-10 -6.24e-11]]
SymNet parameters
[-8.90e-11 -1.99e-11]
SymNet parameters
[[ 1.75e-10  2.88e-09 -1.00e-09 -8.32e-10 -3.91e-10 -1.11e-09 -5.76e-10  2.34e-10
   8.92e-09  3.01e-09  1.85e-09  5.35e-09  6.76e-09  1.99e-09 -1.05e-10  9.05e-11]
 [ 2.53e-11 -4.95e-10  3.80e-10  4.82e-09 -4.95e-11  5.28e-09 -3.71e-11 -1.16e-10
  -4.61e-10 -1.19e-09  1.23e-09 -1.04e-08  2.29e-09  1.41e-09 -3.55e-10  1.34e-10]]
SymNet parameters
[-7.82e-11  2.90e-10]
SymNet parameters
[[ 6.22e-04  3.85e-05  1.09e-03 -1.88e-04  7.42e-05 -5.17e-04  5.58e-03  2.19e-04
  -6.85e-04  5.25e-02  2.83e-03  5.16e-02 -9.97e-01 -9.99e-01 -1.15e-08  4.62e-09
   2.46e-08]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   263    time: 16.38
Func: 8.59e-01  |g|: 9.68e-04
stableloss: 4.99e-02   dataloss: 5.10e-01   sparseloss: 1.22e+01 momentloss: 8.84e+00
current expression:
[u00*u01, u10*v00, u20, u02, u00, u01*u10*v00, u11*v00, u00*u11, u11, u01**2, u01*v00, v00, v00*v01, u10*v01, u00*v01, u01*u10, 1, u20*v00, u00*u02, v00*v10]
[-0.98 -0.98  0.05  0.05  0.01  0.01 -0.01  0.    0.   -0.    0.    0.   -0.   -0.
  0.    0.    0.    0.   -0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00, v00*v11, u00*v11, v11, v00*v01*v10, u01*v00, u00*u11, v00*v01, u10*v10, v00*v20, u00*v10, u01*v01, v10, u00*v02, 1, u00*v00*v10]
[-0.98 -0.98  0.05  0.05  0.01 -0.01  0.    0.    0.    0.    0.    0.    0.    0.
  0.   -0.   -0.   -0.   -0.   -0.  ]
block:  6
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  0.46003313610686264
current stage is: block-6
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8088, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2314,  1.5443,  1.4472, 18.1670, 10.7990, 15.5333,  0.2676,  1.6616,
         1.8518, 16.9058, 13.7408, 22.9659], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 15.73
Func: 1.35e+00  |g|: 2.35e+01
stableloss: 6.04e-02   dataloss: 9.32e-01   sparseloss: 1.22e+01 momentloss: 8.85e+00
iter:   200    time: 34.40
Func: 1.14e+00  |g|: 1.05e-02
stableloss: 6.05e-02   dataloss: 7.21e-01   sparseloss: 1.22e+01 momentloss: 8.72e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 1.139597
         Iterations: 283
         Function evaluations: 377
         Gradient evaluations: 365
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -5.66e-04  5.56e-02 -4.86e-02]
 [ 0.00e+00  4.43e-04  2.96e-02  3.92e-03  4.08e-03]
 [-3.94e-03 -1.98e-02  2.91e-02  6.02e-03 -7.83e-03]
 [-6.21e-02 -5.75e-03 -2.93e-02  8.57e-03 -5.89e-02]
 [-4.30e-02 -1.11e-02 -2.61e-03  4.14e-03 -6.54e-03]]
[[ 0.02 -0.08  0.1  -0.08  0.02]
 [-0.04  0.17 -0.17  0.19 -0.05]
 [-0.09  0.23  0.57  0.08 -0.03]
 [ 0.08 -0.21  0.45 -0.15  0.06]
 [-0.04  0.13 -0.23  0.1  -0.03]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.00e-02 -8.75e-02]
 [ 0.00e+00  0.00e+00  9.58e-03  3.38e-02  4.07e-03]
 [ 0.00e+00  3.40e-02 -1.03e-01  8.81e-02 -5.46e-02]
 [-1.13e-02  1.60e-03  8.69e-03  5.17e-02  1.40e-04]
 [ 1.52e-02 -9.29e-03 -2.93e-02  1.10e-02 -1.68e-02]]
[[-0.    0.    0.01  0.03 -0.02]
 [-0.05  0.05 -0.07 -0.04  0.04]
 [ 0.14 -0.5  -0.43  1.14 -0.25]
 [-0.02 -0.03 -0.01 -0.01  0.01]
 [-0.03  0.06 -0.02 -0.01  0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00 -2.59e-03 -3.26e-04]
 [ 1.00e+00  0.00e+00  6.02e-02 -8.10e-03  1.61e-02]
 [ 0.00e+00  7.68e-04 -7.54e-02  3.62e-02 -2.84e-03]
 [-9.29e-02 -2.98e-02  8.88e-02 -1.93e-02  1.24e-02]
 [-1.05e-01 -1.50e-02 -5.92e-02  1.36e-02 -7.25e-03]]
[[-0.01 -0.06  0.18 -0.1   0.01]
 [ 0.02  0.1  -0.64  0.18 -0.  ]
 [-0.02 -0.02 -0.43 -0.12 -0.02]
 [ 0.02 -0.03  1.1   0.08  0.01]
 [-0.    0.01 -0.21 -0.03  0.  ]]
[[ 0.    0.    1.    0.    0.01]
 [ 0.    0.    0.    0.   -0.  ]
 [ 0.    0.    0.01  0.    0.01]
 [ 0.   -0.    0.    0.    0.01]
 [ 0.11  0.    0.01 -0.    0.  ]]
[[ 1.12e-03  3.28e-03  8.69e-02  2.22e-02 -5.23e-03]
 [-2.96e-03 -1.30e-02 -3.58e-01 -7.90e-02  1.96e-02]
 [-6.24e-02  1.29e+00 -1.86e+00  1.37e+00 -9.23e-02]
 [-1.81e-02  4.18e-02 -4.52e-01 -1.91e-03 -2.61e-03]
 [ 7.52e-03 -2.05e-02  1.30e-01 -1.47e-02  5.69e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.41e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  1.26e-04  5.07e-03]
 [ 0.00e+00  0.00e+00 -3.81e-03  1.55e-03  7.67e-03]
 [ 0.00e+00  2.15e-04  2.01e-04  9.25e-04 -6.26e-03]
 [ 4.51e-04 -9.53e-02  6.96e-03  1.13e-01 -4.67e-02]]
[[-0.1   0.31 -0.28  0.06  0.01]
 [ 0.39 -1.05  1.2  -0.53 -0.01]
 [-0.7   2.35 -1.96  0.23  0.08]
 [ 0.52 -2.02  1.32  0.28 -0.1 ]
 [-0.12  0.45 -0.32 -0.02  0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.49e-02]
 [ 0.00e+00  0.00e+00  0.00e+00  2.31e-03 -3.92e-03]
 [ 1.00e+00  0.00e+00  5.44e-01  3.97e-03  6.69e-02]
 [ 0.00e+00 -4.64e-03  4.17e-03  4.95e-03  3.97e-02]
 [ 8.92e-03  4.37e-03  2.13e-01 -3.28e-03  8.07e-04]]
[[-3.53e-02  3.11e-01 -6.39e-01  3.31e-01 -4.23e-02]
 [ 1.26e-01 -6.42e-01  2.38e+00 -7.16e-01  1.51e-01]
 [-1.14e-01  3.98e-01 -3.07e+00  4.92e-01 -1.48e-01]
 [ 4.62e-02 -3.28e-01  1.89e+00 -3.75e-01  6.33e-02]
 [ 2.06e-03  1.62e-01 -4.07e-01  1.68e-01  3.88e-04]]
SymNet parameters
[[-7.19e-08  6.39e-07  4.39e-09 -1.15e-07  7.76e-07 -2.04e-07  1.20e-07 -3.04e-07
   1.32e-07 -4.49e-07  6.60e-07 -5.18e-07]
 [ 4.77e-08  6.37e-07  2.39e-07  9.95e-07 -5.45e-07 -4.78e-07  2.63e-07 -1.22e-07
  -3.71e-07  7.19e-07  4.86e-07  5.49e-07]]
SymNet parameters
[-2.35e-08 -2.80e-09]
SymNet parameters
[[-6.88e-04 -4.70e-04  9.93e-01 -7.00e-05 -7.48e-03 -2.08e-04  3.88e-04 -1.62e-03
  -9.44e-04  6.58e-04 -4.76e-04  4.52e-05 -2.88e-07]
 [-2.67e-04  1.32e-03 -1.83e-03 -1.18e-06  3.89e-04  2.93e-04 -9.89e-01  4.82e-03
   5.88e-03  3.82e-04 -4.24e-04  4.65e-04 -1.61e-06]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-2.01e-03 -9.90e-01 -1.57e-04  1.12e-03 -8.44e-04  2.57e-04  8.90e-04  1.45e-03
   2.06e-03 -6.74e-04 -1.96e-03  4.56e-05 -5.40e-07  8.77e-04]
 [-9.86e-01  3.76e-03  8.92e-04 -2.43e-04  1.43e-04  2.96e-04  4.45e-04 -1.70e-03
  -1.34e-03  1.34e-04  1.57e-04 -2.45e-04 -7.43e-07 -8.90e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-1.18e-11  2.07e-10 -1.18e-11  1.04e-09 -3.83e-10 -2.56e-10  1.92e-12  2.17e-11
   2.13e-10 -3.15e-10  2.02e-10  1.65e-10 -1.98e-11  1.56e-10  1.91e-10]
 [ 1.22e-11  1.79e-10  2.40e-11  1.36e-10  1.47e-10  8.78e-11 -2.82e-11 -5.50e-11
  -5.99e-11  1.09e-10 -5.67e-10  1.22e-10  1.74e-11 -1.77e-10 -5.68e-11]]
SymNet parameters
[-2.57e-11  1.19e-11]
SymNet parameters
[[-9.93e-12  1.97e-10 -2.49e-11  4.23e-10 -3.31e-11 -9.91e-13  2.09e-11  4.11e-11
  -9.22e-11 -2.08e-11  1.06e-10  9.75e-11  4.78e-12 -1.46e-10  1.02e-10 -1.17e-12]
 [ 2.21e-12 -6.62e-11 -9.45e-12 -2.78e-10 -1.83e-11  9.09e-12  5.66e-12  7.77e-12
  -1.84e-11  8.15e-11  1.35e-10  1.86e-11 -1.41e-11 -1.53e-10  1.24e-11  8.38e-12]]
SymNet parameters
[-2.53e-11  3.48e-11]
SymNet parameters
[[ 5.24e-03  2.44e-04 -8.48e-04  4.87e-02  8.54e-04  5.27e-02 -6.64e-04 -8.69e-04
  -6.30e-04  3.95e-04 -5.21e-04  3.68e-04 -1.00e-07  9.95e-01 -1.00e+00 -2.63e-09
  -2.92e-10]]
SymNet parameters
[-0.]
SymNet parameters
[[-9.89e-04  4.15e-04 -1.61e-03 -1.47e-04  1.50e-03  7.17e-04 -9.93e-01  6.62e-04
   6.69e-03  1.11e-04 -4.00e-04 -6.28e-04]
 [-1.83e-04 -3.99e-04 -9.75e-04  3.81e-04  9.21e-04 -2.82e-04  1.06e-03  8.10e-04
  -9.85e-01  6.00e-04  7.83e-03  8.23e-04]]
SymNet parameters
[-0.    0.01]
SymNet parameters
[[-7.44e-04  6.80e-04 -3.33e-03 -1.06e-03 -9.10e-04 -5.59e-05 -1.80e-04 -9.87e-01
  -7.01e-04  1.72e-03  2.25e-03  1.37e-03 -7.62e-04]
 [-9.87e-01  2.55e-03  4.77e-03  7.25e-04 -4.80e-04  5.66e-05  7.42e-04 -8.05e-04
   9.74e-04 -1.29e-07 -9.98e-04 -3.69e-04 -5.92e-04]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-2.51e-11 -1.67e-10  4.50e-11  4.74e-11 -4.71e-11  9.90e-11  2.57e-11  7.87e-12
   5.93e-11 -8.17e-11 -3.67e-11 -3.23e-10  4.93e-10  2.30e-10]
 [-1.08e-11 -1.14e-10  3.11e-11 -2.33e-10 -2.82e-11 -7.22e-11  5.02e-11 -6.31e-12
  -4.62e-10 -2.06e-10 -4.50e-13 -4.76e-10 -2.74e-10 -2.23e-11]]
SymNet parameters
[-1.14e-11  1.27e-11]
SymNet parameters
[[ 5.84e-12  2.38e-10  9.34e-11 -5.86e-11  5.16e-10  6.28e-10 -1.30e-11  1.37e-11
  -1.39e-10 -5.63e-10  2.01e-09  2.49e-09 -7.45e-10  1.50e-10  3.07e-11]
 [-1.53e-11  2.21e-10 -6.81e-11 -1.75e-10  1.64e-10 -7.88e-11  3.01e-11  1.12e-11
  -5.46e-10 -4.06e-10  1.20e-10 -4.48e-10 -4.23e-10 -5.20e-11 -6.16e-12]]
SymNet parameters
[-7.84e-12 -1.85e-12]
SymNet parameters
[[ 1.68e-11  2.92e-10 -1.08e-10 -8.24e-11 -7.06e-11 -9.03e-11 -5.64e-11  2.41e-11
   8.95e-10  3.24e-10  1.66e-10  5.25e-10  6.53e-10  2.14e-10 -1.04e-11  8.93e-12]
 [ 2.25e-12 -4.81e-11  4.36e-11  4.86e-10  2.95e-11  5.29e-10 -3.90e-12 -1.04e-11
   5.21e-11 -1.64e-10  9.85e-11 -1.02e-09  3.87e-10  1.66e-10 -3.50e-11  1.32e-11]]
SymNet parameters
[-7.80e-12  2.84e-11]
SymNet parameters
[[ 5.07e-04 -2.05e-03  9.94e-04  1.30e-03  7.32e-04 -3.73e-04  3.58e-03 -2.16e-03
  -2.41e-04  4.92e-02 -1.06e-03  5.22e-02 -1.00e+00 -1.00e+00 -1.06e-09  5.29e-10
   2.23e-09]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   283    time: 22.98
Func: 1.14e+00  |g|: 6.42e-04
stableloss: 6.05e-02   dataloss: 7.21e-01   sparseloss: 1.22e+01 momentloss: 8.72e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u11*v00, u00, u10*v10, u10*v01, u01**2, 1, u01*u10, u00*v10, u00**2, u00*v11, u10**2, u01*v01, u10, v00*v01, u00*v00]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.    0.   -0.    0.    0.   -0.
 -0.   -0.   -0.   -0.    0.    0.  ]
[v00*v10, u00*v01, v20, v02, v00, v00*v11, v10**2, u10*v01, u00*u10, v01, u01*v01, u00*v11, u01, u00*v02, u00*v10, v01*v10, u10*v10, v00*v01, u11*v10, 1]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.   -0.   -0.    0.    0.   -0.    0.
 -0.    0.   -0.    0.    0.   -0.  ]
block:  9
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -1.194727007088141
current stage is: block-9
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8821, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2679,  1.7569,  1.7220, 21.1561, 10.6815, 16.3852,  0.2563,  1.6753,
         1.6658, 18.2966, 10.1104, 17.7094], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 12.92
Func: 3.61e+00  |g|: 3.80e+01
stableloss: 9.06e-02   dataloss: 2.99e+00   sparseloss: 1.22e+01 momentloss: 8.72e+00
iter:   200    time: 51.25
Func: 3.28e+00  |g|: 1.87e-01
stableloss: 8.88e-02   dataloss: 2.63e+00   sparseloss: 1.22e+01 momentloss: 1.05e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 3.275643
         Iterations: 271
         Function evaluations: 371
         Gradient evaluations: 358
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -9.78e-04 -4.96e-02 -6.27e-02]
 [ 0.00e+00  2.14e-03  4.34e-02 -1.71e-02  1.15e-01]
 [-1.71e-03  5.06e-02  7.16e-02 -8.10e-03 -2.44e-02]
 [-2.10e-02 -5.92e-03 -4.30e-03 -8.65e-04  7.15e-02]
 [-4.32e-02  6.64e-02  1.20e-02  1.64e-02 -1.10e-02]]
[[-3.86e-02  1.28e-01 -2.72e-01  1.84e-01 -3.35e-02]
 [ 2.05e-02  6.66e-02  1.50e-01 -7.61e-02 -1.10e-02]
 [-7.03e-02  1.34e-02  6.10e-01  2.39e-01 -4.67e-02]
 [ 3.74e-02  8.15e-02  8.98e-02  5.09e-04 -1.75e-02]
 [ 1.31e-02 -8.98e-02  4.90e-02 -4.72e-02  2.13e-02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.08e-01 -9.13e-02]
 [ 0.00e+00  0.00e+00  1.69e-02  6.70e-03  2.71e-02]
 [ 0.00e+00  4.50e-02 -1.03e-01  8.60e-02 -7.54e-02]
 [ 1.61e-03  2.40e-03 -8.03e-03  3.67e-04 -4.31e-03]
 [-3.75e-03 -5.90e-03 -4.53e-02  7.45e-03 -2.93e-02]]
[[-0.02  0.04 -0.04  0.02 -0.01]
 [-0.04  0.08 -0.08  0.03  0.03]
 [ 0.13 -0.55 -0.45  1.14 -0.29]
 [-0.   -0.04  0.09 -0.11  0.07]
 [-0.02  0.06 -0.06  0.05 -0.02]]
[[ 0.    0.    0.    0.   -0.  ]
 [ 1.    0.    0.04 -0.01 -0.  ]
 [ 0.    0.01 -0.1   0.03 -0.03]
 [-0.1  -0.01  0.07 -0.01 -0.01]
 [-0.11  0.01 -0.09  0.02 -0.03]]
[[-0.02 -0.06  0.19 -0.08 -0.  ]
 [ 0.06  0.1  -0.64  0.14  0.03]
 [-0.09 -0.01 -0.45 -0.08 -0.04]
 [ 0.08 -0.07  1.17  0.    0.03]
 [-0.03  0.05 -0.28  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -2.96e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -5.69e-02  5.89e-03]
 [ 0.00e+00  0.00e+00  5.68e-01  4.90e-02  3.10e-01]
 [ 0.00e+00  1.82e-03  6.79e-02 -6.10e-04 -3.31e-03]
 [ 2.40e-01 -4.87e-02  6.50e-03  5.87e-03  8.87e-04]]
[[-0.02  0.02  0.29 -0.04 -0.01]
 [ 0.31 -0.6  -0.54 -0.49  0.36]
 [-0.72  2.69 -2.25  2.48 -0.76]
 [ 0.38 -0.91 -0.11 -0.66  0.35]
 [-0.03  0.14  0.09  0.06 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.29e-01]
 [ 0.00e+00  1.00e+00  0.00e+00  1.47e-03  1.76e-03]
 [ 0.00e+00  0.00e+00  1.03e-03 -3.78e-03 -1.16e-03]
 [ 0.00e+00 -1.43e-03 -5.67e-03  8.83e-04  2.09e-03]
 [ 2.12e-03 -2.88e-01 -2.33e-03  2.20e-03  8.93e-04]]
[[-1.81e-02  1.39e-01  1.63e-03 -1.38e-01  1.82e-02]
 [ 4.28e-02 -3.14e-01 -4.63e-02  3.61e-01 -5.20e-02]
 [ 1.83e-01 -1.93e-01  2.07e+00 -2.55e+00  4.94e-01]
 [ 1.51e-01 -1.18e+00 -8.56e-02  1.27e+00 -1.66e-01]
 [-3.01e-02  2.37e-01  2.66e-02 -2.66e-01  3.48e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.65e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -9.48e-03 -5.69e-02]
 [ 1.00e+00  0.00e+00  1.65e-01  9.35e-03  2.40e-03]
 [ 0.00e+00  3.39e-03  6.30e-03 -9.37e-04  3.99e-02]
 [ 3.63e-04 -6.60e-03  4.39e-01  2.36e-03  1.39e-01]]
[[ 0.08  0.11 -0.45  0.1   0.08]
 [-0.35 -0.15  2.3  -0.13 -0.35]
 [ 0.81 -1.   -2.09 -1.03  0.81]
 [-0.5   0.45  1.4   0.49 -0.51]
 [ 0.13 -0.08 -0.17 -0.09  0.13]]
SymNet parameters
[[-3.51e-07 -2.18e-07  1.30e-06  1.50e-07 -3.34e-07 -8.94e-07  1.25e-07  5.46e-07
   1.20e-06 -4.23e-07  2.44e-07 -3.04e-09]
 [-2.26e-07 -2.81e-07  8.59e-07 -6.09e-07 -3.98e-07  5.14e-07 -3.41e-07  7.96e-07
   4.80e-07  9.86e-08  8.95e-07 -1.30e-07]]
SymNet parameters
[4.85e-08 9.59e-09]
SymNet parameters
[[ 1.29e-04  3.46e-04  9.94e-01 -5.34e-04 -2.45e-03  2.71e-04  2.62e-04 -2.71e-04
  -6.19e-04 -8.46e-05 -1.93e-05 -2.03e-04  1.99e-07]
 [-7.89e-04 -2.19e-04 -4.18e-04 -1.71e-04  1.64e-04 -2.44e-05 -9.90e-01  5.39e-03
   6.36e-04  5.30e-04  2.59e-04 -2.10e-04 -3.30e-07]]
SymNet parameters
[-2.08e-05  6.16e-04]
SymNet parameters
[[ 6.58e-04 -9.91e-01 -1.53e-03  6.32e-04  4.18e-03  8.60e-04  4.20e-05 -4.55e-04
   6.05e-04  1.21e-04 -6.83e-04  3.23e-04  8.56e-08 -7.94e-04]
 [-9.87e-01  2.84e-03  3.09e-04 -1.05e-03  6.29e-04  3.47e-04 -1.19e-03  2.15e-04
   1.37e-04  2.15e-04 -1.21e-04  2.54e-04  2.96e-07 -8.31e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 3.08e-12 -7.01e-11  6.28e-12  6.05e-11  1.89e-10  2.28e-10 -1.72e-13  1.70e-11
   3.75e-11  2.01e-10 -5.70e-11 -1.06e-10  7.41e-12  6.68e-12 -4.10e-12]
 [-1.82e-14 -2.20e-11 -7.35e-12 -7.59e-10 -1.84e-10 -2.82e-10  1.52e-11 -1.26e-11
  -9.17e-11 -1.48e-10  1.69e-10 -3.77e-11 -6.52e-12 -4.16e-11  1.10e-10]]
SymNet parameters
[ 9.26e-12 -4.17e-12]
SymNet parameters
[[ 3.65e-12 -7.33e-11  9.42e-12 -1.34e-10  1.49e-11  8.72e-12 -7.85e-12 -1.38e-11
   3.98e-11  1.08e-11 -3.88e-11 -3.71e-11 -1.79e-12  5.63e-11 -4.15e-11  4.39e-13]
 [-7.47e-13  2.70e-11  3.68e-12  7.00e-11  1.64e-13 -1.37e-11 -1.96e-12 -4.82e-12
   7.11e-12 -3.70e-11 -5.15e-11 -6.09e-12  5.29e-12  5.77e-11  3.74e-13 -3.14e-12]]
SymNet parameters
[ 9.41e-12 -1.30e-11]
SymNet parameters
[[ 5.85e-03  5.12e-04  6.26e-04  5.08e-02 -6.61e-03  5.33e-02  6.10e-06 -1.97e-03
  -1.01e-03  2.83e-04 -6.81e-05  7.09e-05 -2.66e-07  9.89e-01 -1.00e+00  7.96e-10
   7.83e-11]]
SymNet parameters
[0.]
SymNet parameters
[[-1.77e-03 -2.27e-04 -8.01e-05  2.87e-05  2.15e-04 -7.59e-04 -9.87e-01  6.60e-03
   1.26e-03  6.22e-04  3.75e-04 -1.23e-03]
 [ 7.14e-04 -4.33e-04 -7.05e-04  8.72e-04 -2.27e-04 -2.15e-04 -1.06e-04  7.95e-04
  -9.94e-01  4.65e-04  4.87e-03  6.24e-04]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-5.30e-04  7.67e-04 -4.16e-03  2.32e-04 -2.92e-04  2.17e-04  6.82e-04 -9.84e-01
  -3.49e-04  1.28e-03  3.47e-03  7.92e-04  1.62e-03]
 [-9.90e-01  3.79e-03  7.61e-04  5.34e-04  7.81e-04  3.29e-04  6.30e-04  1.05e-04
  -1.36e-04  2.77e-04  1.00e-04  1.40e-04 -1.00e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 9.42e-12  6.94e-11 -2.18e-11 -2.32e-11 -2.06e-11 -4.30e-11 -9.08e-12 -2.85e-12
  -6.71e-11  7.00e-11  3.86e-11  1.27e-10 -2.91e-10 -1.04e-10]
 [ 3.48e-12  5.42e-11 -1.27e-11  9.81e-11  1.86e-12  4.69e-11 -1.84e-11  4.23e-12
   2.50e-10  8.76e-11 -9.91e-12  1.86e-10  1.28e-10  1.59e-11]]
SymNet parameters
[ 4.22e-12 -4.93e-12]
SymNet parameters
[[-2.25e-12 -9.13e-11 -3.29e-11  2.70e-11 -1.79e-10 -2.33e-10  4.56e-12 -5.10e-12
   7.83e-11  2.00e-10 -7.64e-10 -9.36e-10  3.25e-10 -5.28e-11 -1.15e-11]
 [ 5.59e-12 -7.85e-11  2.36e-11  7.11e-11 -1.12e-10  3.86e-11 -1.22e-11 -4.28e-12
   2.43e-10  2.27e-10 -5.61e-11  1.65e-10  1.63e-10  2.62e-11  2.31e-12]]
SymNet parameters
[2.99e-12 9.34e-13]
SymNet parameters
[[-5.39e-12 -1.21e-10  6.82e-11  6.11e-11  1.22e-10 -1.00e-11  1.88e-11 -1.12e-11
  -2.71e-10 -1.86e-10 -4.78e-11 -1.95e-10 -8.23e-11 -1.05e-10  3.88e-12 -3.34e-12]
 [-3.36e-13  1.58e-11 -3.43e-11 -2.09e-10 -1.03e-10 -2.24e-10  3.46e-12  1.68e-12
  -3.22e-10  1.86e-10  3.44e-11  3.88e-10 -6.22e-10 -1.44e-10  1.31e-11 -4.96e-12]]
SymNet parameters
[ 2.99e-12 -9.76e-12]
SymNet parameters
[[ 4.90e-04  1.04e-03  3.04e-03  7.83e-04 -7.76e-04 -4.82e-04  1.10e-02  9.50e-04
   1.34e-03  5.31e-02 -4.53e-03  5.36e-02 -1.00e+00 -9.97e-01  4.39e-10 -3.55e-10
  -7.61e-10]]
SymNet parameters
[0.]
finally, finish this stage
iter:   271    time: 33.41
Func: 3.28e+00  |g|: 3.70e-03
stableloss: 8.89e-02   dataloss: 2.63e+00   sparseloss: 1.22e+01 momentloss: 1.07e+01
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u11, u10*v01, u00*u11, u01**2, 1, u11*v00, u00*u10, v01, u01*v00, u10, u01*u02, u01, v10, u00*u20]
[-9.79e-01 -9.73e-01  5.33e-02  5.08e-02  8.11e-03  6.83e-03 -6.61e-03  5.30e-03
  4.13e-03  2.81e-03  2.47e-03  2.41e-03 -2.29e-03 -1.97e-03 -1.52e-03  1.23e-03
 -1.04e-03  1.02e-03 -1.01e-03  8.50e-04]
[v00*v10, u00*v01, v20, v02, v00, v01*v10, v10, v00*v11, v11, u00*u10, u01*v01, u00*v11, 1, u10, u00*v10, v01, u00*v00*v10, v00*v01, u00*v00, u00*v02]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.   -0.   -0.    0.    0.    0.    0.
 -0.    0.    0.    0.    0.    0.  ]
block:  12
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  0.575681215545732
current stage is: block-12
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9580, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2666,  1.8215,  1.6889, 20.3805, 13.6146, 19.7254,  0.2653,  1.6520,
         1.7322, 15.1235, 12.1561, 23.6164], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 14.48
Func: 7.91e+00  |g|: 1.41e+02
stableloss: 1.21e-01   dataloss: 7.05e+00   sparseloss: 1.22e+01 momentloss: 1.07e+01
iter:   200    time: 63.96
Func: 6.89e+00  |g|: 1.77e+00
stableloss: 1.19e-01   dataloss: 6.02e+00   sparseloss: 1.22e+01 momentloss: 1.19e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 6.887085
         Iterations: 378
         Function evaluations: 495
         Gradient evaluations: 484
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -4.97e-03 -3.61e-02 -7.79e-02]
 [ 0.00e+00 -6.63e-03  5.64e-02  1.23e-02  1.11e-01]
 [ 2.36e-03 -3.62e-02  8.69e-02  4.51e-04 -8.36e-03]
 [-1.56e-02  3.56e-02 -9.05e-03  1.20e-02  5.63e-02]
 [-3.17e-02 -1.70e-02  8.71e-03 -1.41e-02 -8.01e-03]]
[[-2.03e-02  1.22e-01 -2.08e-01  1.17e-01 -3.39e-02]
 [-2.52e-02  5.46e-02  4.67e-02  1.30e-02  2.55e-02]
 [-3.11e-02  7.97e-02  5.98e-01  3.08e-01 -1.51e-01]
 [-8.34e-05  8.18e-02  5.91e-02 -5.14e-02  5.64e-02]
 [ 1.71e-02 -6.87e-02  4.91e-02 -4.46e-02  7.29e-03]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.19e-01 -1.04e-01]
 [ 0.00e+00  0.00e+00 -6.38e-03  3.76e-03  1.70e-02]
 [ 0.00e+00  5.16e-02 -8.34e-02  9.98e-02 -7.85e-02]
 [ 1.10e-02  7.56e-03 -1.71e-02  4.37e-04 -3.04e-03]
 [ 1.25e-03  3.71e-02 -3.40e-02  1.23e-02 -2.89e-02]]
[[-0.02  0.04 -0.07  0.07 -0.02]
 [-0.05  0.16 -0.04 -0.1   0.04]
 [ 0.16 -0.69 -0.49  1.35 -0.32]
 [-0.03  0.09  0.04 -0.2   0.07]
 [-0.02  0.03 -0.06  0.08 -0.02]]
[[ 0.    0.    0.    0.01 -0.  ]
 [ 1.    0.    0.03 -0.03 -0.02]
 [ 0.   -0.03 -0.06 -0.05 -0.04]
 [-0.1  -0.04  0.07 -0.05 -0.01]
 [-0.09 -0.02 -0.05 -0.01 -0.02]]
[[-0.02 -0.03  0.14 -0.04 -0.01]
 [ 0.05  0.02 -0.59  0.07  0.02]
 [-0.06  0.03 -0.4  -0.07 -0.02]
 [ 0.03 -0.07  1.15 -0.03  0.04]
 [-0.01  0.06 -0.32  0.08 -0.04]]
[[ 0.    0.    1.    0.   -0.37]
 [ 0.    0.    0.   -0.   -0.05]
 [ 0.    0.    0.48  0.    0.47]
 [ 0.    0.04  0.    0.01  0.  ]
 [ 0.06  0.03 -0.01  0.    0.19]]
[[ 0.15 -0.64  1.04 -0.63  0.15]
 [-0.15  1.27 -2.43  1.18 -0.13]
 [-0.39  1.29 -1.59  1.49 -0.42]
 [-0.22  1.59 -2.85  1.42 -0.21]
 [ 0.16 -0.7   1.1  -0.65  0.16]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  9.70e-02]
 [ 0.00e+00  1.00e+00  0.00e+00  8.27e-03 -3.61e-01]
 [ 0.00e+00  0.00e+00  5.34e-04 -1.21e-03 -7.57e-04]
 [ 0.00e+00  9.37e-03 -7.39e-04 -2.60e-03  3.79e-03]
 [ 1.86e-03 -1.74e+00  6.32e-03  8.15e-03 -5.22e-03]]
[[-0.18  1.28 -0.24 -0.96  0.11]
 [ 0.81 -5.34  1.64  3.16 -0.28]
 [-0.83  6.8   0.32 -7.24  0.96]
 [ 0.43 -4.24 -1.3   5.98 -0.87]
 [-0.13  1.12  0.15 -1.32  0.18]]
[[ 0.    0.    0.    0.    0.6 ]
 [ 0.    0.    0.   -0.   -0.01]
 [ 1.    0.    0.2   0.01  0.01]
 [ 0.    0.01  0.03  0.02 -0.  ]
 [-0.    0.05  0.35 -0.   -0.01]]
[[-0.02  0.41 -0.92  0.49 -0.04]
 [ 0.1  -1.47  4.34 -1.8   0.18]
 [ 0.44 -0.22 -3.31  0.23  0.35]
 [ 0.12 -1.57  4.48 -1.84  0.16]
 [-0.04  0.47 -1.01  0.53 -0.04]]
SymNet parameters
[[-1.58e-07 -1.29e-07 -9.44e-07  1.39e-06 -1.37e-06 -1.23e-06  2.15e-07  9.65e-08
   1.17e-06 -6.90e-07  1.24e-06 -3.99e-07]
 [-3.57e-07  1.31e-06 -9.00e-07 -2.92e-09 -7.67e-07 -1.28e-07  1.07e-06 -3.92e-07
   4.10e-07 -1.55e-06 -4.68e-09 -4.97e-07]]
SymNet parameters
[ 6.51e-07 -1.24e-06]
SymNet parameters
[[ 3.09e-04 -3.09e-04  9.88e-01  1.04e-04  1.20e-04  1.13e-04  1.25e-03 -4.49e-03
  -1.50e-03 -1.46e-04 -8.81e-04  8.89e-05  1.22e-06]
 [ 1.06e-04 -1.59e-03  3.57e-04 -1.22e-04  4.69e-04  2.55e-04 -9.91e-01  2.27e-04
  -2.52e-03  4.17e-04 -7.09e-04 -1.99e-04 -1.21e-06]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 7.53e-04 -9.87e-01 -9.57e-04  1.67e-04 -3.51e-03 -5.44e-05 -6.56e-04 -1.56e-03
   4.37e-05  2.91e-04  2.64e-04 -3.31e-04 -6.01e-08 -8.78e-04]
 [-9.88e-01  1.09e-03  1.57e-04 -3.75e-04 -8.88e-04  5.42e-04  1.10e-03  2.79e-04
   2.20e-03  8.20e-04 -3.85e-04 -3.09e-04  8.69e-07 -5.18e-03]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 2.23e-08 -1.06e-06  8.42e-08  5.74e-07  1.87e-06 -5.96e-08  1.47e-08  3.78e-08
   1.76e-07 -6.65e-07 -1.72e-06 -3.68e-07  3.56e-10  1.40e-09 -1.49e-06]
 [ 1.25e-08 -2.77e-07  2.60e-08  4.75e-08  2.18e-06 -3.34e-07  8.92e-09  1.04e-07
  -2.64e-07  7.79e-07 -1.95e-06 -4.05e-07 -2.95e-10  2.49e-07 -1.69e-06]]
SymNet parameters
[1.24e-09 3.38e-09]
SymNet parameters
[[ 1.64e-08 -3.69e-07  1.51e-08 -1.06e-06  9.52e-07  6.32e-07  1.00e-09 -5.26e-09
   8.66e-08 -6.81e-08  8.96e-07  5.91e-07 -9.27e-11 -3.44e-08  2.64e-06  2.59e-12]
 [-1.95e-08  1.49e-08 -4.40e-09  1.80e-06 -3.63e-07 -1.44e-06 -8.50e-09 -1.25e-08
   9.08e-08 -6.07e-07  2.47e-07  2.22e-07  2.58e-10  2.83e-08 -9.45e-08 -1.57e-10]]
SymNet parameters
[-7.31e-09  4.19e-09]
SymNet parameters
[[ 1.94e-03 -2.92e-03  2.52e-03  5.29e-02  1.59e-03  5.16e-02 -3.50e-04  1.91e-03
  -2.39e-04  1.38e-03 -9.71e-05 -2.49e-05  1.91e-07  9.91e-01 -1.00e+00 -3.71e-07
  -5.81e-07]]
SymNet parameters
[0.]
SymNet parameters
[[ 5.61e-04  7.17e-04  4.04e-04 -5.86e-04  7.41e-04  3.37e-04 -9.95e-01  7.15e-04
  -1.05e-03  5.89e-04 -1.00e-03 -1.73e-03]
 [ 4.92e-05 -1.64e-03  9.15e-04  3.35e-04  1.34e-03 -1.71e-04  1.92e-03  1.50e-04
  -9.92e-01  5.82e-04  4.88e-05  1.77e-04]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-7.33e-04  1.17e-03 -1.27e-03  1.63e-04  5.81e-04  5.00e-06 -4.25e-05 -9.86e-01
  -8.67e-04 -1.36e-04 -3.73e-03  3.74e-04  7.42e-04]
 [-9.86e-01 -2.25e-04 -1.72e-03  1.03e-03 -1.03e-03  1.58e-04  2.92e-04  7.67e-04
   5.15e-04  6.70e-04  6.57e-04 -4.08e-04  3.38e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-1.83e-08 -8.67e-07 -3.45e-07  2.94e-06  1.42e-06  1.85e-07  3.16e-09 -1.07e-07
  -5.80e-07  1.58e-06  2.94e-06 -2.57e-06  8.79e-07  3.06e-07]
 [-1.76e-08 -7.08e-07 -3.75e-07  1.20e-06 -5.49e-08 -4.35e-07 -3.12e-09 -1.04e-07
  -1.21e-06  1.34e-07  2.37e-06 -5.27e-06  1.61e-06  1.11e-07]]
SymNet parameters
[5.88e-09 2.35e-09]
SymNet parameters
[[-2.46e-08 -6.73e-07 -1.41e-07 -7.33e-07  2.71e-06 -1.16e-07  1.26e-08 -5.05e-08
  -7.71e-07  9.04e-07 -2.52e-06 -2.04e-06 -1.37e-06 -4.29e-07 -5.48e-10]
 [-2.81e-09 -8.83e-08  7.88e-08  2.53e-06  2.25e-07 -5.86e-07 -3.90e-09 -5.22e-08
  -1.82e-06  1.50e-06 -9.51e-07 -9.20e-07 -6.06e-07 -1.99e-06  1.10e-10]]
SymNet parameters
[ 2.67e-09 -6.58e-09]
SymNet parameters
[[-2.07e-09  1.68e-07  2.07e-07  4.91e-07 -2.81e-07 -1.60e-06  1.09e-08  6.76e-08
   2.22e-06 -2.10e-06 -6.61e-07  2.41e-06  2.58e-07  1.06e-06  1.86e-10 -2.03e-10]
 [ 2.97e-09  1.70e-07 -2.73e-08  4.06e-07  1.41e-06  1.43e-06  1.29e-08  4.39e-08
   2.69e-07  3.56e-06 -1.10e-07 -3.02e-08  4.85e-07  7.30e-07  6.12e-10 -2.18e-10]]
SymNet parameters
[ 1.25e-08 -1.64e-09]
SymNet parameters
[[ 3.59e-04 -2.63e-03  1.65e-03  5.52e-04  2.88e-04  2.24e-04  8.75e-03  1.46e-04
   6.20e-04  5.56e-02  2.45e-03  5.10e-02 -9.93e-01 -9.96e-01 -3.57e-06  9.61e-07
   2.12e-06]]
SymNet parameters
[0.]
finally, finish this stage
iter:   378    time: 81.60
Func: 6.89e+00  |g|: 3.31e-02
stableloss: 1.19e-01   dataloss: 6.00e+00   sparseloss: 1.22e+01 momentloss: 1.29e+01
current expression:
[u00*u01, u10*v00, u02, u20, u00, u01*u10*v00, v00*v01, u01, u00*u11, u10, u10*v10, 1, u01*v10, v01, u11, u00*v01, v00*v10, u01*u10, u01*v00, v02]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.   -0.   -0.    0.   -0.    0.    0.    0.
  0.   -0.    0.   -0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00, u00*v11, v00*v01*v10, 1, u01, v11, v00**2, v10*v20, u10*v01, u10, u01*v00, u11*v00, u00*u10, v10, v01*v10, u00*u01]
[-0.98 -0.97  0.06  0.05  0.01 -0.    0.    0.   -0.    0.    0.   -0.   -0.    0.
 -0.    0.   -0.    0.    0.    0.  ]
block:  15
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -1.056247306307692
current stage is: block-15
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8569, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2798,  1.9462,  1.8129, 41.7534, 36.4928, 25.1241,  0.2683,  1.7986,
         1.8126, 27.7634, 50.8704, 24.9601], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 17.16
Func: 1.31e+01  |g|: 2.55e+02
stableloss: 1.82e-01   dataloss: 1.19e+01   sparseloss: 1.22e+01 momentloss: 1.29e+01
iter:   200    time: 87.72
Func: 1.10e+01  |g|: 8.33e+00
stableloss: 1.72e-01   dataloss: 9.75e+00   sparseloss: 1.33e+01 momentloss: 1.49e+01
iter:   400    time: 80.89
Func: 1.09e+01  |g|: 6.36e+00
stableloss: 1.72e-01   dataloss: 9.60e+00   sparseloss: 1.39e+01 momentloss: 1.58e+01
iter:   600    time: 100.43
Func: 1.09e+01  |g|: 8.51e-01
stableloss: 1.72e-01   dataloss: 9.61e+00   sparseloss: 1.38e+01 momentloss: 1.51e+01
iter:   800    time: 86.91
Func: 1.09e+01  |g|: 9.07e-01
stableloss: 1.72e-01   dataloss: 9.60e+00   sparseloss: 1.37e+01 momentloss: 1.51e+01
iter:  1000    time: 78.18
Func: 1.09e+01  |g|: 4.45e-02
stableloss: 1.73e-01   dataloss: 9.60e+00   sparseloss: 1.37e+01 momentloss: 1.51e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 10.860057
         Iterations: 1003
         Function evaluations: 1171
         Gradient evaluations: 1158
convolution moment and kernels
[[ 1.    0.   -0.01  0.03 -0.05]
 [ 0.    0.01 -0.01  0.01 -0.  ]
 [ 0.01 -0.02  0.03  0.03 -0.02]
 [ 0.02  0.02  0.06  0.05  0.02]
 [-0.03  0.   -0.01  0.   -0.01]]
[[-0.    0.01 -0.06  0.05 -0.03]
 [-0.01  0.11  0.06 -0.08  0.07]
 [-0.03  0.02  0.71  0.2  -0.09]
 [-0.    0.04  0.08 -0.01 -0.  ]
 [-0.01  0.04 -0.07  0.01  0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.11e-01 -8.90e-02]
 [ 0.00e+00  0.00e+00 -4.27e-03 -2.56e-02 -1.25e-02]
 [ 0.00e+00  6.07e-02 -8.57e-02  9.89e-02 -6.48e-02]
 [ 5.13e-04 -1.67e-04  4.61e-02 -4.40e-03  2.34e-02]
 [-3.51e-03 -6.90e-03 -2.64e-02  2.03e-02 -2.20e-02]]
[[-3.29e-02  8.08e-02 -7.36e-02  4.07e-02 -1.88e-02]
 [ 7.65e-03 -8.98e-02  1.16e-01 -7.18e-02  5.28e-02]
 [ 1.21e-01 -4.62e-01 -5.17e-01  1.09e+00 -2.49e-01]
 [-3.50e-02  8.18e-03 -2.18e-02  7.74e-02 -1.52e-02]
 [-1.13e-02  4.12e-02 -3.70e-02  1.08e-03  2.77e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00 -2.60e-03 -7.13e-03]
 [ 1.00e+00  0.00e+00  4.91e-02  1.29e-02  5.15e-03]
 [ 0.00e+00  3.91e-03 -1.00e-01  2.33e-02 -3.44e-02]
 [-1.17e-01 -3.40e-04  7.39e-02  1.61e-02  1.12e-02]
 [-9.31e-02  1.15e-03 -8.32e-02  2.02e-02 -2.93e-02]]
[[-0.03 -0.01  0.13 -0.03 -0.02]
 [ 0.08 -0.04 -0.54  0.05  0.04]
 [-0.11  0.12 -0.52 -0.01 -0.05]
 [ 0.08 -0.1   1.14  0.01  0.02]
 [-0.03  0.05 -0.26  0.   -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  1.01e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  9.19e-03 -1.04e+00]
 [ 0.00e+00  0.00e+00  8.28e-01 -4.47e-03  3.59e-01]
 [ 0.00e+00  3.44e-03  5.91e-03 -6.58e-05  1.22e-01]
 [-3.08e-01  3.05e-02  6.88e-03 -5.71e-02  1.71e-03]]
[[-0.14  0.54 -1.2   0.69 -0.2 ]
 [ 1.08 -3.41  6.25 -4.    1.31]
 [-0.52  1.32 -4.    2.23 -0.88]
 [-0.56  3.11 -3.5   2.49 -0.31]
 [ 0.16 -0.63  0.56 -0.48  0.09]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  9.89e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  8.47e-03 -1.21e-03]
 [ 0.00e+00  0.00e+00  6.59e-03  1.39e-03 -4.25e-03]
 [ 0.00e+00  8.30e-03  4.47e-03 -1.77e-03 -5.40e-03]
 [-1.75e-01 -1.80e+00 -2.27e-03  2.74e-03  5.81e-02]]
[[-0.08  0.9   0.2  -1.4   0.21]
 [ 0.31 -3.39 -0.81  5.39 -0.8 ]
 [-0.54  5.71  1.24 -8.74  1.28]
 [ 0.42 -4.3  -0.73  6.2  -0.89]
 [-0.1   1.03  0.16 -1.48  0.21]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.31e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  5.04e-02  1.10e+00]
 [ 1.00e+00  0.00e+00 -2.60e-03 -6.73e-02  6.94e-03]
 [ 0.00e+00  3.92e-03 -1.60e-01  3.87e-04 -1.93e-01]
 [ 4.17e-01  1.70e-01  4.13e-01  7.83e-04  1.48e-01]]
[[ 0.3  -0.79  1.12 -0.59  0.29]
 [-1.35  3.95 -4.87  3.3  -1.37]
 [ 0.66 -0.67 -0.99  0.34  0.66]
 [ 0.44 -2.98  5.47 -3.77  0.5 ]
 [-0.06  0.5  -0.74  0.72 -0.08]]
SymNet parameters
[[-4.36e-07  2.69e-07  5.77e-07  2.03e-08  4.57e-07  6.74e-08 -6.95e-08  2.00e-07
  -2.87e-08 -1.70e-07 -7.54e-08  3.14e-07]
 [-1.28e-07  5.10e-07  7.70e-09 -2.58e-07 -4.68e-07 -2.77e-07 -5.35e-07 -1.18e-07
  -1.32e-08  4.52e-08 -7.86e-08 -9.47e-08]]
SymNet parameters
[ 2.7e-07 -1.2e-07]
SymNet parameters
[[ 7.14e-04  8.18e-04  9.85e-01 -5.82e-04 -9.27e-04  3.46e-04  1.44e-03 -7.56e-04
  -2.06e-04  5.15e-04 -1.02e-03  8.86e-04 -1.81e-07]
 [ 2.37e-04 -2.77e-05  4.13e-04  3.99e-04 -1.61e-04 -4.39e-05 -9.98e-01  6.81e-04
   2.16e-04  6.31e-04 -4.30e-04  6.29e-04 -2.75e-07]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-1.54e-03 -9.83e-01  6.33e-05  4.49e-04  1.93e-03 -3.89e-04 -8.55e-04 -4.27e-04
   3.06e-03  1.79e-03  1.65e-05 -2.19e-03 -3.35e-08  2.78e-03]
 [-9.92e-01  1.96e-03 -3.66e-04 -8.18e-04 -1.68e-04  5.33e-04  4.15e-03  8.18e-04
   1.24e-03  4.38e-04  4.85e-05  2.09e-04 -2.77e-07 -6.78e-03]]
SymNet parameters
[0.01 0.  ]
SymNet parameters
[[ 8.34e-08  5.61e-08  1.82e-07  3.51e-07 -5.79e-07  3.44e-07  5.87e-08 -1.53e-07
  -1.09e-07 -1.75e-07  8.48e-08 -5.84e-09  1.91e-07 -2.32e-08 -1.14e-07]
 [ 3.20e-08  1.28e-07  1.77e-08 -3.49e-07  3.59e-07 -3.22e-08 -1.31e-07  2.91e-07
  -1.82e-07 -8.91e-08  2.67e-07 -3.03e-08  2.11e-08  2.99e-08  4.63e-07]]
SymNet parameters
[ 6.04e-08 -2.42e-07]
SymNet parameters
[[ 2.33e-07  5.48e-08 -6.34e-09  3.43e-07 -2.49e-07 -1.69e-07  7.45e-08 -1.73e-07
   8.56e-08  1.97e-07  6.46e-09  2.16e-08 -5.84e-08 -1.23e-07  8.11e-08 -1.11e-07]
 [ 1.77e-07 -1.52e-07  3.99e-08 -2.82e-07 -2.58e-07 -1.46e-08  7.98e-10 -1.30e-07
   3.77e-08 -1.15e-07 -2.12e-08  1.86e-07 -1.02e-07 -4.46e-08  1.85e-07 -2.87e-07]]
SymNet parameters
[-2.63e-09 -1.26e-07]
SymNet parameters
[[ 2.48e-03  5.02e-04  2.31e-04  5.21e-02  5.37e-03  5.23e-02  1.17e-03  1.71e-03
  -1.14e-03 -2.35e-04 -3.62e-04  3.69e-04  7.60e-08  9.85e-01 -1.01e+00  6.10e-08
   3.30e-07]]
SymNet parameters
[-0.]
SymNet parameters
[[-9.12e-04 -9.49e-05 -3.36e-04  8.65e-04 -9.39e-05 -6.03e-04 -7.17e-01 -5.30e-01
   8.10e-04  2.81e-04  6.20e-04 -1.89e-04]
 [-6.01e-01 -1.51e-04 -1.08e-03  3.87e-04  9.85e-04  6.51e-04 -5.03e-05  1.51e-05
  -6.62e-01  1.33e-04  2.94e-04 -6.96e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 2.20e-03 -9.14e-04 -4.46e-04  4.30e-04  1.31e-04 -7.74e-04  5.81e-01 -6.37e-01
   2.77e-03  6.10e-04  2.04e-03 -3.16e-04 -1.29e-02]
 [-7.16e-01  5.96e-04 -4.78e-04  5.92e-05 -9.17e-04  5.02e-04  1.32e-03 -1.26e-04
   5.36e-01 -4.47e-04 -1.18e-03  5.26e-04  4.45e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-1.11e-07 -1.02e-07  6.72e-08  7.94e-08 -3.51e-07 -4.46e-08 -1.02e-07  1.47e-07
  -3.13e-07 -2.89e-07 -1.85e-08 -1.82e-07 -8.46e-08 -3.89e-07]
 [-2.29e-07  5.74e-08 -9.26e-08  1.07e-07  5.79e-08  5.01e-08 -8.17e-08  5.64e-08
  -1.32e-07 -3.17e-07 -1.20e-07  3.51e-07  1.66e-07  4.81e-07]]
SymNet parameters
[-8.69e-09  9.45e-08]
SymNet parameters
[[-2.17e-07  4.57e-08 -9.26e-08 -1.73e-07  1.15e-07 -8.76e-08 -1.98e-07  8.58e-08
   1.00e-07  1.27e-07 -1.36e-07 -6.10e-08  3.93e-07  3.70e-07 -1.37e-07]
 [ 9.46e-08  5.63e-08  4.30e-08  1.02e-07 -1.24e-07  2.39e-07  5.36e-08  1.59e-08
  -6.56e-07 -4.24e-08 -8.58e-08 -4.57e-08 -6.35e-08  4.32e-09  5.27e-07]]
SymNet parameters
[7.64e-08 7.19e-08]
SymNet parameters
[[-1.39e-07 -3.55e-07 -1.18e-07 -9.51e-08  5.68e-08  1.34e-07 -2.23e-07 -1.46e-07
  -2.93e-07  2.60e-07 -1.84e-07  2.66e-08  2.84e-07 -2.28e-07  2.11e-07 -7.57e-08]
 [-6.78e-08  2.84e-08  1.11e-07 -1.65e-08 -1.66e-07 -2.54e-07 -7.85e-08  3.66e-07
   1.54e-07  5.81e-07 -2.21e-07 -1.41e-07 -2.40e-07  2.73e-07 -3.91e-07 -1.94e-07]]
SymNet parameters
[ 1.34e-07 -2.05e-07]
SymNet parameters
[[ 3.72e-04  2.91e-04  4.74e-04 -4.96e-04 -1.20e-03 -4.28e-05  6.16e-03 -2.99e-04
  -9.68e-04  5.21e-02  4.80e-03  5.16e-02 -1.23e+00 -1.28e+00  2.38e-07  3.78e-07
   1.81e-07]]
SymNet parameters
[-0.]
finally, finish this stage
iter:  1003    time: 11.53
Func: 1.09e+01  |g|: 3.35e-02
stableloss: 1.73e-01   dataloss: 9.60e+00   sparseloss: 1.37e+01 momentloss: 1.51e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00, u01*u10*v00, u11, u01*v00, u00*v10, u00*u10*v00, 1, u00*v20, v00, u01**2, u00*u11, u00*v02, v01, u00*v00, u00**2, v00**2]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.    0.   -0.   -0.   -0.    0.    0.
  0.    0.    0.   -0.   -0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00, u00**2*v00, v11, v00*v10**2, v01*v10, u00**2*v01, v01, v10, v01*v10**2, u00, u00*v11, u00*v00*v10, v00**2*v10, u11*v00, 1, u00*v00**2]
[-0.98 -0.97  0.05  0.05  0.01 -0.01  0.    0.    0.   -0.   -0.   -0.    0.    0.
  0.   -0.   -0.    0.   -0.   -0.  ]
block:  18
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -0.13582620691182024
current stage is: block-18
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8334, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2515,  1.7187,  1.5790, 29.7530, 28.7486, 26.0421,  0.2681,  1.7101,
         1.8493, 23.3138, 50.0643, 23.3550], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 21.70
Func: 1.65e+01  |g|: 4.86e+02
stableloss: 1.65e-01   dataloss: 1.50e+01   sparseloss: 1.37e+01 momentloss: 1.51e+01
iter:   200    time: 105.49
Func: 1.42e+01  |g|: 3.14e+01
stableloss: 1.74e-01   dataloss: 1.27e+01   sparseloss: 1.39e+01 momentloss: 1.42e+01
iter:   400    time: 129.33
Func: 1.41e+01  |g|: 4.70e+00
stableloss: 1.74e-01   dataloss: 1.26e+01   sparseloss: 1.37e+01 momentloss: 1.60e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 14.088871
         Iterations: 538
         Function evaluations: 713
         Gradient evaluations: 698
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.04e-02 -7.53e-04 -1.36e-02]
 [ 0.00e+00 -1.96e-02 -2.81e-02 -1.96e-02 -1.48e-02]
 [ 2.18e-03  2.82e-03  3.77e-02  1.48e-03 -1.09e-02]
 [-2.66e-02 -2.53e-02 -6.71e-02 -6.75e-03 -2.16e-02]
 [-3.21e-02 -2.49e-03  9.07e-03  7.51e-03 -1.29e-03]]
[[ 0.    0.02 -0.06  0.01  0.01]
 [-0.01  0.02  0.06  0.06 -0.03]
 [-0.01 -0.06  1.01 -0.17  0.03]
 [ 0.02  0.02  0.02  0.13 -0.02]
 [-0.01  0.02 -0.04 -0.01 -0.  ]]
[[ 0.    1.    0.   -0.11 -0.08]
 [ 0.    0.   -0.02 -0.02 -0.03]
 [ 0.    0.06 -0.09  0.09 -0.07]
 [ 0.    0.01  0.01 -0.01 -0.01]
 [-0.    0.01 -0.03  0.01 -0.02]]
[[-0.02  0.04 -0.04  0.03 -0.01]
 [-0.02  0.    0.07 -0.09  0.05]
 [ 0.15 -0.6  -0.46  1.14 -0.26]
 [-0.04  0.05  0.02 -0.03  0.02]
 [-0.02  0.06 -0.09  0.06 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  5.16e-03  3.56e-03]
 [ 1.00e+00  0.00e+00  5.75e-02  2.30e-03  1.39e-02]
 [ 0.00e+00 -1.88e-02 -9.25e-02 -5.40e-03 -2.86e-02]
 [-1.12e-01 -1.72e-02  7.39e-02  5.18e-03  8.95e-03]
 [-8.90e-02 -1.59e-02 -7.81e-02 -9.04e-04 -2.79e-02]]
[[-0.02 -0.02  0.13 -0.02 -0.02]
 [ 0.06 -0.01 -0.54  0.02  0.05]
 [-0.08  0.1  -0.5   0.01 -0.06]
 [ 0.07 -0.14  1.19 -0.05  0.05]
 [-0.02  0.06 -0.27  0.02 -0.02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -9.33e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.50e-02  7.38e-02]
 [ 0.00e+00  0.00e+00  8.89e-01 -9.32e-05  4.17e-01]
 [ 0.00e+00  6.30e-03 -8.48e-03 -8.32e-03 -8.06e-03]
 [ 8.98e-03  5.12e-03  1.07e-03 -4.35e-02  6.06e-03]]
[[ 7.68e-03 -5.96e-02  6.98e-02  2.42e-02 -3.32e-02]
 [ 2.88e-01 -1.49e-01 -1.21e-01 -5.19e-01  4.66e-01]
 [-1.71e+00  5.86e+00 -8.54e+00  6.42e+00 -1.97e+00]
 [ 4.01e-01 -5.80e-01  5.24e-01 -9.60e-01  5.78e-01]
 [-8.54e-03  5.48e-04 -3.11e-02  1.04e-01 -5.63e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.44e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  7.73e-03  5.11e-01]
 [ 0.00e+00  0.00e+00 -5.34e-03  1.37e+00  2.35e-04]
 [ 0.00e+00  7.59e-01 -5.61e-03  1.64e-03 -3.55e-01]
 [-2.16e-01 -1.46e+00  4.52e-03  3.70e-03  9.31e-04]]
[[ 0.13  0.18  1.09 -1.93  0.31]
 [-1.11  0.62 -3.26  4.89 -0.29]
 [ 0.98  2.45 -1.34 -2.41 -0.97]
 [ 0.27 -4.8   5.07 -0.79  1.12]
 [-0.26  1.54 -1.54  0.22 -0.18]]
[[ 0.    0.    0.    0.    0.94]
 [ 0.    0.    0.   -0.01  0.  ]
 [ 1.    0.    0.   -0.01  0.01]
 [ 0.    0.06 -0.12 -0.01 -0.03]
 [ 0.1  -0.04  0.47 -0.    0.19]]
[[ 1.50e-01 -4.75e-02 -1.04e-01 -1.54e-01  1.67e-01]
 [-5.79e-01  2.51e-01  1.33e+00  5.79e-01 -6.32e-01]
 [ 1.78e+00 -4.24e+00  3.28e+00 -4.59e+00  1.84e+00]
 [-5.48e-01  3.95e-01  1.15e+00  5.17e-01 -5.60e-01]
 [ 1.38e-01 -1.30e-01 -2.60e-04 -1.27e-01  1.32e-01]]
SymNet parameters
[[ 8.73e-06 -1.30e-05 -2.37e-05  6.78e-06 -9.41e-06 -8.89e-06  4.59e-06 -1.83e-05
   7.31e-06 -1.01e-05 -2.99e-06 -9.27e-06]
 [-3.48e-06  8.40e-08  1.54e-05  5.20e-07 -4.82e-06 -6.67e-06 -6.97e-07  1.45e-06
   6.78e-06  1.83e-05 -6.80e-06  9.47e-06]]
SymNet parameters
[-1.63e-06  7.80e-06]
SymNet parameters
[[ 1.20e-04 -8.98e-04  9.85e-01  6.29e-04  1.80e-04  1.26e-03 -1.01e-03  1.52e-03
   7.56e-04  4.23e-05 -1.17e-03 -5.77e-04 -1.47e-07]
 [ 4.76e-04 -7.51e-04  2.30e-04 -3.73e-04  6.63e-04 -8.43e-05 -9.78e-01 -2.97e-03
  -1.03e-03 -6.66e-04 -3.42e-05  1.58e-04 -4.70e-06]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.16e-03 -9.40e-01 -2.26e-03 -3.69e-04  2.91e-04 -1.76e-04 -1.94e-04 -1.18e-03
   6.42e-04 -2.16e-04 -9.52e-04  2.59e-04 -2.11e-05  5.66e-04]
 [-9.63e-01 -9.41e-04  1.62e-03 -1.73e-03  3.87e-04  8.81e-04 -2.24e-03 -8.41e-04
   3.67e-04  3.71e-04  1.61e-05 -5.18e-04  4.81e-06 -8.00e-03]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 3.09e-06 -2.19e-05  3.68e-06  1.64e-06  1.06e-05  1.71e-06 -1.00e-06 -2.49e-05
  -4.06e-05 -1.22e-06  2.20e-05 -1.07e-05  2.62e-06 -2.25e-05  3.19e-06]
 [ 3.33e-07  2.86e-06 -5.64e-06  9.02e-07  3.62e-06  1.14e-05 -1.44e-06 -7.86e-06
  -3.55e-06 -3.27e-05 -1.03e-05 -1.35e-05  8.17e-07  3.76e-07  5.86e-07]]
SymNet parameters
[ 3.15e-06 -1.46e-06]
SymNet parameters
[[ 5.40e-06  1.94e-05 -1.70e-06 -8.28e-06 -6.27e-06  3.27e-06  3.35e-06  6.72e-06
   7.61e-06  5.75e-06 -9.50e-06  5.67e-06 -8.94e-07  1.38e-05  1.75e-05 -1.29e-06]
 [ 3.34e-06 -6.82e-06 -6.82e-06  7.97e-06 -2.06e-05  8.87e-06  4.46e-06  3.13e-05
  -1.65e-05 -6.79e-06 -1.10e-05 -1.11e-05 -2.57e-06 -2.89e-05 -1.33e-05 -4.40e-06]]
SymNet parameters
[-1.40e-06 -3.57e-06]
SymNet parameters
[[ 8.30e-04 -5.95e-04 -9.96e-05  5.04e-02 -2.96e-03  5.37e-02  3.16e-04 -8.16e-04
   1.93e-03 -4.50e-05 -9.95e-05  3.18e-04 -3.15e-06  1.01e+00 -1.08e+00 -1.01e-05
  -1.57e-05]]
SymNet parameters
[-0.]
SymNet parameters
[[-1.10e-02 -1.48e-03 -3.02e-03 -7.12e-05 -1.07e-03 -2.04e-04 -5.37e-01 -7.04e-01
   1.44e-02 -6.71e-04  9.73e-04 -5.57e-04]
 [-8.76e-01 -9.48e-04 -6.40e-04 -4.94e-04  8.13e-04  2.49e-04  2.93e-04 -2.66e-04
  -4.03e-01 -1.95e-04  4.71e-04 -9.52e-04]]
SymNet parameters
[-0.    0.01]
SymNet parameters
[[ 1.58e-02  3.29e-04 -9.20e-04  2.48e-04 -8.35e-04  2.51e-04  8.23e-01 -3.78e-01
   5.53e-03  6.72e-04  1.62e-03  8.22e-04 -1.07e-02]
 [-5.03e-01  1.26e-04  8.68e-04  1.32e-04 -6.73e-04  3.97e-04 -9.81e-04  1.41e-03
   6.67e-01  3.87e-04  1.38e-03  6.24e-04  8.95e-05]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 1.69e-05 -1.57e-05 -6.94e-07  8.26e-06 -1.02e-06 -8.77e-06 -5.52e-06 -2.80e-06
   1.92e-05  1.82e-06 -5.05e-06  3.34e-05 -5.99e-07 -5.35e-06]
 [ 1.27e-05  2.95e-05 -1.50e-06 -1.70e-05  3.50e-06  2.78e-06 -5.16e-06 -4.12e-06
   8.16e-06  1.29e-05 -7.79e-06  5.53e-06  5.92e-07 -1.42e-07]]
SymNet parameters
[-9.53e-07  2.34e-06]
SymNet parameters
[[-1.26e-05  1.69e-05 -4.45e-06  1.85e-06 -1.24e-06  1.06e-05 -3.01e-06  2.74e-06
   2.54e-06 -1.55e-06 -8.31e-06 -1.87e-06 -4.71e-05  1.25e-05 -2.93e-06]
 [ 3.24e-05  2.96e-05 -1.10e-06 -1.25e-05 -4.08e-05 -1.05e-06 -3.12e-06 -7.19e-06
   4.23e-06 -6.99e-05  3.52e-05 -4.70e-05 -4.90e-05 -1.50e-05  8.52e-06]]
SymNet parameters
[ 2.13e-06 -4.60e-07]
SymNet parameters
[[-8.31e-07  1.12e-05  1.52e-06 -1.07e-06 -8.47e-06 -3.82e-06 -4.08e-06 -4.09e-06
  -1.78e-05  2.35e-06 -2.16e-05  7.57e-06  4.47e-05  1.31e-05  2.38e-06 -1.74e-06]
 [ 8.63e-06  2.57e-05 -3.28e-06 -7.01e-06  2.95e-06  3.73e-06 -3.51e-06 -3.17e-07
   2.49e-05  1.16e-05  2.76e-05  2.94e-06  2.42e-05 -1.02e-05 -5.83e-06 -3.54e-06]]
SymNet parameters
[ 1.75e-06 -3.22e-06]
SymNet parameters
[[-5.50e-04 -4.44e-04  6.94e-04 -1.33e-04  6.88e-05  1.04e-04  6.04e-03  3.47e-04
  -1.68e-04  5.20e-02 -2.38e-03  5.19e-02 -1.17e+00 -1.33e+00  1.93e-05  2.56e-06
   7.26e-07]]
SymNet parameters
[0.]
finally, finish this stage
iter:   538    time: 113.50
Func: 1.41e+01  |g|: 1.27e+00
stableloss: 1.74e-01   dataloss: 1.26e+01   sparseloss: 1.37e+01 momentloss: 1.64e+01
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u11, u10*v01, v10, u00*u10, u01*u02, v00*v01, u01*v00, u20*v00, u00*v01, u00**2, u01, v00*v11, u10*v10, v00**2]
[-0.98 -0.97  0.05  0.05  0.01  0.01 -0.   -0.    0.   -0.   -0.   -0.   -0.   -0.
 -0.   -0.   -0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00, u00**2*v01, v01, u00*v01*v10, u00*u10, u00**2*v00, u00*v00*v10, v01*v10**2, v11, v01*v10, v00*v10**2, u00*v11, v00*v01, v10**2, u00*u11, u00]
[-0.98 -0.97  0.05  0.05  0.01 -0.    0.    0.   -0.   -0.    0.    0.   -0.    0.
  0.    0.   -0.    0.   -0.   -0.  ]
block:  21
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -0.07246404192265038
current stage is: block-21
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8331, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2476,  1.6501,  1.5721, 69.0621, 17.0425, 29.2742,  0.2528,  1.6627,
         1.6552, 43.8168, 19.8057, 22.0710], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 22.08
Func: 2.80e+01  |g|: 1.43e+03
stableloss: 2.06e-01   dataloss: 2.63e+01   sparseloss: 1.37e+01 momentloss: 1.64e+01
iter:   200    time: 113.46
Func: 2.08e+01  |g|: 5.46e+01
stableloss: 2.09e-01   dataloss: 1.90e+01   sparseloss: 1.43e+01 momentloss: 1.71e+01
iter:   400    time: 113.59
Func: 1.30e+01  |g|: 6.06e+01
stableloss: 1.62e-01   dataloss: 1.01e+01   sparseloss: 2.48e+01 momentloss: 1.25e+01
iter:   600    time: 113.48
Func: 1.13e+01  |g|: 2.52e+01
stableloss: 1.41e-01   dataloss: 8.40e+00   sparseloss: 2.58e+01 momentloss: 1.06e+01
iter:   800    time: 116.48
Func: 1.11e+01  |g|: 5.47e+00
stableloss: 1.41e-01   dataloss: 8.16e+00   sparseloss: 2.56e+01 momentloss: 1.09e+01
iter:  1000    time: 115.67
Func: 1.10e+01  |g|: 2.93e+00
stableloss: 1.41e-01   dataloss: 8.12e+00   sparseloss: 2.55e+01 momentloss: 1.06e+01
iter:  1200    time: 113.57
Func: 1.10e+01  |g|: 1.02e+00
stableloss: 1.41e-01   dataloss: 8.11e+00   sparseloss: 2.55e+01 momentloss: 1.06e+01
iter:  1400    time: 113.90
Func: 1.10e+01  |g|: 6.52e-01
stableloss: 1.41e-01   dataloss: 8.11e+00   sparseloss: 2.55e+01 momentloss: 1.06e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 11.008948
         Iterations: 1429
         Function evaluations: 1490
         Gradient evaluations: 1471
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.24e-02  5.10e-02 -6.45e-02]
 [ 0.00e+00  7.72e-03 -1.69e-02 -1.26e-02 -2.30e-02]
 [-7.60e-03 -1.30e-03  4.18e-02  2.11e-02 -3.78e-03]
 [ 2.28e-02 -6.90e-03 -1.86e-02 -4.65e-06 -3.16e-02]
 [-5.30e-02 -3.67e-03  9.74e-03 -2.96e-03 -1.54e-04]]
[[ 1.58e-02 -4.34e-02 -1.48e-02 -3.12e-02  9.94e-03]
 [-4.56e-02  1.43e-01  7.69e-02  4.75e-02  2.65e-03]
 [-4.12e-02  1.12e-01  5.61e-01  1.27e-01 -5.77e-02]
 [-3.91e-03 -2.84e-04  1.90e-01 -3.03e-02  2.36e-02]
 [-1.24e-02  5.41e-02 -1.19e-01  5.13e-02 -1.48e-02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -7.50e-02 -6.48e-02]
 [ 0.00e+00  0.00e+00 -1.01e-03 -5.83e-03 -6.51e-03]
 [ 0.00e+00  1.95e-02 -9.62e-02  4.14e-02 -6.24e-02]
 [-5.44e-04 -3.01e-03 -6.35e-03 -3.97e-03 -1.31e-02]
 [ 5.40e-03 -1.65e-02 -3.74e-02 -7.59e-04 -2.30e-02]]
[[-9.62e-03  2.04e-02  7.73e-04  3.69e-03 -9.56e-03]
 [-2.30e-02  2.01e-02 -6.18e-02  2.23e-02  2.03e-02]
 [ 1.15e-01 -5.44e-01 -2.87e-01  9.59e-01 -2.11e-01]
 [-6.04e-03 -3.86e-02  1.58e-02 -2.87e-02  3.64e-02]
 [-1.99e-02  5.92e-02 -5.63e-02  4.44e-02 -2.23e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  1.40e-03  1.80e-03]
 [ 1.00e+00  0.00e+00  9.06e-03 -6.17e-04 -2.18e-02]
 [ 0.00e+00  2.74e-03 -6.05e-02  2.30e-02 -3.00e-02]
 [-8.27e-02 -2.06e-02  1.95e-02  1.60e-03 -7.69e-03]
 [-7.02e-02 -5.61e-03 -4.50e-02  9.31e-03 -1.80e-02]]
[[-0.01 -0.01  0.1  -0.01 -0.01]
 [ 0.03 -0.01 -0.52  0.    0.03]
 [-0.02 -0.01 -0.31 -0.06 -0.02]
 [ 0.03 -0.03  0.97  0.05  0.01]
 [-0.02  0.05 -0.22  0.01 -0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  2.21e-02]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.26e-02  7.66e-03]
 [ 0.00e+00  0.00e+00  7.48e-01  7.34e-03  2.49e-01]
 [ 0.00e+00  5.13e-02 -1.64e-03 -8.80e-04  2.81e-02]
 [-1.90e-01 -2.50e-02  3.23e-01 -3.40e-03  1.09e-01]]
[[ 5.10e-02  7.87e-02 -3.95e-01  2.04e-02  5.48e-02]
 [-5.84e-02 -1.42e-01  1.02e+00 -2.09e-03 -5.28e-02]
 [-2.97e-02  1.27e+00 -3.49e+00  1.15e+00 -4.34e-02]
 [-1.06e-01  9.96e-02  7.33e-01  1.33e-01 -9.80e-02]
 [ 8.16e-02 -6.38e-02 -2.30e-01 -5.62e-02  7.81e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.85e-02]
 [ 0.00e+00  1.00e+00  0.00e+00 -5.38e-03 -9.19e-02]
 [ 0.00e+00  0.00e+00 -4.24e-03 -9.93e-02  4.10e-02]
 [ 0.00e+00 -1.57e-01  2.23e-01  4.33e-01  3.42e-02]
 [ 2.16e-02  1.10e-01  6.76e-04 -8.41e-03  1.69e-02]]
[[ 0.13 -0.5   0.23  0.3  -0.13]
 [-0.21  1.14 -0.13 -1.23  0.34]
 [ 0.01 -0.45  0.44  0.03  0.1 ]
 [ 0.21 -0.66 -0.16  0.92 -0.39]
 [-0.08  0.25 -0.03 -0.25  0.14]]
[[ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.01]
 [ 1.    0.    0.01 -0.    0.14]
 [ 0.   -0.07 -0.01  0.01  0.01]
 [ 0.22  0.02  0.04 -0.01  0.06]]
[[ 0.05 -0.16  0.28 -0.07  0.03]
 [-0.05  0.09  0.58 -0.14 -0.01]
 [ 0.    0.19 -1.73  0.38 -0.04]
 [-0.04  0.01  0.54 -0.02 -0.03]
 [ 0.05 -0.14  0.34 -0.16  0.05]]
SymNet parameters
[[ 6.47e-04 -6.79e-04 -5.36e-01 -4.81e-03 -4.32e-02  2.06e-03  1.37e-02  1.64e-03
   6.40e-03 -2.16e-03 -9.88e-04 -2.03e-03]
 [-3.25e-04  5.45e-04 -2.97e-03 -4.26e-04  3.35e-04 -5.48e-04  5.56e-01  4.94e-02
  -4.72e-04  9.17e-04  3.08e-04 -1.52e-03]]
SymNet parameters
[-1.39e-04 -3.52e-05]
SymNet parameters
[[-3.18e-04  3.61e-04  1.09e+00 -4.60e-04 -6.87e-03 -8.62e-04  1.13e-03 -2.81e-04
  -1.18e-03  4.47e-04  4.77e-05  1.91e-04 -3.19e-03]
 [-1.99e-04 -2.05e-04 -6.91e-04  3.56e-04  2.82e-04  7.83e-06 -1.09e+00  2.85e-03
  -1.87e-03 -2.02e-04  5.05e-04  8.35e-04  1.38e-03]]
SymNet parameters
[8.65e-05 1.02e-04]
SymNet parameters
[[ 6.17e-02 -7.92e-01 -5.52e-05 -2.27e-02  6.84e-04  2.11e-03  1.07e-03  1.39e-03
  -5.61e-04  5.95e-04  3.63e-04  8.79e-04 -2.73e-01  4.42e-02]
 [-1.07e+00  1.31e-02 -6.95e-04 -3.97e-02  6.61e-04  4.04e-03 -2.48e-04  2.56e-04
   1.05e-02  2.70e-03 -3.48e-04  1.01e-03 -3.67e-03  1.70e-02]]
SymNet parameters
[3.16e-03 2.64e-06]
SymNet parameters
[[-3.02e-01 -5.68e-04 -1.06e-05  1.06e-01 -7.73e-04 -4.13e-03 -2.96e-04 -9.91e-04
  -2.88e-02 -5.03e-03  1.85e-04 -3.88e-03  2.39e-04  1.37e-01  1.65e-02]
 [-4.64e-01 -1.35e-03  2.78e-03  2.68e-03  1.06e-03 -2.24e-03  6.54e-03  1.44e-03
   9.52e-02  6.66e-04 -3.23e-03  6.47e-04  2.76e-04 -6.92e-03  4.24e-03]]
SymNet parameters
[ 2.23e-04 -7.94e-06]
SymNet parameters
[[ 3.45e-04 -3.51e-01 -3.48e-04 -1.04e-02 -2.81e-04  4.94e-04 -5.23e-04 -2.39e-03
  -4.86e-02  9.06e-04  1.44e-03  2.89e-05 -1.70e-01  2.76e-02 -5.86e-04 -8.13e-02]
 [ 2.32e-01  6.44e-02  9.15e-04 -1.48e-01 -1.04e-04  1.27e-02 -5.87e-04 -8.75e-04
   3.43e-02  8.91e-03 -5.50e-04  4.49e-03  6.08e-04  1.03e-01 -7.88e-02 -1.09e-02]]
SymNet parameters
[1.10e-04 3.35e-05]
SymNet parameters
[[ 7.32e-04 -3.48e-04  3.79e-05  4.78e-02 -6.31e-04  5.33e-02 -1.53e-05 -1.20e-03
  -1.04e-05  2.21e-04 -3.44e-04  3.80e-04  1.64e-01  7.85e-01 -1.10e+00 -5.17e-01
   6.80e-01]]
SymNet parameters
[0.]
SymNet parameters
[[-9.25e-04 -1.95e-03  1.54e-03 -8.16e-04 -1.74e-04  6.82e-04 -9.52e-01 -4.65e-01
  -4.48e-03  6.57e-04 -2.94e-03  7.90e-04]
 [-1.19e+00  1.47e-02 -3.73e-03  2.41e-03 -4.26e-04  1.85e-04  9.79e-04  4.46e-03
  -2.05e-01  1.53e-03  2.98e-02  2.04e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 1.79e-03  1.56e-03  1.22e-04  7.72e-04  1.35e-04 -6.29e-04  1.21e+00 -2.25e-01
   5.12e-03  4.91e-04  4.18e-03 -7.50e-04 -1.11e-03]
 [-9.99e-01 -1.60e-02  1.74e-02  1.12e-04 -1.28e-03  1.06e-03 -7.92e-04 -8.72e-03
   4.24e-01  4.88e-04  1.71e-02 -1.91e-04  5.34e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 0.   -0.01  0.1  -0.   -0.   -0.   -0.07  0.11  0.14 -0.    0.02  0.06 -0.01 -0.  ]
 [-0.   -0.01  0.07  0.01 -0.   -0.    0.08  0.14  0.11  0.    0.01 -0.05  0.    0.02]]
SymNet parameters
[-1.14e-04 -6.25e-05]
SymNet parameters
[[-2.30e-02 -8.42e-02  6.11e-02 -5.60e-03 -1.90e-03  1.50e-03 -1.63e-03 -9.20e-02
  -2.12e-01 -9.74e-04 -1.86e-02 -6.26e-03  9.77e-03 -2.29e-02  4.43e-01]
 [-6.47e-04  5.23e-03  6.67e-03 -1.67e-03  1.55e-04  2.10e-03  6.91e-01  8.47e-04
  -2.40e-02  3.92e-03  3.64e-04  3.88e-04 -1.02e-01 -1.00e-01 -4.57e-02]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 6.30e-04 -5.28e-04  4.54e-03  2.87e-06 -9.31e-04  4.46e-04 -5.90e-04 -3.34e-01
   4.64e-02 -1.34e-03 -1.71e-03  2.22e-03  1.55e-02 -9.74e-02 -1.23e-02 -5.86e-02]
 [ 7.16e-04 -1.30e-02 -4.08e-03 -6.48e-03  4.35e-03 -1.12e-04  1.50e-01  6.13e-05
   9.39e-04 -4.34e-03 -1.14e-01 -6.39e-03 -3.19e-02 -3.36e-02  3.12e-04  1.99e-01]]
SymNet parameters
[-2.53e-04 -7.84e-05]
SymNet parameters
[[ 5.94e-05 -1.46e-04 -1.33e-03  8.73e-04  2.20e-04 -5.57e-04  5.32e-04 -3.19e-04
   3.11e-03  5.38e-02 -5.61e-04  4.85e-02 -1.28e+00 -1.21e+00  4.05e-03  7.33e-01
  -5.79e-01]]
SymNet parameters
[-0.]
finally, finish this stage
iter:  1429    time: 37.09
Func: 1.10e+01  |g|: 4.53e-01
stableloss: 1.41e-01   dataloss: 8.11e+00   sparseloss: 2.55e+01 momentloss: 1.06e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00*u01**2, u01*u10*v00, u10*v00*v10, u00*u10*v01, u00*u11*v00, u00, u01**2, u00*v00**2, u00*v00, u00**2*u01, u00**3, u11*v00, u10*v01, u00**2*u02, v00*v10, u00*u01*v10]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.   -0.   -0.    0.    0.
 -0.    0.   -0.    0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v01*v10, u00*v00*v11, u10*v00*v01, v01*v10, u00*u01*v01, u00*u10*v01, v10, u01*v00*v10, v00, u01*v00*v01, u00*u10, 1, v00**2*v10, v00*v11, v00*v01*v10]
[-0.98 -0.98  0.05  0.05  0.02  0.01  0.01  0.01 -0.01  0.   -0.    0.    0.    0.
 -0.    0.   -0.   -0.    0.    0.  ]
block:  24
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  0.038407193687153784
current stage is: block-24
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9181, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2515,  1.6368,  1.6241, 18.9761, 13.5693, 15.5935,  0.2581,  1.5650,
         1.7511, 16.0053, 15.0911, 17.3653], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 197.35
Func: 2.06e+01  |g|: 5.25e+02
stableloss: 1.75e-01   dataloss: 1.73e+01   sparseloss: 2.55e+01 momentloss: 1.06e+01
iter:   200    time: 138.40
Func: 1.62e+01  |g|: 4.82e+01
stableloss: 1.77e-01   dataloss: 1.28e+01   sparseloss: 2.59e+01 momentloss: 1.06e+01
iter:   400    time: 139.28
Func: 1.61e+01  |g|: 9.05e+00
stableloss: 1.77e-01   dataloss: 1.27e+01   sparseloss: 2.61e+01 momentloss: 1.05e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 16.078409
         Iterations: 557
         Function evaluations: 624
         Gradient evaluations: 607
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.08e-02 -6.76e-02 -4.42e-02]
 [ 0.00e+00  8.30e-03  4.56e-03  9.23e-03 -5.28e-04]
 [-7.98e-03 -3.22e-02  7.22e-02 -9.82e-02  1.56e-03]
 [-2.83e-02 -3.76e-03  1.01e-03 -1.96e-02 -3.71e-04]
 [-4.94e-02 -2.93e-02  1.64e-02 -4.48e-02  1.93e-04]]
[[ 1.04e-02  2.87e-03 -5.91e-02  2.30e-02 -1.17e-02]
 [-6.96e-03  1.22e-02  9.51e-02  5.35e-02  4.77e-03]
 [ 1.14e-05  9.89e-03  7.24e-01  6.51e-02 -7.51e-02]
 [-3.15e-02  5.66e-02  1.42e-01  1.97e-02  2.87e-02]
 [ 2.02e-02 -1.34e-02 -8.97e-02  4.21e-02 -2.21e-02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -8.93e-02 -6.37e-02]
 [ 0.00e+00  0.00e+00 -8.85e-03  3.53e-04 -1.62e-02]
 [ 0.00e+00  1.48e-02 -8.38e-02  2.20e-02 -6.32e-02]
 [-1.98e-03 -6.84e-03 -1.56e-02 -1.21e-02 -1.89e-02]
 [-1.44e-03 -1.68e-02 -3.23e-02 -6.76e-03 -2.18e-02]]
[[-0.01  0.02 -0.01  0.   -0.01]
 [-0.02  0.02 -0.05  0.04  0.01]
 [ 0.13 -0.59 -0.27  0.93 -0.2 ]
 [-0.02 -0.    0.01 -0.01  0.04]
 [-0.02  0.06 -0.07  0.06 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  1.14e-03 -7.86e-04]
 [ 1.00e+00  0.00e+00  2.01e-02 -3.40e-03 -7.52e-03]
 [ 0.00e+00 -1.28e-02 -6.59e-02 -2.47e-02 -1.80e-02]
 [-8.39e-02 -2.86e-03  1.66e-02 -1.52e-02 -7.96e-03]
 [-7.50e-02 -7.75e-03 -6.10e-02 -1.37e-02 -1.89e-02]]
[[-0.01 -0.03  0.12 -0.03 -0.01]
 [ 0.03  0.02 -0.56  0.02  0.04]
 [-0.04 -0.   -0.36  0.02 -0.06]
 [ 0.03  0.01  0.99 -0.04  0.06]
 [-0.01  0.   -0.2   0.03 -0.03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  3.66e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  1.99e-02  4.24e-02]
 [ 0.00e+00  0.00e+00  5.33e-01 -1.92e-02  3.26e-01]
 [ 0.00e+00 -3.01e-03  6.99e-02 -2.44e-04 -7.22e-03]
 [-6.39e-02 -3.41e-03  2.35e-01  2.02e-03  1.21e-01]]
[[ 8.54e-02 -1.91e-01  1.54e-01 -2.04e-01  9.12e-02]
 [-4.86e-02  7.67e-02  1.40e-01  1.85e-01 -9.75e-02]
 [-2.04e-01  1.84e+00 -3.58e+00  1.70e+00 -1.41e-01]
 [ 2.10e-02 -3.70e-01  9.15e-01 -3.08e-01 -1.96e-03]
 [ 6.69e-02 -4.18e-02 -1.07e-01 -5.20e-02  6.95e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.16e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  1.04e-03  1.71e-01]
 [ 0.00e+00  0.00e+00  5.20e-03  1.24e-01 -3.26e-03]
 [ 0.00e+00 -1.98e-01 -1.31e-01  4.70e-01 -3.51e-02]
 [ 1.99e-02 -8.61e-02  3.79e-05  1.16e-02 -1.42e-02]]
[[ 0.14 -0.28 -0.03  0.31 -0.11]
 [-0.42  1.16 -0.35 -0.71  0.25]
 [-0.01  0.42 -0.35  0.21 -0.16]
 [ 0.47 -1.78  0.79  0.53 -0.09]
 [-0.18  0.51 -0.09 -0.32  0.1 ]]
[[ 0.    0.    0.    0.    0.01]
 [ 0.    0.    0.   -0.   -0.01]
 [ 1.    0.    0.19  0.01  0.01]
 [ 0.   -0.03 -0.05  0.03  0.05]
 [ 0.16  0.    0.16 -0.01  0.03]]
[[ 0.01  0.16 -0.29  0.22 -0.02]
 [-0.08 -0.2   1.36 -0.4   0.  ]
 [ 0.19 -0.18 -1.63 -0.02  0.12]
 [-0.16  0.26  0.47  0.26 -0.15]
 [ 0.05 -0.06  0.13 -0.09  0.05]]
SymNet parameters
[[-8.49e-03  1.09e-03 -4.64e-01  3.50e-03 -3.65e-02 -3.50e-03  1.48e-02  2.74e-03
   3.74e-03 -4.28e-04 -3.23e-04 -3.12e-03]
 [ 3.03e-04 -2.08e-03 -6.53e-03  1.24e-03  1.22e-03  1.00e-04  4.83e-01  4.12e-02
  -1.71e-03  1.28e-03  1.07e-03 -4.18e-04]]
SymNet parameters
[-1.99e-04 -2.04e-05]
SymNet parameters
[[-7.32e-04  9.25e-04  1.12e+00 -3.73e-03 -4.21e-04  7.28e-04  2.78e-03  1.58e-03
   1.62e-03 -2.70e-04  1.64e-05  7.98e-05  2.90e-02]
 [-1.30e-03  3.20e-03 -1.42e-03  2.50e-04  2.50e-04 -1.62e-05 -1.14e+00  4.77e-03
   2.55e-03 -1.05e-03  3.24e-04  5.50e-04 -3.03e-04]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 3.69e-02 -7.60e-01 -7.34e-05 -1.22e-02  8.59e-04 -2.86e-03  8.90e-04 -1.43e-03
   1.45e-03 -5.44e-04  6.10e-04  3.91e-04 -3.81e-01  3.01e-02]
 [-1.16e+00  9.55e-04 -3.99e-05 -4.25e-02  9.11e-04  2.09e-03 -5.51e-04 -5.73e-04
   1.24e-02 -4.17e-04 -6.68e-05 -1.28e-04 -8.61e-04  2.64e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-2.05e-01  2.34e-05 -3.34e-04  1.46e-01 -4.74e-03  1.47e-02  6.05e-04 -4.03e-04
  -5.95e-02  5.44e-03 -2.37e-03  4.00e-04  1.12e-04  1.52e-01  3.60e-02]
 [-5.08e-01  1.12e-02 -1.51e-04 -9.07e-03 -1.49e-03  5.55e-05 -1.12e-02  4.02e-03
   7.03e-02  4.60e-04  4.71e-04 -7.80e-04  3.99e-04  1.42e-03 -1.41e-02]]
SymNet parameters
[ 2.39e-04 -5.78e-05]
SymNet parameters
[[ 1.37e-01 -2.84e-01 -5.42e-05 -1.32e-03  6.28e-04 -2.53e-04  3.01e-02 -2.17e-04
  -3.77e-02 -9.06e-04  2.10e-04  8.69e-05 -1.29e-01  1.61e-02 -4.72e-03 -4.56e-02]
 [ 4.41e-04 -2.11e-02 -1.23e-04 -1.89e-01  4.30e-03  6.80e-03  5.03e-04 -7.86e-04
   5.57e-02 -1.00e-03  1.41e-03 -1.68e-03  1.65e-04  1.60e-01 -9.99e-02 -1.32e-01]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 6.94e-04 -1.96e-03 -1.43e-03  4.81e-02 -6.65e-04  5.53e-02 -1.03e-03 -1.87e-03
  -9.17e-04  3.11e-04  7.33e-05 -1.86e-05  1.84e-04  7.69e-01 -1.12e+00 -4.51e-01
   6.76e-01]]
SymNet parameters
[0.]
SymNet parameters
[[-1.54e-04 -1.56e-03  3.04e-03 -1.11e-03 -1.80e-04 -3.67e-04 -9.04e-01 -5.06e-01
   3.09e-03  2.31e-03 -8.95e-03 -2.87e-03]
 [-1.16e+00  7.48e-03  1.97e-03  2.30e-03  4.37e-04  1.96e-03 -1.61e-04  2.34e-02
  -1.82e-01 -3.78e-03  3.02e-02  4.43e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-1.13e-03  6.61e-04 -1.89e-03  1.64e-03  3.33e-04  1.26e-03  1.23e+00 -1.85e-01
  -4.65e-03 -3.93e-03  1.22e-02  5.04e-03  6.10e-04]
 [-9.11e-01 -2.02e-02  2.47e-02  2.25e-03  6.71e-05  2.89e-03  2.61e-02  2.72e-02
   4.20e-01 -3.93e-03  2.18e-02  2.97e-04 -1.02e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 0.   -0.01  0.12  0.    0.    0.   -0.06  0.08  0.15  0.01  0.03  0.05 -0.   -0.01]
 [-0.02 -0.    0.04  0.    0.   -0.01  0.03  0.18  0.1   0.    0.01 -0.05  0.03  0.05]]
SymNet parameters
[-9.09e-05 -1.12e-04]
SymNet parameters
[[ 8.25e-03 -8.04e-02  6.45e-02 -1.22e-03  5.47e-05  2.28e-03  1.02e-01 -4.69e-02
  -2.28e-01  4.80e-04 -3.67e-02 -1.21e-02  2.45e-03 -5.81e-03  4.14e-01]
 [ 8.46e-05  1.35e-03  8.17e-03 -1.02e-03 -1.48e-03  2.55e-04  6.96e-01 -1.19e-01
   3.97e-03  1.16e-02  6.78e-03 -3.97e-03 -7.87e-02 -7.68e-02 -1.43e-02]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-7.99e-05  1.05e-03  3.91e-03 -4.91e-04 -6.99e-04  1.82e-03  1.89e-01 -2.97e-01
   1.11e-01  4.96e-03  1.81e-03 -2.32e-03  4.48e-04 -8.58e-02  6.73e-04 -3.97e-02]
 [ 5.80e-04 -3.70e-02  9.50e-04 -1.16e-02 -2.13e-04 -7.25e-03  1.22e-01 -1.11e-01
   3.29e-06  1.48e-02 -1.25e-01 -1.68e-02 -1.06e-02  8.42e-03  9.26e-02  1.95e-01]]
SymNet parameters
[-2.60e-04 -8.98e-05]
SymNet parameters
[[-5.66e-04 -3.66e-03  2.25e-03  6.72e-04  7.00e-04  1.37e-04  5.23e-04 -2.82e-04
  -4.50e-03  5.31e-02 -9.56e-04  5.06e-02 -1.31e+00 -1.23e+00 -1.16e-02  7.90e-01
  -7.37e-01]]
SymNet parameters
[0.]
finally, finish this stage
iter:   557    time: 143.93
Func: 1.61e+01  |g|: 5.90e-01
stableloss: 1.76e-01   dataloss: 1.27e+01   sparseloss: 2.60e+01 momentloss: 1.05e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00*u01**2, u01*u10*v00, u10*v00*v10, u00*u10*v01, u00*u11*v00, u00, u01**2, u10*v01, u00*v00**2, u01, u01*u10, v00**2, u10, u10*v10, u00*u01*v00, u00**2*v00]
[-0.99 -0.98  0.06  0.05  0.02  0.01  0.01  0.01  0.01  0.01  0.    0.   -0.   -0.
  0.   -0.   -0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v01*v10, u00*v00*v11, u10*v00*v01, v10, v01*v10, u01, u00*u01*v01, v00, u00*u10*v01, u01*v00*v01, u00, u00*u10, u00*u01*v00, u01*v00*v10, u10]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01 -0.    0.   -0.    0.    0.   -0.
 -0.   -0.    0.    0.    0.    0.  ]
block:  27
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -1.9748737679833526
current stage is: block-27
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9131, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2613,  1.7142,  1.5906, 21.3154, 14.6464, 14.4073,  0.2530,  1.5931,
         1.6829, 17.7338, 14.7446, 16.5317], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 256.37
Func: 2.50e+01  |g|: 5.75e+02
stableloss: 2.09e-01   dataloss: 2.12e+01   sparseloss: 2.60e+01 momentloss: 1.05e+01
iter:   200    time: 161.86
Func: 2.16e+01  |g|: 1.16e+02
stableloss: 1.95e-01   dataloss: 1.77e+01   sparseloss: 2.66e+01 momentloss: 1.06e+01
iter:   400    time: 163.61
Func: 2.14e+01  |g|: 1.69e+01
stableloss: 1.96e-01   dataloss: 1.76e+01   sparseloss: 2.62e+01 momentloss: 1.10e+01
iter:   600    time: 163.28
Func: 2.13e+01  |g|: 6.65e+00
stableloss: 1.97e-01   dataloss: 1.74e+01   sparseloss: 2.62e+01 momentloss: 1.09e+01
iter:   800    time: 162.66
Func: 2.13e+01  |g|: 7.58e-01
stableloss: 1.98e-01   dataloss: 1.74e+01   sparseloss: 2.61e+01 momentloss: 1.08e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 21.260537
         Iterations: 837
         Function evaluations: 903
         Gradient evaluations: 889
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -8.69e-03 -3.20e-02 -3.90e-02]
 [ 0.00e+00 -2.22e-03  1.99e-02 -2.53e-02  1.14e-02]
 [-9.98e-03  4.76e-03  5.16e-02 -2.19e-03  4.83e-03]
 [-3.27e-02 -2.81e-02  5.26e-02 -2.57e-02  2.13e-02]
 [-6.66e-02 -6.57e-03 -9.18e-04 -1.18e-02 -1.76e-03]]
[[-0.01  0.   -0.05  0.01 -0.01]
 [ 0.    0.07  0.1   0.01  0.04]
 [-0.01 -0.01  0.61  0.12 -0.09]
 [-0.02  0.06  0.2   0.03  0.02]
 [ 0.02 -0.01 -0.09  0.   -0.  ]]
[[ 0.    1.    0.   -0.08 -0.06]
 [ 0.    0.    0.01  0.    0.02]
 [ 0.    0.01 -0.1   0.03 -0.07]
 [-0.    0.   -0.    0.01  0.01]
 [ 0.   -0.02 -0.04 -0.   -0.02]]
[[-1.73e-02  5.65e-02 -5.43e-02  3.95e-02 -2.16e-02]
 [-1.72e-02 -1.07e-02 -2.35e-02  1.86e-02  2.34e-02]
 [ 1.18e-01 -5.52e-01 -2.72e-01  9.19e-01 -2.01e-01]
 [-1.03e-02 -1.31e-02 -3.11e-02  2.69e-02  2.20e-02]
 [-1.31e-02  2.77e-02 -3.45e-03  6.66e-04 -1.09e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  3.95e-03 -4.03e-03]
 [ 1.00e+00  0.00e+00  1.79e-02 -6.97e-05 -1.75e-02]
 [ 0.00e+00 -4.70e-03 -8.21e-02 -3.48e-03 -4.63e-02]
 [-7.63e-02 -8.16e-03  3.42e-02  5.49e-03 -5.99e-03]
 [-7.27e-02  1.58e-03 -5.33e-02  2.46e-03 -2.56e-02]]
[[-0.01 -0.01  0.08  0.   -0.02]
 [ 0.04 -0.01 -0.49 -0.02  0.03]
 [-0.04  0.03 -0.4   0.   -0.02]
 [ 0.04 -0.05  1.04 -0.01  0.02]
 [-0.02  0.06 -0.26  0.05 -0.02]]
[[ 0.    0.    1.    0.    0.13]
 [ 0.    0.    0.   -0.01 -0.06]
 [ 0.    0.    0.8  -0.01  0.38]
 [ 0.    0.06 -0.01  0.   -0.01]
 [-0.12 -0.01  0.38  0.01  0.16]]
[[ 9.90e-02 -7.47e-02 -1.19e-01 -1.39e-01  1.13e-01]
 [-4.65e-02 -2.55e-01  9.44e-01 -5.75e-02 -1.05e-01]
 [-2.30e-04  1.20e+00 -3.00e+00  9.88e-01  9.04e-02]
 [-1.09e-01  6.72e-02  5.48e-01  1.35e-01 -1.63e-01]
 [ 1.02e-01 -1.18e-01 -1.06e-01 -1.07e-01  1.09e-01]]
[[ 0.    0.    0.    0.    0.05]
 [ 0.    1.    0.   -0.    0.01]
 [ 0.    0.   -0.    0.17  0.03]
 [ 0.   -0.28 -0.04  0.28  0.  ]
 [ 0.02 -0.06 -0.05  0.02 -0.  ]]
[[ 0.08 -0.26  0.05  0.23 -0.09]
 [-0.24  0.93 -0.16 -0.92  0.32]
 [ 0.12 -0.34  0.62 -0.14 -0.15]
 [ 0.19 -0.79 -0.36  1.01 -0.13]
 [-0.09  0.25  0.18 -0.41  0.1 ]]
[[ 0.    0.    0.    0.   -0.11]
 [ 0.    0.    0.    0.02  0.05]
 [ 1.    0.    0.06  0.02  0.08]
 [ 0.   -0.05  0.02  0.01  0.03]
 [ 0.17 -0.02  0.01 -0.02  0.03]]
[[ 2.93e-02 -9.30e-02  1.78e-01 -3.06e-02 -1.76e-03]
 [-8.07e-02  2.45e-01  4.19e-01  4.96e-02  3.88e-02]
 [-3.65e-02  3.04e-01 -2.09e+00  5.40e-01 -2.21e-01]
 [-5.68e-02  7.35e-02  6.16e-01 -1.49e-02  5.44e-02]
 [ 3.68e-02 -9.71e-02  2.32e-01 -1.12e-01  2.17e-02]]
SymNet parameters
[[-4.26e-03 -3.02e-03 -5.28e-01 -4.45e-03 -3.88e-02 -1.65e-03  9.78e-03 -1.37e-03
  -1.43e-03  1.25e-04 -4.77e-05 -2.35e-03]
 [ 4.56e-04  1.59e-03 -1.20e-03  1.55e-03  4.22e-05  8.96e-04  5.42e-01  4.56e-02
   5.52e-04 -6.47e-04 -4.62e-04  7.90e-06]]
SymNet parameters
[-8.73e-05  4.78e-05]
SymNet parameters
[[-9.55e-04  6.48e-04  1.14e+00  9.89e-03 -1.77e-04  3.47e-04  9.05e-04  5.41e-06
  -1.72e-03  9.20e-05 -4.86e-04  3.52e-04  9.01e-04]
 [ 5.89e-04 -8.98e-03 -1.27e-04 -6.88e-03  2.99e-04  4.06e-04 -1.11e+00  1.84e-03
   1.75e-03 -2.10e-04  6.64e-04  1.35e-03 -1.41e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 6.72e-02 -7.26e-01  6.42e-03 -3.98e-02 -2.30e-03  3.49e-03  9.90e-03  4.37e-04
   2.44e-03  5.99e-04  8.19e-04 -1.49e-03 -2.95e-01  4.64e-02]
 [-1.11e+00 -5.18e-05  9.94e-03 -6.63e-02 -2.74e-03  3.48e-03 -2.93e-04 -5.48e-04
   2.26e-03 -1.03e-03  1.06e-03  6.37e-06  1.03e-02  2.69e-02]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-3.30e-01 -8.73e-04 -5.48e-05  1.97e-01  8.75e-03 -1.74e-02 -3.48e-04  4.44e-04
  -2.11e-02 -2.55e-03 -1.99e-03  7.76e-03  4.93e-05  1.01e-01 -7.93e-05]
 [-4.41e-01 -8.00e-04 -2.38e-02 -1.36e-03 -2.36e-04  2.27e-04 -4.45e-02 -1.34e-04
   6.69e-02 -1.67e-03 -1.27e-03  4.84e-04  6.84e-02 -2.00e-02  1.57e-02]]
SymNet parameters
[ 2.52e-04 -1.95e-05]
SymNet parameters
[[ 3.09e-02 -3.56e-01 -1.18e-02 -1.86e-02 -7.03e-04  1.72e-03 -1.65e-02 -4.24e-04
  -4.95e-02  1.92e-03  9.40e-04 -1.77e-03 -2.17e-01  3.93e-02 -3.51e-04 -4.02e-02]
 [ 3.14e-01 -7.60e-03 -5.63e-03 -2.03e-01 -9.43e-03  7.19e-03 -1.01e-04 -1.06e-03
   3.72e-03 -2.58e-03  4.20e-03  7.45e-04 -6.30e-04  1.22e-01 -7.85e-02 -1.10e-02]]
SymNet parameters
[ 1.62e-04 -8.21e-05]
SymNet parameters
[[ 7.01e-04  7.59e-05  5.01e-04  4.66e-02  4.58e-05  5.51e-02  2.88e-04 -1.55e-03
  -7.04e-04  1.73e-04  8.99e-05 -1.97e-04  8.18e-04  7.78e-01 -1.12e+00 -6.24e-01
   7.64e-01]]
SymNet parameters
[0.]
SymNet parameters
[[-6.68e-05  1.12e-03  1.41e-03  2.37e-04 -4.22e-04 -7.39e-04 -1.05e+00 -4.70e-01
   3.16e-03 -2.89e-05  2.94e-04  1.04e-03]
 [-1.24e+00  7.59e-03 -4.21e-03  1.23e-04  3.07e-05  6.34e-04  3.11e-02 -4.88e-03
  -1.82e-01  7.20e-04  1.91e-03  3.69e-05]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 1.33e-03 -4.11e-03 -1.58e-03 -1.57e-04  5.04e-04  4.32e-04  1.40e+00 -2.16e-01
  -4.84e-03 -4.07e-04 -6.89e-04 -8.02e-04 -8.09e-04]
 [-1.07e+00 -4.07e-02  1.28e-03  1.19e-03  4.86e-05  5.05e-05  3.73e-02  1.29e-02
   4.42e-01  4.49e-04 -7.61e-03 -3.46e-04 -2.30e-04]]
SymNet parameters
[6.28e-05 2.87e-04]
SymNet parameters
[[ 0.   -0.07  0.04  0.01 -0.01 -0.   -0.05  0.02  0.2  -0.01  0.01  0.06 -0.01 -0.01]
 [-0.01 -0.06  0.02  0.    0.    0.    0.06  0.03  0.19  0.01  0.01 -0.05  0.02  0.04]]
SymNet parameters
[-1.92e-05 -2.96e-05]
SymNet parameters
[[-3.89e-04 -1.34e-01  1.04e-02  5.31e-03  1.77e-03  9.83e-04  3.69e-02  8.29e-03
  -1.15e-01  1.85e-03 -2.49e-02  3.60e-03  1.54e-03 -1.01e-01  4.43e-01]
 [-8.53e-03  3.76e-03 -6.19e-03  2.68e-03  6.88e-04 -3.12e-03  6.07e-01 -4.52e-02
   2.10e-03  3.02e-03  6.73e-03  6.66e-03 -1.01e-01 -9.14e-02 -3.35e-05]]
SymNet parameters
[2.51e-05 7.66e-05]
SymNet parameters
[[-4.03e-04  6.26e-02 -2.08e-02  6.06e-03  5.62e-03  7.90e-03  2.50e-04  8.56e-04
   5.40e-02  2.73e-03  1.08e-02  1.39e-02  7.23e-04 -3.38e-01 -3.58e-05  3.00e-02]
 [-1.42e-02 -6.75e-03 -3.43e-03 -1.94e-04  1.40e-03 -6.17e-04  2.70e-01 -2.21e-02
  -6.52e-04 -5.34e-04 -2.91e-02  1.13e-03 -4.38e-02 -4.01e-02 -6.56e-02  4.35e-02]]
SymNet parameters
[-5.34e-05 -1.69e-04]
SymNet parameters
[[ 3.82e-04 -2.87e-03  6.42e-04 -7.05e-05  1.24e-04 -1.03e-04 -2.38e-04  2.66e-03
  -1.60e-04  5.46e-02  6.20e-04  4.95e-02 -1.25e+00 -1.09e+00 -3.46e-04  8.13e-01
  -5.57e-01]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   837    time: 69.57
Func: 2.13e+01  |g|: 7.34e-01
stableloss: 1.98e-01   dataloss: 1.74e+01   sparseloss: 2.61e+01 momentloss: 1.08e+01
current expression:
[u10*v00, u00*u01, u20, u02, u00*u01**2, u01*u10*v00, u10*v00*v10, u00*u10*v01, u00*u11*v00, u00, u00*u01*v10, u00*v00**2, u01**2, u00**2*u02, u01*u10, u10*v01, v01, u00**3, u01*u02, u10*v10]
[-0.99 -0.99  0.06  0.05  0.02  0.01  0.01  0.01  0.01  0.    0.   -0.    0.    0.
  0.    0.   -0.   -0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, v00*v01, u01*v00, v01, u01, v10**2, u10*v01, 1, v01*v10, u01*v00*v10, v00**2, u00*u01*v00, u10*v10]
[-0.98 -0.98  0.05  0.05  0.02  0.01  0.01  0.01  0.   -0.    0.   -0.    0.   -0.
 -0.    0.    0.    0.    0.    0.  ]
block:  30
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  2.171920373710716
current stage is: block-30
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8186, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2263,  1.4880,  1.4433, 13.6167, 12.1630, 14.9603,  0.2518,  1.6526,
         1.6132, 14.4633, 14.3412, 17.2747], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 153.88
Func: 3.10e+01  |g|: 9.04e+02
stableloss: 2.15e-01   dataloss: 2.67e+01   sparseloss: 2.61e+01 momentloss: 1.08e+01
iter:   200    time: 189.96
Func: 2.65e+01  |g|: 1.40e+02
stableloss: 2.29e-01   dataloss: 2.22e+01   sparseloss: 2.61e+01 momentloss: 1.08e+01
iter:   400    time: 190.28
Func: 2.63e+01  |g|: 9.78e+00
stableloss: 2.27e-01   dataloss: 2.20e+01   sparseloss: 2.65e+01 momentloss: 1.08e+01
iter:   600    time: 188.16
Func: 2.61e+01  |g|: 9.00e+00
stableloss: 2.27e-01   dataloss: 2.18e+01   sparseloss: 2.70e+01 momentloss: 1.07e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 26.105637
         Iterations: 764
         Function evaluations: 839
         Gradient evaluations: 824
convolution moment and kernels
[[ 1.    0.   -0.01  0.04 -0.03]
 [ 0.    0.01 -0.04  0.01 -0.01]
 [-0.01 -0.    0.07 -0.02  0.03]
 [-0.05  0.02 -0.02  0.    0.01]
 [-0.05 -0.    0.04 -0.    0.02]]
[[ 0.01  0.01 -0.05 -0.01  0.01]
 [-0.01 -0.    0.14  0.06 -0.03]
 [-0.02  0.09  0.66 -0.05  0.04]
 [-0.05  0.13  0.08  0.13 -0.05]
 [ 0.02 -0.06 -0.01 -0.05  0.02]]
[[ 0.    1.    0.   -0.07 -0.07]
 [ 0.    0.   -0.   -0.   -0.01]
 [ 0.    0.02 -0.09  0.04 -0.06]
 [ 0.   -0.01  0.   -0.01  0.  ]
 [ 0.   -0.01 -0.03  0.   -0.02]]
[[-0.02  0.05 -0.04  0.03 -0.01]
 [ 0.   -0.05  0.03 -0.03  0.02]
 [ 0.1  -0.52 -0.33  0.96 -0.2 ]
 [-0.01  0.   -0.04  0.02  0.02]
 [-0.01  0.03 -0.02  0.02 -0.01]]
[[ 0.    0.    0.   -0.01 -0.01]
 [ 1.    0.    0.02 -0.01 -0.01]
 [ 0.   -0.01 -0.08 -0.02 -0.05]
 [-0.08 -0.01  0.03 -0.   -0.  ]
 [-0.07 -0.01 -0.05 -0.01 -0.02]]
[[-0.01 -0.01  0.09  0.   -0.02]
 [ 0.01  0.03 -0.54  0.01  0.03]
 [-0.01 -0.03 -0.36 -0.01 -0.04]
 [ 0.02 -0.01  1.01 -0.01  0.03]
 [-0.02  0.04 -0.24  0.04 -0.02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.35e-02]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.82e-02 -1.08e-03]
 [ 0.00e+00  0.00e+00  7.37e-01  7.49e-02  2.52e-01]
 [ 0.00e+00  5.85e-02 -1.68e-02  2.19e-02  1.24e-04]
 [-1.72e-01  3.87e-03  3.58e-01  3.72e-02  1.21e-01]]
[[ 0.06  0.04 -0.34 -0.03  0.09]
 [-0.1  -0.08  0.97  0.01 -0.12]
 [ 0.05  1.04 -3.22  1.    0.09]
 [-0.08 -0.02  0.88  0.05 -0.15]
 [ 0.06  0.01 -0.29 -0.04  0.1 ]]
[[ 0.    0.    0.    0.    0.02]
 [ 0.    1.    0.   -0.   -0.01]
 [ 0.    0.   -0.19  0.   -0.03]
 [ 0.   -0.    0.11  0.4   0.  ]
 [-0.04 -0.02 -0.07  0.02 -0.01]]
[[ 0.1  -0.33  0.16  0.12 -0.1 ]
 [-0.22  0.87 -0.1  -0.59  0.21]
 [-0.03  0.14 -0.22 -0.23  0.09]
 [ 0.3  -1.07  0.36  0.88 -0.3 ]
 [-0.12  0.32 -0.09 -0.26  0.11]]
[[ 0.    0.    0.    0.    0.01]
 [ 0.    0.    0.    0.01  0.01]
 [ 1.    0.    0.07 -0.05  0.22]
 [ 0.   -0.02  0.01 -0.01  0.01]
 [ 0.2  -0.    0.01 -0.03  0.07]]
[[ 6.26e-02 -2.35e-01  4.30e-01 -1.76e-01  3.83e-02]
 [-2.01e-02  1.10e-01  4.04e-01 -6.71e-04  2.65e-02]
 [-7.57e-02  2.56e-01 -1.69e+00  3.66e-01 -1.36e-01]
 [-3.08e-02  7.70e-02  4.65e-01 -3.00e-02  3.87e-02]
 [ 7.11e-02 -2.36e-01  4.32e-01 -1.88e-01  3.99e-02]]
SymNet parameters
[[-4.76e-03  2.82e-04 -7.27e-01  2.18e-03 -3.67e-02  2.94e-03  3.49e-04 -9.34e-04
   6.25e-05 -1.50e-03 -9.13e-04 -1.04e-03]
 [-5.75e-04 -9.33e-04 -9.87e-04 -2.27e-04 -2.69e-04 -1.51e-03  6.59e-01  4.10e-02
  -3.84e-03  1.87e-03 -3.41e-04 -1.50e-03]]
SymNet parameters
[7.26e-05 3.43e-05]
SymNet parameters
[[ 6.82e-04 -7.52e-04  1.08e+00 -4.56e-03 -1.07e-02  2.59e-03 -1.06e-03  1.46e-03
   5.50e-04  4.27e-04 -2.61e-04 -1.13e-03 -7.96e-03]
 [ 6.73e-05 -2.22e-03 -9.81e-04  1.91e-03  5.15e-04 -1.87e-04 -1.02e+00  7.82e-03
   5.75e-03 -2.61e-04  2.18e-04  6.69e-04 -3.68e-03]]
SymNet parameters
[8.60e-04 6.94e-05]
SymNet parameters
[[ 7.55e-02 -8.64e-01  4.44e-04 -1.15e-02 -3.09e-03  2.61e-03 -1.73e-03 -1.57e-04
  -1.36e-02  3.02e-04  1.72e-03 -1.48e-03 -2.90e-01  5.20e-02]
 [-1.09e+00 -4.62e-03  6.20e-03 -7.49e-02 -7.04e-04  6.53e-04 -4.98e-04 -8.10e-04
   3.73e-03  2.14e-03 -1.57e-03  2.13e-04  2.68e-04  7.11e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-2.53e-01 -3.28e-04 -1.12e-04  2.26e-01  1.08e-02 -7.41e-03  2.57e-04 -1.34e-04
  -1.02e-03 -7.62e-03 -5.62e-04  4.56e-03  4.04e-04  1.70e-01  5.35e-02]
 [-5.07e-01 -7.70e-02 -3.21e-05 -6.94e-03 -7.46e-04 -2.27e-03  2.28e-02 -3.46e-03
   6.72e-02  1.68e-03 -2.77e-04 -1.39e-03  4.91e-04 -9.49e-03  8.61e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 2.57e-01 -2.20e-01  6.37e-03  1.39e-03 -8.11e-04  1.50e-03 -2.66e-05  2.38e-03
  -4.17e-02 -9.70e-04  5.70e-04  2.64e-04 -9.53e-02  2.86e-02 -7.76e-03 -2.27e-02]
 [ 3.66e-04 -2.07e-04  2.33e-04 -3.67e-01 -3.16e-04 -2.35e-04 -9.05e-04 -2.65e-04
   1.55e-02  1.29e-02 -8.62e-03  2.95e-03  6.01e-04  1.54e-01 -1.01e-01 -3.82e-02]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 3.48e-04 -1.28e-03 -1.09e-04  4.91e-02  9.32e-04  5.28e-02 -8.34e-04  4.39e-04
  -1.91e-03 -3.19e-04 -4.72e-04  2.96e-04  3.11e-01  7.52e-01 -1.04e+00 -6.63e-01
   7.07e-01]]
SymNet parameters
[0.]
SymNet parameters
[[-4.08e-02  1.18e-02  1.34e-03 -1.36e-03  1.18e-04  1.28e-05 -1.24e+00 -2.83e-01
   1.64e-02  1.53e-03 -1.84e-02  2.03e-03]
 [-1.53e+00  2.57e-02 -3.07e-03  4.04e-04  3.09e-04  1.82e-03 -6.32e-04  4.42e-03
  -3.95e-01 -2.30e-04 -3.34e-03 -1.46e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 4.49e-02 -1.39e-02 -1.40e-03  1.66e-03 -1.01e-04 -7.44e-05  1.38e+00 -3.83e-01
   4.39e-03 -5.04e-04  1.86e-02 -1.83e-03 -3.45e-04]
 [-1.24e+00 -4.77e-03  1.94e-03 -1.03e-03  2.48e-04  7.62e-04  8.81e-03 -4.18e-03
   2.52e-01  1.92e-04 -4.03e-03  1.14e-04 -9.58e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-0.04 -0.1   0.02 -0.   -0.   -0.   -0.08  0.02  0.23 -0.01 -0.01  0.09  0.01  0.  ]
 [-0.11 -0.09  0.02 -0.01  0.01 -0.01  0.    0.    0.27  0.01 -0.   -0.07  0.02  0.02]]
SymNet parameters
[-4.38e-05  1.46e-04]
SymNet parameters
[[ 1.52e-02 -1.22e-01  2.49e-02 -2.48e-03 -2.72e-03 -5.44e-04 -1.52e-02  2.96e-02
   6.98e-02 -4.05e-03 -1.32e-04  8.32e-03  4.37e-02 -2.53e-02  3.40e-01]
 [ 1.99e-02  7.98e-05 -1.14e-03  1.51e-03  4.37e-03  6.00e-04  4.12e-01  8.42e-02
   7.16e-02  7.72e-03  2.29e-02  1.15e-02 -9.74e-02 -1.16e-01  1.14e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 7.01e-02  5.89e-02 -2.11e-04  2.46e-03 -2.61e-03  4.49e-03 -6.99e-02  7.99e-02
   3.83e-01 -4.49e-03 -3.89e-03 -2.68e-03  7.50e-02 -4.75e-02 -2.21e-01 -3.32e-02]
 [ 8.78e-04  4.79e-03  3.83e-03 -5.06e-03  1.41e-03  5.38e-04  3.53e-01  1.22e-02
   1.35e-02  4.56e-03 -4.05e-02  2.94e-03 -4.52e-02 -5.42e-02  3.97e-02  2.02e-01]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 2.15e-04  1.03e-03 -6.11e-04  2.18e-04  3.32e-04  3.17e-04  5.24e-04 -3.12e-03
  -3.14e-03  5.57e-02  4.52e-04  4.95e-02 -1.02e+00 -1.14e+00  4.24e-03  5.75e-01
  -7.53e-01]]
SymNet parameters
[0.]
finally, finish this stage
iter:   764    time: 208.91
Func: 2.61e+01  |g|: 8.21e+00
stableloss: 2.27e-01   dataloss: 2.16e+01   sparseloss: 2.77e+01 momentloss: 1.06e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00*u01**2, u10*v00*v10, u00*u10*v01, u01*u10*v00, u00*u11*v00, u10*v10, u01**2, u01*u10, u10*v01, 1, v10, u00*v10, u01, v00, u00**2*u02, u01*u02]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01  0.01  0.01 -0.    0.   -0.    0.
 -0.   -0.   -0.   -0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, v10**2, v01*v10, u01*v00, v10, v01, u01*v00*v10, u00*v00**2*v10, u00*v10, v00, u00*v00*v10, u00**2*v00**3, v00**2*v10]
[-0.98 -0.98  0.06  0.05  0.02  0.01  0.01  0.01  0.   -0.   -0.   -0.   -0.    0.
 -0.    0.    0.   -0.   -0.    0.  ]
block:  35
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -0.4229129763925281
current stage is: block-35
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9585, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2685,  1.8710,  1.7524, 19.2913, 14.2310, 16.8957,  0.2541,  1.5409,
         1.6258, 14.9927, 10.8997, 15.6761], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 258.70
Func: 6.28e+01  |g|: 2.76e+03
stableloss: 3.46e-01   dataloss: 5.76e+01   sparseloss: 2.77e+01 momentloss: 1.06e+01
iter:   200    time: 233.24
Func: 4.93e+01  |g|: 2.90e+02
stableloss: 3.44e-01   dataloss: 4.39e+01   sparseloss: 2.87e+01 momentloss: 1.18e+01
iter:   400    time: 233.68
Func: 4.84e+01  |g|: 5.66e+01
stableloss: 3.45e-01   dataloss: 4.28e+01   sparseloss: 2.95e+01 momentloss: 1.16e+01
iter:   600    time: 229.69
Func: 4.80e+01  |g|: 2.54e+01
stableloss: 3.43e-01   dataloss: 4.22e+01   sparseloss: 3.05e+01 momentloss: 1.16e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 47.903209
         Iterations: 700
         Function evaluations: 770
         Gradient evaluations: 755
convolution moment and kernels
[[ 1.    0.    0.01 -0.   -0.03]
 [ 0.    0.    0.01 -0.01 -0.04]
 [ 0.01  0.01  0.11  0.02  0.05]
 [ 0.06  0.05  0.03  0.01 -0.02]
 [-0.03  0.    0.06  0.01  0.02]]
[[ 0.02 -0.04  0.   -0.07  0.02]
 [-0.01 -0.04  0.24  0.02 -0.01]
 [-0.03  0.17  0.52  0.13 -0.01]
 [-0.02  0.01  0.12  0.02 -0.05]
 [ 0.01  0.02 -0.07  0.02  0.02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -7.78e-02 -7.35e-02]
 [ 0.00e+00  0.00e+00 -2.86e-03 -1.96e-03 -1.00e-02]
 [ 0.00e+00  2.39e-02 -9.74e-02  3.99e-02 -6.76e-02]
 [ 5.99e-03  5.05e-03  2.49e-02  3.33e-03  8.46e-03]
 [ 9.66e-04 -1.35e-02 -3.60e-02  3.22e-03 -2.45e-02]]
[[-0.02  0.05 -0.04  0.03 -0.02]
 [ 0.   -0.05  0.04 -0.02  0.03]
 [ 0.1  -0.49 -0.37  0.97 -0.2 ]
 [-0.02 -0.01 -0.02  0.03  0.  ]
 [-0.01  0.05 -0.04  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  6.90e-03 -1.30e-03]
 [ 1.00e+00  0.00e+00  1.61e-02  9.75e-04 -1.97e-02]
 [ 0.00e+00 -2.62e-04 -9.74e-02  4.05e-03 -4.31e-02]
 [-7.50e-02  1.26e-02  3.88e-02  2.82e-03 -1.37e-03]
 [-7.64e-02 -7.12e-03 -7.70e-02 -1.42e-03 -2.93e-02]]
[[-0.02 -0.    0.1  -0.02 -0.02]
 [ 0.05 -0.02 -0.52  0.    0.06]
 [-0.05  0.   -0.33 -0.03 -0.05]
 [ 0.03  0.01  0.96  0.01  0.04]
 [-0.02  0.03 -0.22  0.03 -0.02]]
[[ 0.    0.    1.    0.    0.15]
 [ 0.    0.    0.    0.    0.03]
 [ 0.    0.    0.61  0.07  0.33]
 [ 0.    0.01 -0.03 -0.01  0.02]
 [-0.09  0.04  0.29  0.06  0.15]]
[[ 0.07 -0.11  0.01 -0.19  0.13]
 [-0.08  0.17  0.17  0.33 -0.23]
 [ 0.07  0.66 -2.05  0.54  0.24]
 [-0.09  0.24  0.1   0.32 -0.21]
 [ 0.09 -0.21  0.14 -0.25  0.13]]
[[ 0.    0.    0.    0.   -0.05]
 [ 0.    1.    0.   -0.16  0.  ]
 [ 0.    0.   -0.01  0.1  -0.  ]
 [ 0.    0.   -0.02  0.41 -0.  ]
 [-0.1  -0.11 -0.08 -0.07 -0.02]]
[[ 0.13 -0.29 -0.04  0.26 -0.16]
 [-0.43  1.15  0.12 -0.98  0.53]
 [ 0.14 -0.15 -0.45  0.26 -0.41]
 [ 0.21 -0.77  0.1   0.95 -0.09]
 [-0.11  0.25 -0.01 -0.3   0.07]]
[[ 0.    0.    0.    0.   -0.09]
 [ 0.    0.    0.   -0.02  0.  ]
 [ 1.    0.    0.36 -0.03  0.2 ]
 [ 0.   -0.02 -0.06  0.02 -0.05]
 [ 0.17 -0.02  0.22 -0.04  0.09]]
[[ 1.08e-01 -1.63e-01  1.56e-01 -7.82e-02  5.90e-02]
 [-1.89e-01  1.32e-01  8.60e-01 -9.27e-02 -3.92e-02]
 [-1.72e-03  6.31e-01 -2.78e+00  8.11e-01 -1.63e-01]
 [-5.43e-02 -2.54e-01  1.26e+00 -3.12e-01  3.22e-02]
 [ 4.73e-02  1.26e-02 -2.94e-02  3.04e-02  2.15e-02]]
SymNet parameters
[[ 5.33e-04  7.48e-03 -6.53e-01 -1.79e-03 -2.59e-02  4.81e-03  5.71e-03 -3.73e-05
  -1.34e-03 -1.23e-04 -1.76e-04 -1.38e-03]
 [-2.21e-03  9.40e-03  9.55e-05 -1.28e-03  6.63e-05  1.47e-03  5.70e-01  2.87e-02
   4.07e-03 -1.79e-05  5.83e-04 -2.41e-04]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-6.00e-03 -7.67e-03  1.14e+00  2.38e-03  1.24e-03 -1.75e-04 -1.81e-03  1.70e-03
  -5.49e-04 -2.69e-04  4.51e-05 -2.85e-04  4.68e-04]
 [ 1.16e-02 -1.71e-02  4.30e-04  4.52e-03  6.73e-04 -4.35e-04 -1.18e+00 -1.34e-04
  -6.38e-03  1.13e-03 -6.57e-04  1.01e-03  7.97e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 1.83e-01 -7.05e-01  3.19e-04  9.09e-02 -1.28e-04 -1.45e-02 -4.03e-04  4.84e-03
  -3.87e-02 -5.66e-05 -4.09e-04  1.40e-03 -4.62e-01  8.18e-02]
 [-1.13e+00  1.61e-04 -1.24e-04 -1.26e-01 -1.39e-03  1.50e-02 -6.67e-03 -2.29e-03
   2.33e-02  8.56e-04  4.10e-04 -2.16e-03 -1.59e-03 -5.89e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-4.60e-01 -2.07e-02  5.27e-04  2.11e-01  3.09e-03 -9.98e-03 -4.99e-04 -6.81e-04
  -3.81e-02  1.93e-06 -2.07e-03  2.43e-03 -3.41e-04  1.34e-01  9.75e-02]
 [-3.25e-01 -9.16e-02  1.50e-02  1.55e-02  7.08e-04 -1.94e-03 -9.67e-03 -9.00e-04
   5.28e-02  8.50e-05  8.96e-04  2.30e-04 -2.42e-02 -1.19e-03  1.47e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 3.73e-01 -1.73e-01  7.52e-04  2.05e-02  1.00e-04 -3.80e-03  3.85e-04  1.07e-03
  -2.72e-02 -1.54e-04 -3.30e-04  6.87e-04 -1.43e-01  3.00e-02 -1.54e-02 -9.43e-03]
 [-3.63e-01 -9.35e-03 -4.04e-02 -5.84e-01 -3.73e-03  7.31e-02 -3.21e-04 -1.67e-02
   1.06e-01  6.60e-04  3.02e-03 -8.26e-03  3.09e-05  7.40e-02 -9.04e-02 -5.53e-02]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 1.49e-03  5.63e-04  1.19e-03  4.52e-02 -1.10e-03  5.56e-02 -1.03e-03  1.42e-03
  -3.05e-03 -4.10e-05 -5.08e-04  2.35e-06  1.38e-03  7.29e-01 -1.27e+00 -8.46e-01
   9.89e-01]]
SymNet parameters
[0.]
SymNet parameters
[[ 3.93e-02 -2.22e-02  2.52e-06 -1.96e-03  5.19e-04 -4.37e-04 -1.20e+00 -7.49e-02
  -1.41e-02  2.35e-03 -9.81e-03 -7.11e-03]
 [-1.00e+00  1.48e-01 -2.74e-02  5.51e-03  3.75e-04  6.52e-04  3.84e-02  2.14e-02
  -4.49e-01  2.39e-03  4.57e-03  1.21e-02]]
SymNet parameters
[0.01 0.  ]
SymNet parameters
[[-2.92e-02  1.07e-02  9.88e-04  1.63e-03 -3.81e-04  2.43e-04  8.35e-01 -4.77e-01
  -7.46e-03 -2.09e-03  8.26e-03  5.28e-03  1.07e-02]
 [-1.20e+00 -6.23e-03 -6.72e-03 -2.62e-03  4.29e-04 -8.84e-04 -5.55e-04 -7.95e-03
   8.42e-02  1.57e-03 -1.82e-02 -1.22e-02 -6.64e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 0.2  -0.07  0.02 -0.   -0.    0.   -0.06  0.    0.17 -0.01 -0.02  0.03 -0.02 -0.02]
 [-0.15 -0.08  0.   -0.02  0.   -0.    0.02  0.03  0.21  0.   -0.03 -0.07  0.01 -0.  ]]
SymNet parameters
[-4.37e-05 -4.54e-05]
SymNet parameters
[[ 2.11e-04 -1.96e-01  2.63e-02 -6.63e-03 -3.86e-04 -8.24e-04 -2.30e-01  8.96e-02
  -9.76e-02 -2.57e-03 -1.14e-02 -1.94e-02  4.65e-02 -1.70e-02  3.22e-01]
 [-1.21e-01  3.70e-02  1.76e-04  1.33e-02 -1.84e-03  2.82e-03  5.40e-01  5.66e-02
  -5.80e-02 -4.31e-03  5.86e-02  3.59e-02 -4.22e-02 -5.11e-02  1.96e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-0.04  0.18 -0.03  0.01  0.    0.   -0.12  0.14  0.2   0.    0.01  0.02  0.07 -0.01
  -0.27 -0.02]
 [ 0.04 -0.02 -0.   -0.01  0.   -0.    0.64  0.01  0.02  0.   -0.06 -0.03 -0.03 -0.05
  -0.06  0.06]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-3.57e-04 -1.25e-03 -9.51e-04 -8.36e-04 -9.49e-05  3.68e-04  6.67e-04  1.73e-04
   3.30e-03  5.57e-02 -5.65e-04  4.84e-02 -1.31e+00 -1.52e+00 -1.64e-02  1.07e+00
  -1.02e+00]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   700    time: 171.37
Func: 4.79e+01  |g|: 2.54e+01
stableloss: 3.43e-01   dataloss: 4.21e+01   sparseloss: 3.06e+01 momentloss: 1.16e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00*u01**2, u00*u10*v01, u10*v00*v10, u01*u10*v00, u00*u11*v00, u00, u01*u10, u01*u02, u10*v10, u00**3, v10, v00, u10, u01**2*u02, u00*v10, u00**2*u10]
[-0.99 -0.98  0.06  0.05  0.02  0.01  0.01  0.01  0.01  0.01 -0.01  0.   -0.   -0.
 -0.   -0.    0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v01*v10, u00*v00*v11, v10, v10**2, u10*v01, v00, v00**2, u01*v01, v00**3, 1, u01, v00*v01, v00**2*v10, u00*u10*v01]
[-0.99 -0.98  0.06  0.05  0.02  0.01  0.01  0.01  0.01 -0.01 -0.    0.    0.    0.
 -0.   -0.   -0.   -0.   -0.   -0.  ]
block:  40
name:  burgers-2-central-sparse0.005-noise0.001
device:  cuda:2
generate a random number to check random seed:  -0.9221142853958083
current stage is: block-40
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8968, device='cuda:2', dtype=torch.float64)
u_obs variance
tensor([ 0.2628,  1.8077,  1.6499, 17.5477, 14.9432, 15.7201,  0.2577,  1.6523,
         1.6778, 14.9070, 13.9424, 16.9332], device='cuda:2',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 242.26
Func: 7.85e+01  |g|: 9.78e+03
stableloss: 4.28e-01   dataloss: 7.19e+01   sparseloss: 3.06e+01 momentloss: 1.16e+01
iter:   200    time: 265.89
Func: 6.49e+01  |g|: 8.63e+02
stableloss: 4.07e-01   dataloss: 5.84e+01   sparseloss: 3.01e+01 momentloss: 1.22e+01
iter:   400    time: 267.88
Func: 6.33e+01  |g|: 1.13e+02
stableloss: 4.10e-01   dataloss: 5.71e+01   sparseloss: 2.87e+01 momentloss: 1.18e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 63.164842
         Iterations: 459
         Function evaluations: 531
         Gradient evaluations: 517
convolution moment and kernels
[[ 1.    0.   -0.02  0.01 -0.02]
 [ 0.    0.    0.03 -0.02 -0.  ]
 [-0.09 -0.    0.06  0.03  0.03]
 [ 0.02 -0.01  0.01 -0.02 -0.01]
 [-0.07 -0.    0.02  0.02  0.01]]
[[ 1.12e-03 -1.73e-02 -1.39e-02 -6.88e-02  2.78e-02]
 [ 4.30e-03  1.50e-02  8.60e-02  1.24e-01 -5.13e-02]
 [-4.09e-02  8.33e-02  7.98e-01 -5.85e-02  2.33e-02]
 [ 9.79e-03 -2.08e-02  1.00e-01  8.12e-02 -3.04e-02]
 [-2.79e-04  1.62e-02 -6.51e-02 -1.33e-02  1.04e-02]]
[[ 0.    1.    0.   -0.08 -0.06]
 [ 0.    0.   -0.    0.01  0.  ]
 [ 0.    0.01 -0.1   0.01 -0.07]
 [-0.    0.01 -0.01  0.   -0.01]
 [ 0.   -0.02 -0.04 -0.02 -0.03]]
[[-0.01  0.04 -0.04  0.04 -0.02]
 [-0.02  0.01 -0.03 -0.01  0.03]
 [ 0.12 -0.57 -0.29  0.99 -0.22]
 [-0.01 -0.03  0.05 -0.08  0.06]
 [-0.02  0.05 -0.06  0.06 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  2.26e-04  3.24e-03]
 [ 1.00e+00  0.00e+00  2.13e-02  5.81e-05 -5.70e-03]
 [ 0.00e+00 -4.77e-04 -9.01e-02  7.20e-03 -2.74e-02]
 [-8.15e-02  8.35e-04  1.58e-02 -5.18e-03 -9.43e-03]
 [-8.49e-02 -5.58e-03 -8.13e-02 -8.49e-04 -2.75e-02]]
[[-0.02 -0.02  0.11 -0.03 -0.01]
 [ 0.05 -0.   -0.52  0.01  0.05]
 [-0.06  0.02 -0.41  0.02 -0.08]
 [ 0.05 -0.04  1.05 -0.05  0.07]
 [-0.02  0.03 -0.22  0.03 -0.03]]
[[ 0.    0.    1.    0.    0.05]
 [ 0.    0.    0.    0.01 -0.06]
 [ 0.    0.    0.64  0.05  0.33]
 [ 0.   -0.    0.01 -0.02 -0.04]
 [-0.15  0.03  0.34  0.02  0.15]]
[[ 0.11 -0.19  0.   -0.2   0.13]
 [-0.13  0.12  0.71  0.04 -0.15]
 [ 0.04  1.15 -3.51  1.4   0.02]
 [-0.15  0.13  0.79 -0.06 -0.12]
 [ 0.09 -0.07 -0.2  -0.04  0.09]]
[[ 0.    0.    0.    0.    0.05]
 [ 0.    1.    0.    0.03 -0.18]
 [ 0.    0.    0.05  0.09 -0.01]
 [ 0.   -0.08  0.27  0.31  0.01]
 [-0.04 -0.09  0.06 -0.03  0.01]]
[[ 0.1  -0.29  0.12  0.13 -0.1 ]
 [-0.23  0.61  0.33 -0.93  0.36]
 [ 0.26 -0.25  0.02 -0.21 -0.04]
 [-0.02 -0.67  0.16  0.93 -0.26]
 [-0.06  0.39 -0.32 -0.13  0.09]]
[[ 0.    0.    0.    0.   -0.1 ]
 [ 0.    0.    0.   -0.05  0.04]
 [ 1.    0.    0.34 -0.06  0.11]
 [ 0.   -0.01 -0.01  0.01  0.03]
 [ 0.24  0.02  0.24 -0.    0.08]]
[[ 0.05  0.01  0.01  0.05  0.04]
 [-0.14  0.1   0.51  0.05 -0.15]
 [ 0.01  0.34 -1.73  0.19  0.14]
 [-0.09  0.02  0.44  0.2  -0.2 ]
 [ 0.06 -0.06  0.15 -0.07  0.07]]
SymNet parameters
[[ 2.93e-03 -9.31e-03 -5.62e-01  4.44e-06 -3.02e-02 -1.85e-03  9.43e-03 -1.37e-03
  -1.64e-03 -1.82e-04  1.77e-04 -6.39e-04]
 [-4.70e-03 -1.04e-03 -1.48e-03  1.73e-03 -9.94e-04  6.55e-04  5.86e-01  3.65e-02
   3.37e-04  1.38e-03  7.37e-04 -2.88e-05]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-5.27e-03  1.67e-02  1.08e+00  5.78e-04  3.89e-05 -6.98e-04 -5.40e-04  1.97e-04
   7.76e-04  2.82e-04 -5.19e-05  3.55e-05  1.70e-02]
 [ 1.66e-02 -3.22e-03  2.29e-03 -3.91e-03  1.36e-03  9.19e-04 -1.18e+00  6.47e-04
  -2.44e-03 -1.77e-04  9.90e-04 -2.31e-03 -1.30e-02]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 7.68e-02 -7.43e-01 -3.60e-03  3.80e-02  2.08e-03 -2.62e-03  1.66e-03  7.03e-04
  -2.98e-02  1.04e-04  1.21e-03 -1.21e-03 -4.10e-01  4.84e-02]
 [-9.90e-01 -2.54e-03  2.23e-03 -9.37e-02 -3.62e-03  3.21e-03  1.58e-02 -7.38e-04
   3.93e-02 -1.30e-03 -2.83e-04  4.65e-04 -1.98e-02  7.64e-03]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[-3.70e-01  2.18e-03 -6.77e-03  2.02e-01  6.36e-03 -1.15e-02 -1.51e-04  1.17e-04
  -7.54e-02  5.56e-03 -5.96e-03  3.81e-04  5.63e-05  1.25e-01  9.29e-02]
 [-3.55e-01 -1.66e-01 -2.30e-02  9.12e-03  3.51e-04 -1.48e-04 -2.03e-02  1.68e-03
   5.17e-02 -1.12e-03 -6.80e-05  1.53e-03 -2.67e-02 -6.85e-03  1.39e-02]]
SymNet parameters
[ 5.75e-05 -1.03e-02]
SymNet parameters
[[ 3.01e-01 -1.76e-01 -1.30e-03  8.72e-03  5.49e-04 -3.78e-04  4.60e-03 -1.27e-03
  -2.99e-02  6.13e-04  1.05e-03 -8.80e-04 -1.21e-01  1.97e-02 -1.47e-02 -1.13e-02]
 [ 6.32e-04 -8.75e-03  4.15e-04 -3.68e-01 -2.10e-02  2.19e-02  7.33e-04 -8.60e-04
   1.46e-01 -3.88e-03  1.54e-04  3.08e-03  1.54e-04  1.40e-01 -7.59e-02 -6.88e-02]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 4.19e-04 -2.25e-03 -6.93e-04  4.30e-02 -1.17e-03  5.67e-02  1.25e-03 -1.10e-03
   8.22e-04 -1.77e-04 -2.96e-04 -2.60e-04  6.76e-04  7.68e-01 -1.27e+00 -7.48e-01
   1.02e+00]]
SymNet parameters
[0.]
SymNet parameters
[[-3.40e-02  5.88e-03 -2.40e-03 -2.73e-04  2.22e-04 -1.20e-03 -1.29e+00 -1.06e-01
  -1.35e-02 -1.41e-03 -2.15e-02 -1.60e-02]
 [-9.20e-01  6.06e-02  1.60e-02  2.24e-03  1.95e-04 -1.44e-03 -5.34e-04  1.48e-02
  -4.85e-01  2.58e-03  1.30e-02  5.61e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 2.41e-02 -1.11e-02 -6.82e-05  1.26e-04 -1.65e-04  7.63e-04  8.91e-01 -5.34e-01
   1.58e-02  1.09e-03  1.48e-02  1.14e-02  2.17e-03]
 [-1.18e+00 -1.20e-02 -6.84e-03 -8.33e-04  2.72e-04 -2.48e-03 -4.42e-02 -4.28e-03
   7.70e-02 -2.06e-04 -4.23e-04 -2.61e-03  8.40e-04]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 0.11 -0.06 -0.01 -0.   -0.    0.   -0.01 -0.01  0.2  -0.01 -0.02  0.05 -0.03 -0.02]
 [-0.17 -0.05 -0.04 -0.    0.01 -0.   -0.01 -0.01  0.16 -0.   -0.03 -0.07  0.02  0.01]]
SymNet parameters
[ 1.64e-04 -4.85e-05]
SymNet parameters
[[-9.05e-03 -1.26e-01 -3.59e-02 -3.94e-03 -5.42e-04  1.87e-04 -2.64e-01  4.88e-04
   1.20e-03 -5.11e-03  1.80e-03  3.81e-04  4.09e-02 -1.65e-02  3.27e-01]
 [-1.97e-02 -6.37e-02 -6.16e-03  4.71e-03 -7.87e-04 -1.11e-03  5.57e-01  1.05e-02
  -5.95e-02  3.04e-03  7.28e-02  4.97e-02 -9.00e-02 -6.27e-02 -3.91e-04]]
SymNet parameters
[ 7.78e-05 -8.24e-04]
SymNet parameters
[[-1.27e-02  1.11e-01  2.81e-02  2.81e-03 -1.05e-05  3.69e-04 -1.37e-01 -1.17e-02
   2.32e-01  2.26e-03 -6.59e-03 -5.91e-03  5.97e-02  4.88e-03 -2.33e-01 -2.47e-02]
 [-5.24e-02  5.72e-02  8.98e-03 -1.56e-04  1.70e-03 -1.56e-03  5.64e-01 -2.03e-02
  -2.57e-02  8.00e-04 -5.89e-02 -3.17e-02 -5.19e-02 -4.58e-02 -2.75e-02  6.79e-02]]
SymNet parameters
[-1.01e-04 -5.08e-06]
SymNet parameters
[[-4.61e-04 -7.79e-04 -1.23e-03 -3.57e-04  2.44e-04 -3.91e-05  2.57e-04 -3.53e-04
   2.48e-03  5.35e-02 -2.04e-03  5.05e-02 -1.21e+00 -1.36e+00 -5.94e-04  9.49e-01
  -1.12e+00]]
SymNet parameters
[0.]
finally, finish this stage
iter:   459    time: 149.04
Func: 6.32e+01  |g|: 9.99e+01
stableloss: 4.08e-01   dataloss: 5.70e+01   sparseloss: 2.86e+01 momentloss: 1.15e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00*u01**2, u10*v00*v10, u00*u10*v01, u01*u10*v00, u00*u11*v00, u00, u00**3, u10*v10, u01, u00*v00**2, u10, u01*u02, u01*u20, u00**2*u01, u00*v10, v00]
[-0.98 -0.98  0.06  0.05  0.02  0.01  0.01  0.01  0.01  0.01 -0.   -0.   -0.   -0.
 -0.    0.   -0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v01*v10, u00*u01*v01, u00*v00*v11, v00, u00*v00, u00, v00**3, 1, v10**2, u00*u10*v01, v01, u01*v00, u10*v01, v10*v20, v10]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01  0.01 -0.   -0.   -0.    0.   -0.
  0.   -0.   -0.   -0.   -0.    0.  ]
u_obs.abs().max()
tensor(3.9172, device='cuda:2', dtype=torch.float64)
model(u_obs[0],T=50*dt).abs().max()
tensor(3.4641, device='cuda:2', dtype=torch.float64)
model(u_obs[0],T=100*dt).abs().max()
tensor(2.6389, device='cuda:2', dtype=torch.float64)
{'--name': 'burgers-2-upwind-sparse0.005-noise0.001', '--dtype': 'double', '--device': 'cuda:0', '--constraint': '2', '--dt': 0.01, '--cell_num': 1, '--eps': 6.283185307179586, '--blocks': [0, 1, 2, 3, 4, 5, 6, 9, 12, 15, 18, 21, 24, 27, 30, 35, 40], '--kernel_size': 5, '--max_order': 2, '--dx': 0.19634954084936207, '--hidden_layers': 5, '--scheme': 'upwind', '--dataname': 'burgers', '--viscosity': 0.05, '--zoom': 4, '--max_dt': 0.000625, '--batch_size': 28, '--data_timescheme': 'rk2', '--channel_names': 'u,v', '--freq': 4, '--data_start_time': 1.0, '--start_noise': 0.001, '--end_noise': 0.001, '--stablize': 0.0, '--sparsity': 0.005, '--momentsparsity': 0.001, '--npseed': -1, '--torchseed': -1, '--maxiter': 2000, '--recordfile': 'None', '--recordcycle': 200, '--savecycle': -1, '--start_from': -1}
block:  0
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  1.6906926641428281
current stage is: warmup
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8871, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2652,  2.1568,  2.1372, 19.5794, 10.1412, 18.5577,  0.2598,  1.9818,
         2.0713, 17.2177,  9.7103, 19.1620], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 13.02
Func: 5.72e+00  |g|: 1.83e+00
stableloss: 2.00e-03   dataloss: 5.72e+00   sparseloss: 2.44e+01 momentloss: 7.27e+00
iter:   200    time: 13.91
Func: 4.05e-02  |g|: 3.48e-02
stableloss: 1.33e-02   dataloss: 4.05e-02   sparseloss: 5.34e+01 momentloss: 7.27e+00
iter:   400    time: 10.90
Func: 3.73e-02  |g|: 1.49e-02
stableloss: 1.29e-02   dataloss: 3.73e-02   sparseloss: 6.33e+01 momentloss: 7.27e+00
iter:   600    time: 8.97
Func: 3.68e-02  |g|: 9.50e-03
stableloss: 1.30e-02   dataloss: 3.68e-02   sparseloss: 7.04e+01 momentloss: 7.27e+00
iter:   800    time: 8.97
Func: 3.65e-02  |g|: 1.29e-02
stableloss: 1.30e-02   dataloss: 3.65e-02   sparseloss: 7.86e+01 momentloss: 7.27e+00
iter:  1000    time: 8.88
Func: 3.61e-02  |g|: 1.39e-02
stableloss: 1.30e-02   dataloss: 3.61e-02   sparseloss: 8.08e+01 momentloss: 7.27e+00
iter:  1200    time: 8.80
Func: 3.59e-02  |g|: 1.92e-02
stableloss: 1.30e-02   dataloss: 3.59e-02   sparseloss: 8.78e+01 momentloss: 7.27e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.035790
         Iterations: 1303
         Function evaluations: 1375
         Gradient evaluations: 1370
convolution moment and kernels
[[1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 0.    1.    0.   -0.33 -0.25]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 2.78e-17  3.33e-16 -1.50e+00  2.00e+00 -5.00e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[ 0.    0.    0.    0.    0.  ]
 [ 1.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [-0.33  0.    0.    0.    0.  ]
 [-0.25  0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  2.78e-17  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  3.33e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.50e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -5.00e-01  0.00e+00  0.00e+00]]
[[0.   0.   1.   0.   0.08]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [-2.22e-16  1.00e+00 -2.00e+00  1.00e+00 -1.53e-16]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 6.94e-03 -5.56e-02  9.25e-18  5.56e-02 -6.94e-03]
 [-5.56e-02  4.44e-01 -7.40e-17 -4.44e-01  5.56e-02]
 [ 9.25e-18 -7.40e-17  1.23e-32  7.40e-17 -9.25e-18]
 [ 5.56e-02 -4.44e-01  7.40e-17  4.44e-01 -5.56e-02]
 [-6.94e-03  5.56e-02 -9.25e-18 -5.56e-02  6.94e-03]]
[[0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [1.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.08 0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00 -2.22e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.53e-16  0.00e+00  0.00e+00]]
SymNet parameters
[[ 2.04e+00 -1.55e-02  1.26e-01 -3.65e-02 -7.29e-03 -4.30e-04  8.75e-01  7.94e-03
   8.36e-02  2.80e-02  2.19e-02  2.67e-02]
 [ 7.98e-01  1.22e+00 -1.85e+00  3.98e-01 -2.41e-01  4.27e-01  5.20e+00  5.66e-02
  -3.51e-01 -4.13e-02 -4.72e-02 -8.04e-02]]
SymNet parameters
[-0.11 -0.3 ]
SymNet parameters
[[ 9.59e-01  1.35e+00 -9.89e-01  4.07e-01  4.71e-02  1.74e-01 -2.26e-01  4.54e-01
   7.67e-02 -6.39e-02 -2.71e-02  4.89e-02  1.22e-02]
 [ 8.70e-01  2.52e-02  1.10e-01 -3.56e-03 -5.37e-04 -1.91e-03  1.61e-01 -4.06e-04
  -3.82e-03  2.94e-05 -2.13e-03 -5.52e-04  3.03e-03]]
SymNet parameters
[ 0.07 -0.73]
SymNet parameters
[[ 1.05e+00  5.84e-02  6.28e-01  1.35e-01 -4.60e-02 -2.51e-02 -2.59e+00 -1.34e-01
   8.23e-02  2.61e-02  4.99e-03  6.40e-03 -4.97e-04  3.95e-03]
 [ 1.40e+00 -5.30e-01  4.60e-01  1.68e-01  7.69e-02  6.00e-02  2.86e+00 -3.44e-01
  -1.42e-01  4.94e-02 -1.88e-02 -6.90e-02  1.35e-02 -2.70e-02]]
SymNet parameters
[-0.16  0.21]
SymNet parameters
[[-1.01e+00  3.16e-01  3.93e-01 -4.37e-02 -7.76e-03 -1.98e-02  1.53e+00 -4.97e-02
  -6.51e-03  6.41e-03  2.58e-03 -6.01e-03  4.97e-03 -2.27e-03  5.44e-03]
 [-7.95e-01  5.46e-01 -2.17e-01 -9.73e-03  6.87e-04 -7.54e-03 -1.79e+00 -1.39e-02
  -6.14e-03  1.51e-03  3.62e-03  1.46e-03 -6.30e-03  2.98e-02  1.27e-02]]
SymNet parameters
[-0.05  0.25]
SymNet parameters
[[-2.87e-01 -1.76e-01  5.01e-02  2.61e-02  4.05e-03  1.07e-02 -8.28e-01  2.72e-02
   2.30e-03 -4.12e-03 -6.67e-04  3.53e-03  5.77e-04  2.18e-04 -2.00e-03 -1.02e-03]
 [-8.46e-01 -3.87e-01 -3.76e-01  3.24e-02  2.09e-03  1.17e-02  1.48e+00  3.21e-02
   9.11e-03 -4.08e-03 -4.89e-03  3.90e-03  1.37e-03  7.78e-03 -7.64e-03 -2.21e-02]]
SymNet parameters
[ 0.39 -0.32]
SymNet parameters
[[-1.81e-01 -2.96e-01 -9.88e-02 -2.77e-03 -6.15e-03  2.38e-02  7.11e-01 -5.30e-02
  -8.55e-03  7.75e-03  1.92e-04 -4.84e-03 -2.30e-03 -1.71e-01 -5.43e-03  4.88e-01
  -1.09e+00]]
SymNet parameters
[-0.13]
SymNet parameters
[[-0.83 -0.15 -0.06 -0.   -0.02  0.   -1.09  0.01  0.74 -0.06 -0.01 -0.25]
 [-0.2   0.    0.    0.01 -0.01  0.01 -0.55 -0.07  0.05 -0.01  0.04 -0.05]]
SymNet parameters
[ 1.1  -0.43]
SymNet parameters
[[ 8.93e-01  7.67e-04  6.50e-02  3.63e-02 -6.46e-03  5.90e-03  8.43e-01 -2.96e-01
   1.19e+00  3.42e-02  1.46e-01  1.22e-01  1.47e-01]
 [ 7.64e-01 -5.70e-02 -2.30e-02 -5.91e-03 -1.96e-03 -1.81e-03 -1.68e+00 -3.44e-01
  -1.29e-01 -1.62e-02 -1.93e-02 -4.26e-02 -4.82e-02]]
SymNet parameters
[-0.08 -0.41]
SymNet parameters
[[ 1.55e-01  2.29e-02  1.08e-02  1.37e-03  3.81e-03 -8.39e-04  4.21e-01 -6.95e-03
  -1.37e-01  1.11e-02  6.09e-04  4.26e-02  4.30e-03 -8.68e-04]
 [-1.95e+00 -2.62e-01  5.21e-02  1.28e-01 -9.82e-02  5.58e-02 -8.42e-01 -6.74e-02
   1.29e+00 -9.91e-02  5.89e-01 -4.37e-01  2.33e-01  2.42e-02]]
SymNet parameters
[-0.59 -0.34]
SymNet parameters
[[-5.50e-01  5.94e-02 -1.54e-02 -1.90e-02  6.39e-03  1.18e-03  2.93e-01 -1.45e+00
  -6.06e-01 -1.28e-02 -7.15e-02 -6.28e-02  9.59e-02 -1.41e-02  7.94e-02]
 [ 1.52e+00  4.25e-02 -2.64e-04 -1.36e-02  5.95e-03 -7.21e-04  2.93e-01  6.27e-02
  -3.95e-01  3.78e-03 -4.58e-02  1.92e-02 -6.13e-02  2.14e-04 -1.91e-02]]
SymNet parameters
[ 0.   -0.62]
SymNet parameters
[[ 1.   -0.88 -0.15  0.09  0.   -0.04 -0.67  0.22 -1.22  0.01  0.12  0.02  0.62  0.06
   0.21  0.02]
 [-0.35 -0.26 -0.32 -0.12 -0.1  -0.04  0.27 -0.52 -0.95 -0.36 -0.4  -0.79 -0.7   0.1
   0.16  0.25]]
SymNet parameters
[ 0.03 -0.05]
SymNet parameters
[[-0.71 -0.15 -0.01  0.04 -0.03  0.01  0.1  -0.29  0.7  -0.    0.15 -0.15  1.17  0.33
   0.59  0.35  0.01]]
SymNet parameters
[0.37]
finally, finish this stage
iter:  1303    time: 6.68
Func: 3.58e-02  |g|: 1.42e-02
stableloss: 1.30e-02   dataloss: 3.58e-02   sparseloss: 9.20e+01 momentloss: 7.27e+00
current expression:
[u00*u01, u10*v00, u00, u20, u02, u00**3, v00, u00*u11*v00, u00**2*u02, 1, u00*u01**2, u00*v00, u00**2, u01*u10*v00, u00*u10*v01, v01, v00*v01, u01*v00, u00**2*v00**2, u01]
[-0.89 -0.88  0.08  0.04  0.04 -0.04  0.01  0.01 -0.01  0.01  0.01 -0.01 -0.01  0.01
  0.01 -0.01 -0.01 -0.    0.    0.  ]
[v00*v10, u00*v01, v00, v20, v02, v00**3, u00**2*v00, u00, v00*v10**2, v00**2*v20, u00*v00*v11, u00*v01*v10, u01, u00*v00**2, u00*v00, u00*u01*v01, v00**2*v01, v10, u00**3, u10*v00]
[-0.89 -0.88  0.04  0.04  0.04 -0.03  0.01  0.01  0.01 -0.01  0.01  0.01 -0.01  0.01
  0.01  0.01  0.01  0.01 -0.   -0.  ]
block:  1
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.46791011632291146
current stage is: block-1
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7016, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2742,  2.2040,  2.2316, 20.1506, 10.7846, 19.9427,  0.2495,  1.9614,
         2.0957, 17.0934, 10.3445, 19.2568], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 996.76
Func: 5.04e-01  |g|: 8.85e-01
stableloss: 1.11e-02   dataloss: 3.72e-02   sparseloss: 9.20e+01 momentloss: 7.27e+00
iter:   200    time: 10.71
Func: 1.04e-01  |g|: 8.87e-02
stableloss: 1.07e-02   dataloss: 1.83e-02   sparseloss: 1.58e+01 momentloss: 6.73e+00
iter:   400    time: 15.93
Func: 8.62e-02  |g|: 2.63e-02
stableloss: 1.07e-02   dataloss: 1.83e-02   sparseloss: 1.22e+01 momentloss: 6.71e+00
iter:   600    time: 16.69
Func: 8.51e-02  |g|: 7.78e-03
stableloss: 1.07e-02   dataloss: 1.82e-02   sparseloss: 1.20e+01 momentloss: 6.70e+00
iter:   800    time: 14.16
Func: 8.50e-02  |g|: 4.33e-08
stableloss: 1.07e-02   dataloss: 1.82e-02   sparseloss: 1.20e+01 momentloss: 6.69e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.085042
         Iterations: 817
         Function evaluations: 850
         Gradient evaluations: 850
convolution moment and kernels
[[ 1.00e+00  0.00e+00  1.20e-03 -2.41e-03 -4.51e-02]
 [ 0.00e+00 -1.54e-04  2.60e-03  7.15e-04  5.91e-03]
 [ 3.51e-03  1.59e-03 -5.68e-05 -1.63e-03 -2.51e-03]
 [-4.38e-03  1.38e-03  5.09e-03 -1.20e-03 -5.81e-03]
 [-1.43e-02  1.67e-03  4.22e-03 -6.02e-04  3.88e-03]]
[[ 7.31e-03 -2.78e-02  2.78e-02 -2.71e-02  7.36e-03]
 [-2.70e-02  9.70e-02 -8.02e-02  9.58e-02 -2.80e-02]
 [-1.62e-02  9.16e-02  7.46e-01  1.04e-01 -1.92e-02]
 [-8.90e-03  1.54e-02  6.23e-02  3.53e-03 -5.99e-03]
 [ 8.98e-04  3.33e-03 -2.90e-02  8.57e-03 -6.00e-04]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.43e-01 -9.53e-02]
 [ 0.00e+00  0.00e+00 -1.27e-03  3.36e-04 -3.40e-03]
 [ 0.00e+00  2.78e-03 -1.64e-02  8.45e-03 -2.73e-02]
 [-2.26e-03 -4.49e-03  4.84e-03  1.56e-02  9.84e-03]
 [-4.05e-03 -1.27e-02 -4.43e-03 -1.05e-02 -3.29e-03]]
[[ 0.    0.01 -0.03  0.03 -0.01]
 [-0.04  0.08 -0.06  0.01  0.02]
 [ 0.14 -0.63 -0.34  1.05 -0.24]
 [-0.05  0.13 -0.17  0.13 -0.02]
 [ 0.   -0.01  0.02 -0.02  0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  1.94e-03 -1.52e-03]
 [ 1.00e+00  0.00e+00  5.13e-03 -4.38e-04 -9.10e-03]
 [ 0.00e+00  1.40e-03 -8.73e-03 -5.36e-03 -4.37e-03]
 [-1.50e-01  3.24e-03  4.67e-03  3.52e-03 -6.97e-03]
 [-7.40e-02  4.38e-03 -5.56e-03 -2.29e-03  1.23e-03]]
[[ 6.92e-03 -3.17e-02  1.27e-01 -2.09e-02  2.84e-03]
 [-1.66e-02  7.65e-02 -6.20e-01  4.83e-02 -8.69e-03]
 [ 1.88e-02 -9.61e-02 -3.15e-01 -6.90e-02  1.67e-02]
 [-1.13e-02  6.27e-02  1.03e+00  4.11e-02 -9.96e-03]
 [-3.76e-04 -3.34e-03 -2.32e-01  4.58e-03 -1.40e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  9.59e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  2.95e-03  2.83e-03]
 [ 0.00e+00  0.00e+00  3.19e-03  1.27e-04 -1.52e-03]
 [ 0.00e+00  3.10e-03  2.66e-03 -2.36e-03 -3.57e-03]
 [ 1.97e-02 -4.90e-05 -6.44e-04 -5.45e-04 -2.05e-02]]
[[-0.02  0.07 -0.08  0.07 -0.02]
 [ 0.07 -0.29  0.34 -0.28  0.07]
 [-0.19  1.75 -3.01  1.76 -0.19]
 [ 0.08 -0.33  0.42 -0.34  0.09]
 [-0.02  0.09 -0.12  0.09 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.81e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -2.01e-04 -2.64e-04]
 [ 0.00e+00  0.00e+00 -8.77e-05  2.25e-04  1.66e-04]
 [ 0.00e+00 -1.31e-04 -1.17e-04  4.42e-05  2.56e-04]
 [-1.06e-04  3.03e-04 -1.64e-06 -4.09e-04  2.66e-05]]
[[ 0.01 -0.06 -0.    0.06 -0.01]
 [-0.06  0.44  0.   -0.45  0.06]
 [ 0.   -0.   -0.    0.01 -0.  ]
 [ 0.05 -0.44 -0.    0.44 -0.05]
 [-0.01  0.05  0.   -0.06  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  8.68e-02]
 [ 0.00e+00  0.00e+00  0.00e+00  2.93e-03  2.40e-03]
 [ 1.00e+00  0.00e+00  3.29e-03 -1.56e-04 -1.84e-03]
 [ 0.00e+00  3.10e-03  2.62e-03 -2.29e-03 -3.23e-03]
 [ 9.76e-03 -6.38e-04 -8.30e-04  2.70e-04 -9.34e-03]]
[[-0.01  0.03 -0.11  0.02 -0.01]
 [ 0.03 -0.12  1.45 -0.1   0.03]
 [ 0.04 -0.15 -2.2  -0.16  0.04]
 [ 0.04 -0.15  1.52 -0.16  0.04]
 [-0.01  0.04 -0.14  0.05 -0.01]]
SymNet parameters
[[-2.01e-12  5.92e-12  3.16e-12  1.06e-11 -1.09e-11  8.86e-12  5.93e-12  1.02e-11
  -2.48e-12  5.55e-12  8.21e-12  1.03e-11]
 [-1.07e-11  6.14e-13  3.39e-12 -6.69e-12 -3.69e-12 -2.96e-12 -3.09e-13  2.22e-12
  -9.11e-13 -5.39e-12  5.23e-12  7.13e-12]]
SymNet parameters
[-5.72e-12 -5.84e-13]
SymNet parameters
[[-2.74e-12 -3.94e-12 -2.14e-12  1.86e-12  6.08e-12  7.39e-12  6.84e-12 -1.59e-11
   7.53e-12  6.88e-13  8.14e-12  1.11e-11  2.88e-11]
 [ 1.42e-11  8.56e-12 -2.34e-13  1.51e-11  3.74e-11 -8.91e-12 -3.98e-12  2.18e-12
   2.43e-13  3.31e-11  1.93e-12  2.49e-11 -7.35e-11]]
SymNet parameters
[3.53e-12 3.25e-12]
SymNet parameters
[[-5.79e-13 -4.51e-12 -1.28e-12 -8.46e-12  3.17e-13  5.27e-12  1.21e-11 -7.31e-12
  -3.92e-12  2.78e-12 -3.96e-12  1.39e-12 -1.42e-11  1.24e-12]
 [-6.37e-13 -4.34e-12 -1.22e-11 -6.77e-12  6.70e-12 -3.33e-12 -1.29e-12 -6.88e-12
  -2.26e-12 -1.55e-12  1.22e-11 -9.92e-12  3.52e-12 -1.07e-11]]
SymNet parameters
[1.2e-11 7.6e-13]
SymNet parameters
[[ 1.34e-04 -3.45e-04  9.85e-01  3.96e-04 -8.63e-04  6.27e-05 -1.75e-04  3.04e-04
  -2.79e-05  4.13e-05 -1.25e-04 -2.66e-04 -2.74e-11  3.90e-11  9.37e-11]
 [ 9.73e-05  6.20e-05 -1.43e-04  1.17e-04 -2.84e-04 -2.29e-05 -9.86e-01  2.47e-04
  -6.53e-07 -3.10e-06  1.57e-04  1.52e-05  1.25e-10  2.25e-11  3.50e-12]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 2.25e-05 -9.87e-01  1.13e-04  4.32e-04  2.61e-04  3.36e-04 -1.34e-04  8.12e-04
   2.73e-05  1.21e-04 -3.50e-04  4.04e-04 -1.03e-11 -5.74e-12  4.45e-11  1.24e-04]
 [-9.80e-01  4.62e-04  5.04e-05 -8.19e-04  3.45e-04 -3.33e-04  2.95e-04 -5.63e-04
   5.45e-04 -4.77e-04 -5.30e-04  3.15e-04 -1.30e-10 -1.08e-11 -7.54e-11 -6.74e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 9.09e-04  4.66e-04 -3.69e-04  4.94e-02 -2.30e-03  4.98e-02 -1.80e-04  2.67e-04
   9.46e-05 -1.14e-04 -5.22e-04  6.47e-04  2.96e-11 -1.85e-13 -1.96e-11  9.79e-01
  -9.89e-01]]
SymNet parameters
[1.95e-05]
SymNet parameters
[[-8.85e-12 -1.01e-11 -3.06e-12 -5.26e-11  1.22e-11 -5.01e-11  2.71e-13 -8.07e-12
   1.62e-12  1.57e-12 -1.98e-11 -8.07e-12]
 [ 1.67e-11 -1.65e-11 -3.55e-12 -3.31e-11  3.15e-11 -1.06e-10  1.67e-12 -1.56e-11
   2.95e-11  3.44e-11 -2.59e-11  3.71e-12]]
SymNet parameters
[7.61e-13 1.62e-11]
SymNet parameters
[[-8.06e-05  1.59e-04  2.50e-04  4.36e-04 -2.08e-04  4.05e-04  1.09e-04 -2.06e-04
   9.84e-01 -3.68e-04 -5.73e-04  5.12e-04 -3.26e-12]
 [ 1.28e-04 -3.07e-04  2.95e-04 -3.32e-04  2.24e-04  1.67e-04 -9.83e-01 -5.59e-04
   1.82e-03 -1.35e-04 -3.10e-05 -5.43e-04 -1.42e-11]]
SymNet parameters
[-4.05e-04  3.02e-05]
SymNet parameters
[[-1.15e-11 -1.87e-11 -2.81e-13 -1.66e-11  9.69e-11 -4.98e-11  1.94e-11 -7.87e-12
   7.44e-12  9.39e-11  3.19e-11 -1.45e-11 -2.03e-11 -2.07e-11]
 [-1.76e-12  2.77e-12 -1.06e-12 -1.15e-12 -8.14e-12 -6.89e-13  4.50e-12 -1.90e-11
   3.34e-12  5.97e-13 -9.72e-12 -9.29e-12  6.73e-12 -4.28e-12]]
SymNet parameters
[1.60e-11 5.17e-12]
SymNet parameters
[[-2.37e-04 -1.79e-05 -2.06e-04 -2.47e-04 -3.67e-05  1.24e-04  8.06e-05 -9.83e-01
   1.31e-04  6.21e-04  1.99e-03  1.65e-04 -3.05e-12 -2.70e-04  5.77e-12]
 [ 9.84e-01  3.52e-04 -7.22e-04 -4.88e-04  3.90e-04  4.90e-04 -2.04e-04 -9.14e-05
   5.60e-04 -3.18e-05  2.94e-04  1.88e-05 -2.18e-12 -2.11e-04 -1.54e-12]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-7.92e-12 -1.95e-13  9.21e-13  1.08e-12  6.52e-12 -5.03e-12 -3.18e-12  8.90e-13
  -1.34e-11  5.02e-12 -6.29e-12  9.20e-12 -1.07e-11 -7.52e-12  1.12e-11 -2.85e-13]
 [-2.24e-12  5.58e-12 -9.72e-12  8.44e-12  9.16e-12 -3.31e-12  8.99e-12  1.12e-11
   8.98e-13  3.93e-12  1.33e-11 -3.82e-12  8.80e-12  4.91e-12  8.91e-12  1.60e-11]]
SymNet parameters
[1.67e-12 1.15e-11]
SymNet parameters
[[-2.09e-04  5.05e-05 -2.05e-04  5.36e-05 -1.69e-04 -5.84e-05  4.17e-04  3.22e-04
   3.07e-05  4.98e-02 -5.85e-04  4.95e-02  4.75e-13  9.86e-01  4.37e-12  9.85e-01
  -9.57e-11]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   817    time: 1.40
Func: 8.50e-02  |g|: 3.73e-09
stableloss: 1.07e-02   dataloss: 1.82e-02   sparseloss: 1.20e+01 momentloss: 6.69e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u11, u00, u01, u11*v00, u01*u02, u00*v01, u10, v20, u01*v00, u01*v01, u01*v10, v11, u01*v11, u01*v02, u01**2]
[-9.57e-01 -9.51e-01  4.98e-02  4.94e-02  6.39e-03 -2.30e-03  1.77e-03  9.09e-04
  8.33e-04 -8.01e-04  7.87e-04 -7.12e-04  6.47e-04  6.23e-04 -5.51e-04  5.33e-04
 -5.22e-04 -5.18e-04 -4.66e-04  4.51e-04]
[v00*v10, u00*v01, v02, v20, u00*v11, v10**2, v01*v10, v00, u10*v01, v01, u00*v02, v11, v00*v11, v10*v20, v00*v20, u20*v01, u02*v01, u02*v00, u00, v00*v01]
[-9.54e-01 -9.53e-01  4.98e-02  4.95e-02  1.93e-03  1.77e-03 -1.09e-03  8.10e-04
  6.99e-04  6.25e-04  6.02e-04 -5.86e-04  5.54e-04 -5.26e-04 -4.96e-04 -4.74e-04
  4.73e-04 -4.23e-04 -4.06e-04  3.97e-04]
block:  2
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.531929813847547
current stage is: block-2
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8739, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2400,  1.5815,  1.6556, 19.1885,  9.1194, 17.7789,  0.2550,  1.7774,
         1.7603, 19.9938, 10.2103, 21.1631], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 9.59
Func: 2.24e-01  |g|: 6.95e-01
stableloss: 2.12e-02   dataloss: 9.08e-02   sparseloss: 1.20e+01 momentloss: 6.70e+00
iter:   200    time: 18.08
Func: 2.18e-01  |g|: 1.81e-03
stableloss: 2.01e-02   dataloss: 8.22e-02   sparseloss: 1.21e+01 momentloss: 7.29e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.218129
         Iterations: 290
         Function evaluations: 493
         Gradient evaluations: 479
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -2.51e-04  9.47e-03 -4.76e-02]
 [ 0.00e+00 -3.23e-04 -2.15e-02  3.49e-03 -3.12e-03]
 [ 1.71e-03 -4.34e-03  9.47e-03 -4.66e-03 -7.92e-03]
 [ 3.65e-02  7.85e-03 -9.35e-03 -2.12e-02  1.99e-02]
 [-6.75e-02  5.35e-03 -1.77e-03  3.71e-03  2.68e-03]]
[[-1.43e-02  4.18e-02 -1.28e-01  1.41e-02  4.49e-04]
 [ 1.94e-02 -1.87e-03  2.52e-01  6.19e-02 -2.20e-02]
 [-2.70e-02  1.57e-02  6.06e-01 -1.38e-02  9.23e-03]
 [-4.87e-02  2.19e-01 -6.07e-02  1.67e-01 -4.03e-02]
 [ 1.82e-02 -7.48e-02  4.56e-02 -4.82e-02  9.80e-03]]
[[ 0.    1.    0.   -0.12 -0.11]
 [ 0.    0.   -0.01 -0.   -0.01]
 [ 0.    0.01 -0.01  0.01 -0.05]
 [ 0.    0.01 -0.   -0.02 -0.  ]
 [-0.01 -0.02  0.   -0.03 -0.01]]
[[ 0.    0.02 -0.05  0.02 -0.01]
 [-0.07  0.1  -0.06  0.03  0.02]
 [ 0.17 -0.63 -0.44  1.14 -0.28]
 [-0.09  0.16 -0.06 -0.03  0.04]
 [ 0.01 -0.   -0.05  0.06 -0.03]]
[[ 0.    0.    0.    0.    0.01]
 [ 1.    0.    0.02 -0.01 -0.02]
 [ 0.   -0.   -0.06 -0.01 -0.  ]
 [-0.1   0.    0.04 -0.01  0.  ]
 [-0.1   0.01 -0.06  0.   -0.01]]
[[-6.32e-03 -5.56e-02  1.59e-01 -6.00e-02 -5.39e-04]
 [ 3.02e-02  9.11e-02 -5.96e-01  8.52e-02  1.56e-02]
 [-1.93e-02 -1.73e-01 -2.53e-01 -1.48e-01 -2.37e-03]
 [ 4.52e-03  1.38e-01  9.22e-01  1.01e-01  2.81e-03]
 [-4.50e-04 -3.73e-02 -1.73e-01 -1.92e-02 -4.60e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  7.74e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  1.21e-03 -4.12e-03]
 [ 0.00e+00  0.00e+00  1.60e-02 -5.04e-03 -1.19e-03]
 [ 0.00e+00  3.09e-03 -4.25e-03 -6.09e-03  3.54e-03]
 [ 9.57e-03 -1.12e-04 -1.81e-03 -1.29e-03 -8.03e-03]]
[[-0.01  0.04 -0.05  0.04 -0.01]
 [ 0.04 -0.13  0.12 -0.1   0.03]
 [-0.12  1.42 -2.54  1.41 -0.11]
 [ 0.02 -0.05  0.03 -0.06  0.02]
 [-0.    0.01 -0.01  0.02 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.49e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -8.05e-07 -1.72e-03]
 [ 0.00e+00  0.00e+00  4.48e-04 -6.71e-04  4.32e-05]
 [ 0.00e+00  1.08e-04 -6.90e-04 -3.76e-04  2.17e-03]
 [-2.14e-05 -4.45e-04 -1.55e-04  6.35e-04 -2.52e-04]]
[[ 4.97e-03 -4.82e-02 -9.30e-03  6.05e-02 -7.96e-03]
 [-4.92e-02  4.23e-01  2.50e-02 -4.56e-01  5.78e-02]
 [-5.27e-03  1.44e-02 -9.84e-03 -1.10e-04  6.64e-04]
 [ 5.48e-02 -4.37e-01 -1.82e-02  4.60e-01 -5.96e-02]
 [-6.21e-03  5.17e-02  7.15e-03 -6.09e-02  8.24e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.48e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  1.44e-03 -2.96e-03]
 [ 1.00e+00  0.00e+00  9.95e-03 -5.40e-03 -9.15e-04]
 [ 0.00e+00  2.97e-03 -4.16e-03 -5.90e-03  3.34e-03]
 [ 1.61e-01 -1.34e-03 -1.23e-03 -1.50e-04 -4.27e-02]]
[[-0.05  0.18 -0.19  0.17 -0.04]
 [ 0.18 -0.7   1.71 -0.66  0.17]
 [-0.11  0.4  -2.09  0.36 -0.1 ]
 [ 0.16 -0.63  1.62 -0.63  0.16]
 [-0.04  0.15 -0.16  0.16 -0.04]]
SymNet parameters
[[-9.10e-12  1.99e-13 -1.13e-12  6.62e-12 -2.55e-12  8.76e-12 -2.90e-12  3.14e-12
  -5.20e-13  1.11e-12 -3.53e-12  7.90e-12]
 [ 3.74e-13 -3.88e-12 -1.32e-12 -2.76e-12 -2.59e-12 -5.09e-12 -1.24e-12  3.26e-12
  -2.50e-12  6.85e-12  5.00e-13  1.27e-13]]
SymNet parameters
[7.66e-13 1.22e-13]
SymNet parameters
[[ 3.49e-12 -1.61e-11 -6.28e-12 -8.43e-11  2.75e-11 -7.78e-11 -1.62e-11  7.62e-12
  -3.22e-11  1.57e-11 -6.42e-12 -3.52e-11 -2.97e-12]
 [ 6.91e-11 -1.00e-11  5.01e-12 -3.48e-11  9.40e-11 -9.56e-11 -2.78e-11  8.26e-12
   7.26e-12  1.17e-10  2.46e-11 -1.12e-12  7.57e-12]]
SymNet parameters
[ 1.22e-12 -8.77e-13]
SymNet parameters
[[-1.69e-13  5.13e-12 -7.69e-13 -1.27e-11  9.90e-12  6.95e-12 -4.43e-12  1.92e-12
  -1.89e-12  1.04e-11 -5.56e-13  6.04e-12  1.47e-12 -1.28e-13]
 [ 1.30e-11 -6.90e-12 -5.41e-13 -2.02e-11  1.22e-11 -3.57e-11 -4.43e-12  1.51e-12
   4.68e-13  1.06e-11 -3.14e-12 -8.16e-12 -3.63e-13  1.10e-12]]
SymNet parameters
[-1.29e-12 -1.86e-14]
SymNet parameters
[[ 5.34e-04 -5.01e-04  9.90e-01  7.88e-05  1.66e-03 -1.39e-03  5.77e-05  6.85e-04
  -9.62e-04 -3.50e-04  3.62e-04  2.42e-05 -3.65e-12  1.35e-10  3.18e-11]
 [ 1.82e-04 -9.71e-04 -7.47e-05 -2.89e-04 -4.00e-04  3.99e-05 -9.93e-01 -2.71e-04
  -5.06e-04  5.18e-04 -1.00e-04  4.01e-04 -1.11e-11 -4.02e-11  2.34e-12]]
SymNet parameters
[-5.08e-05  2.21e-04]
SymNet parameters
[[-1.91e-04 -9.93e-01  1.92e-04 -8.45e-04  1.65e-03 -1.12e-04 -5.91e-04 -1.86e-04
  -2.02e-04 -5.46e-04 -3.11e-04 -5.49e-04  2.33e-12 -2.16e-11 -4.13e-12 -2.69e-04]
 [-9.79e-01 -2.49e-03 -9.65e-04 -8.02e-04 -7.82e-05  5.88e-04  6.29e-04  6.56e-04
   7.95e-04  3.55e-05 -2.02e-04  3.72e-04  1.05e-11 -5.75e-12  4.34e-12 -1.11e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 4.66e-03 -4.34e-03  2.15e-04  5.12e-02  3.83e-03  5.16e-02  5.92e-05 -4.72e-04
   2.28e-04 -7.81e-04  9.00e-05  6.83e-04 -3.05e-12 -5.26e-11  3.15e-12  9.84e-01
  -9.98e-01]]
SymNet parameters
[-0.]
SymNet parameters
[[-2.84e-11  5.94e-12 -2.61e-11  5.86e-11 -2.61e-11  6.48e-11  8.39e-13  3.59e-11
   2.57e-11 -5.49e-11 -1.64e-11 -6.14e-11]
 [ 1.23e-11 -1.40e-12  3.88e-12 -7.38e-11  3.55e-11 -6.54e-11  1.73e-11 -1.23e-11
  -1.20e-11 -3.69e-12  6.23e-11 -1.87e-10]]
SymNet parameters
[ 1.50e-12 -8.94e-13]
SymNet parameters
[[-8.19e-05 -3.10e-05  1.16e-04 -1.12e-04  1.55e-04 -5.20e-04  1.85e-03 -9.78e-04
   9.90e-01  7.13e-04  2.54e-05 -6.41e-04 -3.87e-11]
 [ 1.68e-03 -7.37e-04 -3.06e-05  3.25e-04 -1.46e-04 -4.60e-04 -9.92e-01 -4.04e-04
  -3.66e-05  1.71e-04  1.92e-04 -4.88e-04 -1.12e-10]]
SymNet parameters
[-9.82e-04 -4.29e-05]
SymNet parameters
[[ 1.26e-12  1.51e-12  3.46e-13  1.26e-12 -1.20e-11  6.32e-12  1.17e-12  6.74e-13
  -5.30e-13 -2.31e-11 -7.58e-12 -5.06e-12  2.09e-12  4.44e-12]
 [ 4.35e-12 -7.64e-13  3.90e-13 -1.68e-11 -5.48e-13 -8.84e-12  2.55e-12  5.18e-13
  -7.36e-13  1.86e-12 -2.86e-12  4.41e-12 -6.93e-13 -2.21e-12]]
SymNet parameters
[-1.66e-12 -5.06e-13]
SymNet parameters
[[-1.23e-04  3.25e-03  3.90e-04  3.70e-04  8.12e-04 -1.05e-03  8.66e-05 -9.84e-01
   9.25e-04 -8.85e-04  4.83e-04  1.76e-03  5.02e-11  1.12e-03  1.34e-11]
 [ 9.89e-01  6.88e-04  3.27e-04 -1.61e-04 -1.38e-04 -1.44e-04 -9.86e-04  8.79e-04
   3.51e-04 -3.23e-04  4.53e-04 -3.65e-04 -6.37e-11  1.52e-03  1.52e-12]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 8.07e-13 -2.38e-12 -1.74e-12 -1.94e-12 -7.14e-14 -3.52e-12  8.03e-13 -6.59e-13
  -6.36e-12  5.25e-12 -6.55e-13  1.77e-11  1.10e-12  2.72e-13 -1.15e-12 -2.26e-12]
 [ 1.60e-13 -9.69e-13  1.46e-12  6.79e-13 -1.91e-12  3.07e-12 -9.11e-13 -9.81e-13
   2.42e-12 -3.92e-12 -1.27e-13 -1.31e-11 -9.05e-13  6.78e-12 -9.17e-13  3.08e-12]]
SymNet parameters
[-1.41e-14 -1.15e-12]
SymNet parameters
[[ 2.29e-04  4.32e-06 -4.76e-04  4.59e-04  9.15e-04 -2.63e-04  6.64e-03  1.07e-04
  -4.79e-05  5.17e-02  1.61e-03  5.10e-02 -1.54e-11  9.92e-01 -4.22e-12  9.94e-01
  -1.04e-12]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   290    time: 22.93
Func: 2.18e-01  |g|: 6.27e-09
stableloss: 2.01e-02   dataloss: 8.22e-02   sparseloss: 1.21e+01 momentloss: 7.29e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u01, u11, u01**2, u01*u10, u11*v00, u00*u11, u20*v00, u01*v00, u00*v00, v00*v10, u00*u02, u01*u02, u01*v10, v02]
[-9.70e-01 -9.68e-01  5.16e-02  5.12e-02  1.08e-02  5.62e-03 -5.32e-03  3.83e-03
 -2.46e-03 -1.90e-03 -1.63e-03  1.62e-03  1.36e-03  1.11e-03 -1.10e-03  9.41e-04
 -8.26e-04 -7.96e-04  7.88e-04 -7.82e-04]
[v00*v10, u00*v01, v02, v20, v00, u00*u01, u00*v10, v00*v01, v00**2, u00*v20, v11, v00*v01*v10, u00*v00*v10, u00*u20, u11, u00*v02, v01**2, u00*u11, v01*v10, u01*v10]
[-9.74e-01 -9.67e-01  5.17e-02  5.10e-02  7.61e-03  3.19e-03  2.55e-03  1.92e-03
 -1.82e-03  1.72e-03  1.61e-03  1.45e-03 -1.08e-03 -1.03e-03  9.15e-04 -8.68e-04
 -8.59e-04  7.98e-04 -7.39e-04 -7.22e-04]
block:  3
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  0.5142222203480947
current stage is: block-3
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9785, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2445,  1.8531,  1.5452, 24.1681, 10.3325, 14.0406,  0.2707,  1.8852,
         1.8292, 21.7109, 11.6528, 17.4996], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 11.17
Func: 4.58e-01  |g|: 2.82e+00
stableloss: 3.45e-02   dataloss: 2.54e-01   sparseloss: 1.21e+01 momentloss: 7.29e+00
iter:   200    time: 19.72
Func: 4.29e-01  |g|: 1.50e-03
stableloss: 3.39e-02   dataloss: 2.22e-01   sparseloss: 1.22e+01 momentloss: 8.20e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.429253
         Iterations: 267
         Function evaluations: 351
         Gradient evaluations: 341
convolution moment and kernels
[[ 1.00e+00  0.00e+00  1.14e-03  1.32e-02 -7.16e-02]
 [ 0.00e+00  1.51e-03 -1.97e-03  8.38e-03 -3.27e-03]
 [-1.60e-03  3.31e-03  7.51e-02  8.14e-03 -9.45e-03]
 [ 9.19e-02 -5.50e-04 -4.39e-03 -3.00e-02 -9.81e-03]
 [-1.21e-01  8.16e-02 -8.93e-03  1.00e-01 -6.78e-03]]
[[-0.05  0.05 -0.14 -0.07  0.05]
 [ 0.18 -0.06  0.28  0.36 -0.19]
 [-0.33  0.31  0.35 -0.24  0.19]
 [ 0.16 -0.04  0.18  0.24 -0.14]
 [-0.04  0.05 -0.1  -0.01  0.03]]
[[ 0.    1.    0.   -0.11 -0.11]
 [ 0.    0.   -0.01 -0.   -0.02]
 [ 0.    0.05 -0.04  0.07 -0.04]
 [ 0.    0.03 -0.   -0.01 -0.01]
 [-0.01  0.02 -0.01  0.01 -0.01]]
[[-5.02e-03  5.20e-04  1.28e-02 -2.72e-02  7.07e-03]
 [-3.49e-02  9.13e-02 -7.29e-02  6.62e-02 -5.19e-03]
 [ 1.24e-01 -5.74e-01 -5.06e-01  1.15e+00 -2.54e-01]
 [-4.55e-02  1.25e-01 -3.30e-02 -2.64e-02  1.84e-02]
 [-7.00e-03  1.06e-02 -4.85e-02  4.93e-02 -1.35e-02]]
[[ 0.    0.    0.   -0.   -0.02]
 [ 1.    0.    0.02  0.01 -0.01]
 [ 0.    0.01 -0.    0.06 -0.01]
 [-0.12 -0.03  0.04  0.   -0.  ]
 [-0.12  0.01 -0.03  0.06 -0.01]]
[[-2.60e-02 -9.13e-04  1.03e-01 -7.50e-02  2.24e-02]
 [ 8.64e-02 -4.30e-02 -5.03e-01  2.10e-01 -6.24e-02]
 [-1.24e-01  1.48e-01 -5.76e-01 -2.18e-01  6.45e-02]
 [ 7.17e-02 -7.71e-02  1.10e+00  2.30e-01 -7.26e-02]
 [-3.01e-02  6.44e-02 -2.65e-01 -5.02e-02  2.28e-02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.88e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  6.70e-03  1.96e-03]
 [ 0.00e+00  0.00e+00  9.27e-03 -6.15e-03  6.49e-04]
 [ 0.00e+00  1.32e-03 -1.65e-03 -9.15e-03  7.30e-06]
 [ 2.49e-01 -1.21e-04 -5.13e-03  2.44e-04 -4.89e-02]]
[[-0.05  0.19 -0.03  0.18 -0.05]
 [ 0.2  -0.76  0.1  -0.72  0.18]
 [-0.37  2.42 -2.59  2.39 -0.36]
 [ 0.19 -0.74  0.1  -0.75  0.2 ]
 [-0.05  0.18 -0.03  0.19 -0.05]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.85e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  6.73e-05 -7.45e-04]
 [ 0.00e+00  0.00e+00 -1.19e-03  2.62e-03  4.84e-03]
 [ 0.00e+00  4.19e-04 -8.52e-04 -7.82e-04 -5.36e-04]
 [-7.01e-04  4.31e-03  1.52e-03 -2.41e-03 -4.50e-03]]
[[ 3.53e-03 -3.90e-02 -3.40e-02  8.20e-02 -1.33e-02]
 [-3.80e-02  3.59e-01  1.71e-01 -5.77e-01  8.82e-02]
 [-3.63e-02  1.70e-01 -3.22e-01  2.46e-01 -6.16e-02]
 [ 7.22e-02 -5.26e-01  1.67e-01  3.12e-01 -2.21e-02]
 [-1.03e-02  7.15e-02 -3.43e-02 -2.75e-02 -1.49e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.74e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  6.50e-03 -1.48e-03]
 [ 1.00e+00  0.00e+00  9.70e-03 -3.56e-03 -1.49e-03]
 [ 0.00e+00  6.82e-04 -4.19e-03 -8.53e-03  4.59e-03]
 [ 6.98e-03  1.35e-02 -6.39e-03 -9.92e-02 -3.76e-03]]
[[ 0.04 -0.09 -0.1   0.12 -0.05]
 [-0.18  0.39  1.33 -0.44  0.21]
 [ 0.56 -1.75 -0.77 -0.46 -0.04]
 [-0.2   0.47  1.24 -0.41  0.21]
 [ 0.05 -0.12 -0.06  0.11 -0.05]]
SymNet parameters
[[ 2.34e-11  5.27e-13  2.82e-12 -1.68e-11  7.24e-12 -1.89e-11  7.63e-12 -9.19e-12
   1.77e-12 -2.84e-12  1.12e-11 -1.61e-11]
 [-4.57e-13  7.08e-12  4.24e-12  6.00e-12  1.94e-12  5.60e-12  3.40e-12 -7.09e-12
   7.64e-12 -1.97e-11 -3.45e-12 -6.59e-12]]
SymNet parameters
[-2.11e-12 -3.34e-13]
SymNet parameters
[[ 2.08e-10 -1.80e-10  1.94e-12 -2.66e-10 -6.33e-10 -1.88e-10  1.21e-10 -3.63e-11
  -2.37e-11 -5.90e-10  3.16e-10  1.42e-10  8.11e-12]
 [-8.01e-11  2.41e-10 -4.98e-11  1.23e-10  3.26e-10  2.05e-10 -3.15e-10 -4.39e-12
   9.99e-11  6.04e-10 -1.71e-10  3.17e-10 -2.07e-11]]
SymNet parameters
[-7.59e-13  1.39e-13]
SymNet parameters
[[-9.47e-13 -6.45e-12  3.51e-12  1.10e-11 -5.93e-11 -2.13e-11  1.20e-11 -6.38e-12
   5.57e-12 -2.87e-11 -2.39e-12 -4.01e-11 -4.00e-12  3.50e-13]
 [-3.42e-11  1.70e-11  8.42e-13  3.39e-11 -2.66e-11  1.02e-10  1.43e-11 -4.58e-12
  -1.18e-12 -3.15e-11  1.19e-11  2.70e-11  9.91e-13 -3.02e-12]]
SymNet parameters
[3.39e-12 4.79e-14]
SymNet parameters
[[-1.84e-04 -8.91e-04  9.91e-01  6.57e-04 -4.65e-03  1.54e-03  5.38e-04  1.39e-03
   4.68e-04  3.75e-04  2.85e-06  1.05e-03  5.80e-12 -3.64e-10 -9.60e-11]
 [ 1.64e-03 -5.19e-03 -1.43e-03  2.94e-04 -4.59e-04 -5.07e-05 -9.84e-01  5.02e-04
  -7.40e-03  3.73e-04 -1.66e-04  1.04e-03  2.49e-11  6.61e-11 -1.96e-11]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 1.22e-04 -9.87e-01  9.28e-04  2.84e-04 -5.12e-03  9.55e-04  1.09e-04  1.20e-03
  -1.57e-03  3.48e-04 -3.02e-04  7.67e-04 -3.06e-12  8.17e-11 -2.50e-11  1.45e-03]
 [-9.85e-01  1.75e-04 -9.68e-04 -5.07e-04  6.55e-05  1.06e-03  8.51e-04  3.07e-04
  -1.80e-03  2.65e-05 -1.78e-04 -1.57e-04 -2.66e-11  4.45e-10 -8.40e-13 -9.67e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 8.13e-03 -6.79e-04  1.99e-04  5.19e-02  2.49e-03  5.23e-02  5.56e-04  4.57e-04
   1.08e-03  4.18e-04 -5.90e-04 -1.32e-04  1.00e-11  1.46e-10 -7.46e-12  9.90e-01
  -1.00e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[-4.02e-11 -4.30e-10  2.38e-11 -2.00e-10  4.99e-10 -1.39e-11 -1.12e-10 -4.09e-10
  -2.52e-10  4.90e-10 -9.12e-10  1.77e-10]
 [-2.07e-10  2.15e-10 -4.95e-10  1.41e-10 -4.52e-10  2.38e-10 -3.23e-10  6.65e-10
   5.02e-10 -6.58e-10  5.81e-10 -2.08e-10]]
SymNet parameters
[-5.73e-12 -3.18e-12]
SymNet parameters
[[ 1.16e-04  2.35e-04 -2.59e-03  6.73e-04  7.93e-04  1.00e-03  1.50e-03 -4.50e-04
   9.86e-01  5.82e-04 -4.17e-03  1.18e-03  2.43e-10]
 [ 1.66e-03 -4.36e-04 -2.23e-03 -3.15e-05 -1.26e-04  6.36e-04 -9.87e-01  6.45e-04
  -6.52e-03  3.28e-04 -1.86e-04 -3.39e-04 -3.00e-10]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-3.24e-12 -3.89e-12 -1.38e-12 -2.85e-12  3.28e-11 -1.92e-11 -3.61e-12 -2.56e-12
   2.25e-12  6.69e-11  1.76e-11  1.61e-11 -5.71e-12 -1.37e-11]
 [-1.32e-11  1.82e-12 -9.54e-13  5.00e-11  2.71e-13  2.42e-11 -8.79e-12 -9.71e-13
   1.94e-12 -4.42e-12  1.59e-11 -1.18e-11  1.89e-12  6.72e-12]]
SymNet parameters
[4.55e-12 1.38e-12]
SymNet parameters
[[-1.21e-03 -7.89e-04 -1.60e-03 -5.09e-05 -5.10e-04  4.47e-04 -1.08e-04 -9.85e-01
   9.39e-04  1.46e-03 -5.43e-03  3.69e-04  3.83e-10 -8.81e-04 -4.76e-11]
 [ 9.88e-01 -7.45e-04  6.39e-03 -2.91e-04  5.52e-04 -9.87e-04 -4.70e-04  4.43e-04
  -5.72e-04  1.70e-04  1.69e-04 -2.85e-04 -1.42e-10  6.99e-04 -1.26e-11]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-2.21e-12  6.48e-12  4.70e-12  5.52e-12  3.00e-13  9.81e-12 -2.18e-12  1.81e-12
   1.72e-11 -1.44e-11  1.71e-12 -4.74e-11 -3.01e-12 -8.21e-13  3.15e-12  6.09e-12]
 [-4.36e-13  2.65e-12 -3.94e-12 -2.12e-12  5.08e-12 -8.67e-12  2.49e-12  2.68e-12
  -6.59e-12  1.08e-11  4.61e-13  3.47e-11  2.48e-12 -1.84e-11  2.51e-12 -8.25e-12]]
SymNet parameters
[3.84e-14 3.14e-12]
SymNet parameters
[[ 5.40e-04  6.91e-05 -8.46e-04  5.01e-04 -5.35e-04 -2.73e-04  8.65e-03 -2.65e-04
   1.30e-03  5.26e-02  2.47e-03  5.16e-02  8.87e-12  9.98e-01  5.21e-12  9.98e-01
   1.30e-11]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   267    time: 10.63
Func: 4.29e-01  |g|: 6.43e-08
stableloss: 3.39e-02   dataloss: 2.22e-01   sparseloss: 1.22e+01 momentloss: 8.20e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u10*v10, u01*u10, u00*u11, u11*v00, u00*u10, u11, u01*v10, u01*v00, u00*v10, u20*v00, u10**2, u00*u10*v00, v00*v01, u01]
[-0.97 -0.97  0.05  0.05  0.01  0.01 -0.01 -0.01 -0.01  0.    0.    0.   -0.    0.
 -0.   -0.   -0.   -0.   -0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00, v10**2, u10*v01, u00*v11, v00*v11, u00*v10, u10*v00, v11, v10, u10*v10, u00*u10, v00**2, u00*v02, v01*v10, u00**2, v00*v20]
[-0.97 -0.97  0.05  0.05  0.01 -0.01 -0.01 -0.01  0.    0.    0.    0.    0.   -0.
 -0.   -0.    0.    0.   -0.   -0.  ]
block:  4
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -2.6779354197713485
current stage is: block-4
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9288, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2434,  1.7513,  1.5642, 20.8519, 10.0512, 15.9509,  0.2265,  1.4272,
         1.5736, 15.4596,  8.1672, 18.6719], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 8.35
Func: 6.03e-01  |g|: 2.58e+00
stableloss: 4.05e-02   dataloss: 3.26e-01   sparseloss: 1.22e+01 momentloss: 8.20e+00
iter:   200    time: 23.92
Func: 5.72e-01  |g|: 8.58e-05
stableloss: 4.07e-02   dataloss: 2.98e-01   sparseloss: 1.22e+01 momentloss: 7.74e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.572351
         Iterations: 243
         Function evaluations: 273
         Gradient evaluations: 273
convolution moment and kernels
[[ 1.00e+00  0.00e+00  3.92e-03 -6.52e-02 -2.98e-02]
 [ 0.00e+00  9.37e-04 -4.33e-02 -3.40e-04  8.41e-05]
 [-5.45e-03  9.56e-03  2.60e-02  4.70e-02  1.61e-02]
 [ 5.35e-02  7.57e-03  1.97e-03  5.61e-04  1.43e-02]
 [-1.53e-01 -2.41e-02 -4.61e-02  7.28e-03 -2.56e-03]]
[[-0.01 -0.   -0.11 -0.05 -0.  ]
 [ 0.02  0.11  0.31  0.19  0.03]
 [-0.   -0.13  0.42 -0.08 -0.11]
 [-0.01  0.15  0.19  0.22  0.01]
 [ 0.   -0.05  0.   -0.09  0.01]]
[[ 0.    1.    0.   -0.09 -0.11]
 [ 0.    0.   -0.   -0.01 -0.01]
 [ 0.    0.03 -0.05  0.04 -0.06]
 [ 0.01 -0.01 -0.   -0.02 -0.01]
 [-0.    0.01 -0.01 -0.01 -0.01]]
[[-3.02e-03  5.83e-03 -2.28e-02  1.65e-02 -4.02e-03]
 [-6.35e-02  1.53e-01 -9.79e-02  2.74e-02  2.41e-03]
 [ 1.55e-01 -6.33e-01 -4.30e-01  1.13e+00 -2.45e-01]
 [-7.38e-02  1.58e-01 -8.15e-02 -2.08e-02  2.43e-02]
 [-3.88e-04  1.60e-02 -5.44e-02  6.08e-02 -2.14e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00 -7.20e-03 -4.59e-04]
 [ 1.00e+00  0.00e+00  2.85e-02 -4.73e-03 -1.36e-02]
 [ 0.00e+00  5.21e-03  5.45e-04  2.72e-02  1.80e-02]
 [-1.21e-01 -1.68e-02  5.19e-02  1.94e-02 -3.76e-03]
 [-1.13e-01  4.77e-04 -3.79e-02  1.88e-02 -2.26e-03]]
[[-4.20e-04 -6.91e-02  1.66e-01 -7.08e-02  4.65e-03]
 [ 3.01e-02  8.51e-02 -5.69e-01  1.02e-01  1.56e-02]
 [-5.96e-02 -2.45e-02 -4.61e-01 -1.14e-01 -2.02e-02]
 [ 5.04e-02 -2.79e-02  1.11e+00  1.24e-01 -1.49e-02]
 [-1.73e-02  3.11e-02 -2.48e-01 -3.34e-02  1.07e-02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  9.81e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.91e-03  1.32e-04]
 [ 0.00e+00  0.00e+00  3.63e-02  2.31e-03  1.12e-02]
 [ 0.00e+00  3.58e-03 -4.30e-04 -3.95e-04  1.26e-03]
 [ 2.13e-01 -1.36e-03  3.21e-03  7.50e-03 -9.04e-03]]
[[-0.01  0.05  0.15  0.03 -0.01]
 [ 0.06 -0.19 -0.63 -0.13  0.04]
 [-0.17  1.57 -1.47  1.48 -0.13]
 [ 0.06 -0.18 -0.64 -0.12  0.03]
 [-0.01  0.04  0.16  0.03 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  8.49e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -1.14e-04 -2.25e-04]
 [ 0.00e+00  0.00e+00 -3.22e-04  1.40e-03  1.03e-03]
 [ 0.00e+00 -7.59e-05  1.09e-04 -2.54e-04 -1.57e-04]
 [-4.66e-03  1.74e-03  2.81e-03 -4.12e-03 -3.66e-03]]
[[ 0.01 -0.04 -0.03  0.08 -0.01]
 [-0.05  0.39  0.14 -0.55  0.08]
 [-0.01  0.08 -0.21  0.15 -0.04]
 [ 0.06 -0.5   0.14  0.34 -0.03]
 [-0.01  0.07 -0.03 -0.03  0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.63e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.78e-03  2.81e-03]
 [ 1.00e+00  0.00e+00  8.77e-03  1.19e-03  9.18e-03]
 [ 0.00e+00  3.86e-03  5.90e-04 -8.88e-04 -1.87e-03]
 [ 2.37e-03 -6.46e-04  5.79e-03  7.86e-03 -3.28e-02]]
[[-0.04  0.15 -0.29  0.13 -0.03]
 [ 0.16 -0.61  2.19 -0.54  0.13]
 [-0.08  0.29 -2.86  0.2  -0.04]
 [ 0.16 -0.64  2.24 -0.57  0.13]
 [-0.04  0.15 -0.3   0.14 -0.03]]
SymNet parameters
[[-1.43e-12 -4.02e-15 -1.75e-13  1.22e-12 -5.07e-13  1.26e-12 -4.29e-13  5.29e-13
  -7.13e-14  4.95e-14 -6.28e-13  8.99e-13]
 [ 4.20e-14 -6.06e-13 -2.53e-13 -7.24e-13 -2.50e-13 -3.89e-13 -2.03e-13  4.77e-13
  -4.07e-13  1.25e-12  2.12e-13  3.99e-13]]
SymNet parameters
[1.23e-13 1.91e-14]
SymNet parameters
[[ 2.05e-11  5.70e-11 -9.21e-12  6.78e-11 -7.25e-11  1.01e-12  1.59e-11  1.47e-11
   4.64e-13 -3.73e-11 -1.59e-11 -7.12e-11 -4.76e-13]
 [-5.95e-12 -4.09e-11  1.11e-11 -1.49e-11  5.43e-11 -4.41e-12 -1.41e-11 -1.14e-11
  -9.68e-12  6.88e-11  9.94e-12  1.00e-10  1.22e-12]]
SymNet parameters
[1.68e-13 2.56e-13]
SymNet parameters
[[-3.08e-13  2.15e-13 -1.08e-13  3.22e-13  1.95e-12  1.68e-12 -6.19e-13  5.84e-13
  -2.95e-13  1.68e-12  2.49e-14  8.16e-13  2.35e-13 -2.06e-14]
 [ 1.73e-12 -9.99e-13 -2.14e-14 -1.80e-12  1.75e-12 -5.36e-12 -7.90e-13  2.13e-13
   4.37e-14  1.94e-12 -6.52e-13 -1.33e-12 -5.82e-14  1.77e-13]]
SymNet parameters
[-1.99e-13 -4.24e-15]
SymNet parameters
[[ 5.60e-04  2.76e-04  9.89e-01 -9.79e-05 -3.03e-03 -8.65e-05 -1.11e-03  2.78e-03
  -1.38e-03 -3.15e-04  5.62e-04 -1.22e-04 -3.06e-13  2.27e-10  4.42e-12]
 [-1.58e-04 -7.68e-04  1.67e-04 -5.20e-05 -7.11e-04 -6.87e-05 -9.88e-01  3.65e-03
  -2.36e-03 -2.18e-04 -2.96e-04  2.10e-03 -1.51e-12 -3.10e-11  1.37e-12]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 1.88e-03 -9.93e-01 -1.89e-04 -1.74e-05 -2.90e-03  6.25e-05 -6.82e-04  7.66e-04
   1.99e-04  1.15e-04  7.92e-04  1.74e-05  4.82e-13  9.20e-11  2.01e-12 -9.30e-04]
 [-9.83e-01  3.41e-03 -1.22e-03 -8.66e-04  1.03e-04  2.19e-03 -1.41e-04 -5.56e-04
   4.67e-04  6.53e-05  6.08e-04 -1.46e-04  1.74e-12  5.06e-11  9.90e-15 -9.33e-03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 1.27e-02 -5.34e-04  2.61e-03  5.18e-02  4.56e-04  5.14e-02  3.71e-04 -4.59e-04
   5.47e-04 -3.22e-04 -3.31e-04  1.89e-04 -6.11e-13 -5.97e-11  6.52e-13  9.88e-01
  -1.00e+00]]
SymNet parameters
[0.]
SymNet parameters
[[-3.36e-11  7.45e-11  1.22e-10  3.96e-11 -7.78e-11 -8.02e-11  8.59e-11  5.66e-11
  -2.83e-10 -2.55e-10  2.75e-11  6.11e-10]
 [ 5.96e-11 -1.40e-11 -9.02e-11 -1.40e-10  6.64e-11 -1.86e-11  5.76e-11 -1.28e-10
   2.11e-10 -1.77e-10 -1.74e-10  1.06e-10]]
SymNet parameters
[-5.91e-14 -1.11e-12]
SymNet parameters
[[-9.24e-04 -3.64e-04  9.32e-04 -2.93e-05  4.31e-04 -3.99e-04 -5.35e-04 -5.14e-04
   9.90e-01  7.67e-04 -2.35e-03 -2.86e-04  3.76e-11]
 [ 3.10e-04  2.65e-05 -7.85e-05  8.29e-04 -1.11e-04 -7.37e-04 -9.90e-01  2.49e-03
  -1.79e-03 -1.76e-04  2.95e-05  5.98e-04 -5.74e-11]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 2.10e-13  2.05e-13  7.60e-14  4.84e-14 -1.90e-12  1.02e-12  1.33e-13  1.68e-13
  -1.56e-13 -3.35e-12 -1.10e-12 -6.49e-13  3.35e-13  7.32e-13]
 [ 6.47e-13 -9.40e-14  1.85e-14 -2.29e-12  2.50e-14 -9.76e-13  4.55e-13  1.00e-13
  -9.59e-14  2.58e-13 -4.80e-13  7.47e-13 -1.11e-13 -4.19e-13]]
SymNet parameters
[-2.66e-13 -8.13e-14]
SymNet parameters
[[-1.93e-03 -1.84e-03 -1.47e-03 -2.27e-04  2.65e-04 -3.49e-05  8.91e-04 -9.88e-01
   4.05e-04 -4.20e-04 -3.04e-03  1.06e-03  1.36e-11 -1.76e-03  1.65e-12]
 [ 9.87e-01 -4.19e-03  4.65e-03 -7.66e-05  3.22e-04 -2.03e-03 -5.17e-04  2.28e-04
  -8.76e-04  9.67e-05  5.18e-04  6.15e-05 -4.60e-11 -1.18e-03  4.37e-13]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 1.30e-13 -3.78e-13 -2.77e-13 -2.94e-13 -1.28e-14 -5.71e-13  1.27e-13 -1.07e-13
  -9.85e-13  8.49e-13 -7.38e-14  2.76e-12  1.77e-13  8.21e-14 -1.85e-13 -3.49e-13]
 [ 2.51e-14 -1.56e-13  2.34e-13  8.60e-14 -3.06e-13  5.02e-13 -1.46e-13 -1.56e-13
   3.84e-13 -6.28e-13 -6.07e-14 -2.02e-12 -1.45e-13  1.02e-12 -1.47e-13  4.67e-13]]
SymNet parameters
[-2.18e-15 -1.85e-13]
SymNet parameters
[[-1.73e-04 -2.03e-03 -6.97e-04 -2.21e-04  9.60e-07  5.95e-04  4.79e-03 -1.68e-04
   7.88e-04  5.15e-02  2.43e-04  5.00e-02 -5.14e-11  9.94e-01 -6.47e-14  1.00e+00
  -6.00e-13]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   243    time: 5.13
Func: 5.72e-01  |g|: 3.37e-08
stableloss: 4.07e-02   dataloss: 2.98e-01   sparseloss: 1.22e+01 momentloss: 7.74e+00
current expression:
[u00*u01, u10*v00, u02, u20, u00, u01*u10*v00, u10, u10*v01, u01**2, u11*v00, 1, u00*u11, v00*v01, u10*v10, u01*u20, u10*v20, u01*u10, u00**2, v00*v10, u00*v00]
[-0.98 -0.96  0.05  0.05  0.01  0.01  0.    0.    0.    0.    0.   -0.   -0.   -0.
  0.    0.   -0.    0.    0.   -0.  ]
[u00*v01, v00*v10, v02, v20, v00, u10*v01, u01*v01, v01*v10, u00*v11, v00*v11, u01, u20*v01, u00**2, u00*u01, u00*v00, v10**2, u00*v00*v10, v10, u00*u10, v00*v01*v10]
[-0.98 -0.97  0.05  0.05  0.01 -0.    0.    0.   -0.    0.   -0.    0.   -0.   -0.
  0.   -0.    0.    0.   -0.   -0.  ]
block:  5
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  0.636558915634273
current stage is: block-5
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9246, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2499,  1.6919,  1.6999, 20.0345,  9.8736, 18.4442,  0.2452,  1.6704,
         1.6935, 18.1147, 10.3062, 20.3225], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 9.49
Func: 1.28e+00  |g|: 8.69e+00
stableloss: 6.31e-02   dataloss: 9.34e-01   sparseloss: 1.22e+01 momentloss: 7.74e+00
iter:   200    time: 28.40
Func: 1.17e+00  |g|: 1.25e-02
stableloss: 6.48e-02   dataloss: 8.16e-01   sparseloss: 1.22e+01 momentloss: 9.13e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 1.166749
         Iterations: 230
         Function evaluations: 310
         Gradient evaluations: 297
convolution moment and kernels
[[ 1.    0.   -0.    0.01 -0.08]
 [ 0.    0.   -0.01  0.03 -0.05]
 [-0.01 -0.01  0.08 -0.05  0.01]
 [-0.06  0.    0.03 -0.01 -0.01]
 [-0.09  0.06  0.02  0.04  0.01]]
[[-0.01 -0.04  0.01 -0.05  0.03]
 [ 0.09  0.05  0.08  0.19 -0.11]
 [-0.18  0.13  0.47 -0.05  0.11]
 [ 0.02  0.2   0.09  0.22 -0.12]
 [-0.   -0.01 -0.13  0.01  0.02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.16e-01 -1.09e-01]
 [ 0.00e+00  0.00e+00  2.64e-03 -1.06e-02 -8.20e-03]
 [ 0.00e+00  3.07e-02 -5.52e-02  2.87e-02 -7.55e-02]
 [-9.46e-03 -1.99e-02  7.34e-03  1.09e-03 -4.68e-04]
 [ 2.79e-04  5.88e-03 -4.81e-03 -1.43e-02 -1.94e-02]]
[[-0.    0.02 -0.07  0.08 -0.02]
 [-0.07  0.11  0.   -0.1   0.04]
 [ 0.17 -0.62 -0.49  1.21 -0.26]
 [-0.06  0.09 -0.01 -0.03  0.02]
 [-0.01  0.04 -0.09  0.07 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  8.64e-04  8.98e-03]
 [ 1.00e+00  0.00e+00  3.48e-02  1.64e-02  4.77e-04]
 [ 0.00e+00  6.14e-03 -6.15e-02 -9.64e-04 -1.86e-02]
 [-1.20e-01  1.97e-02  4.68e-02  2.86e-03  1.69e-03]
 [-1.13e-01  1.08e-03 -6.06e-02 -9.25e-03 -1.79e-02]]
[[-6.97e-03 -3.58e-02  1.18e-01 -2.97e-02 -1.47e-02]
 [ 2.10e-02  6.46e-02 -5.07e-01  4.08e-02  4.47e-02]
 [-9.05e-03 -1.18e-01 -4.63e-01 -2.58e-02 -5.98e-02]
 [ 1.08e-02  5.50e-02  1.17e+00 -5.37e-02  5.72e-02]
 [-7.19e-03 -5.44e-04 -2.62e-01  3.16e-02 -1.80e-02]]
[[ 0.    0.    1.    0.    0.01]
 [ 0.    0.    0.    0.01  0.01]
 [ 0.    0.    0.32 -0.09  0.01]
 [ 0.    0.01  0.   -0.01 -0.  ]
 [ 0.28  0.01  0.01 -0.01  0.07]]
[[ 0.07 -0.31  0.76 -0.31  0.07]
 [-0.26  1.56 -3.79  1.72 -0.36]
 [ 0.31 -1.17  3.55 -1.45  0.47]
 [-0.26  1.54 -3.71  1.63 -0.33]
 [ 0.07 -0.31  0.74 -0.28  0.07]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.22e-02]
 [ 0.00e+00  1.00e+00  0.00e+00  2.59e-03 -3.17e-03]
 [ 0.00e+00  0.00e+00  3.23e-03 -8.65e-03  2.96e-03]
 [ 0.00e+00  1.08e-03  2.73e-03 -1.77e-04  2.78e-03]
 [ 1.05e-03 -4.14e-03  9.38e-04  1.02e-01 -2.32e-03]]
[[-0.05  0.07 -0.02 -0.04  0.04]
 [ 0.18 -0.06  0.1  -0.08 -0.14]
 [-0.29  0.53  0.2  -0.78  0.35]
 [ 0.27 -0.91  0.05  0.84 -0.26]
 [-0.06  0.17 -0.01 -0.15  0.06]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.14e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  8.48e-02  4.90e-03]
 [ 1.00e+00  0.00e+00  1.52e-01 -9.83e-03  2.35e-01]
 [ 0.00e+00  9.49e-03  3.38e-03 -5.68e-03  2.44e-04]
 [ 5.01e-03  2.60e-02  2.04e-01 -1.77e-02  5.60e-03]]
[[-0.02  0.29 -0.63  0.33 -0.03]
 [ 0.33 -1.91  4.57 -2.03  0.34]
 [-0.46  2.7  -7.22  3.07 -0.56]
 [ 0.28 -1.8   4.62 -2.2   0.42]
 [-0.01  0.27 -0.65  0.36 -0.05]]
SymNet parameters
[[ 8.58e-09  6.52e-11  1.05e-09 -7.28e-09  2.96e-09 -7.49e-09  2.59e-09 -3.23e-09
   4.84e-10 -3.03e-10  3.78e-09 -5.37e-09]
 [-2.06e-10  3.44e-09  1.55e-09  4.47e-09  1.29e-09  2.14e-09  1.18e-09 -2.77e-09
   2.50e-09 -7.36e-09 -1.28e-09 -2.45e-09]]
SymNet parameters
[-7.45e-10 -1.15e-10]
SymNet parameters
[[-4.51e-06  5.10e-07  1.93e-06 -7.97e-06 -2.48e-06 -2.86e-06 -5.11e-06  4.02e-07
   1.88e-06  4.27e-06 -1.50e-07  6.61e-06  2.88e-09]
 [ 5.71e-06 -4.38e-07  1.18e-06 -7.97e-06 -1.24e-05 -1.05e-05  3.44e-06 -2.54e-07
   6.19e-07 -4.69e-06  1.00e-06 -1.48e-05 -7.35e-09]]
SymNet parameters
[-1.93e-09 -1.92e-09]
SymNet parameters
[[ 1.18e-09 -1.81e-09  5.81e-10  1.78e-11 -1.53e-08 -8.81e-09  4.45e-09 -3.63e-09
   1.82e-09 -1.14e-08 -9.42e-10 -9.02e-09 -1.42e-09  1.24e-10]
 [-1.11e-08  6.15e-09  1.48e-10  1.16e-08 -1.00e-08  3.36e-08  4.86e-09 -1.22e-09
  -2.56e-10 -1.16e-08  4.00e-09  9.05e-09  3.52e-10 -1.07e-09]]
SymNet parameters
[1.21e-09 2.69e-11]
SymNet parameters
[[ 1.97e-04 -3.33e-04  9.88e-01 -1.16e-03  5.90e-03 -6.63e-04 -8.38e-04 -2.41e-03
   8.69e-04  6.55e-04 -7.26e-04  4.95e-04  1.96e-09  2.42e-05 -2.98e-08]
 [ 1.79e-03  9.75e-04  5.93e-04 -2.14e-04  3.77e-04 -3.07e-04 -9.90e-01 -3.68e-03
   4.21e-03  2.97e-04 -4.72e-04  6.70e-04  9.11e-09  1.56e-07 -7.67e-09]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.07e-03 -9.89e-01  8.03e-04 -1.58e-03  7.43e-03 -2.30e-04  2.61e-04 -1.63e-04
  -6.15e-04 -6.72e-04 -3.34e-04 -6.53e-04 -2.45e-09 -1.20e-05 -1.05e-08  1.97e-03]
 [-9.82e-01 -3.22e-03  4.79e-03 -6.95e-04 -6.51e-04  1.72e-04  1.05e-03  1.10e-03
  -9.08e-04  4.25e-04 -2.53e-04  1.16e-04 -1.04e-08  2.92e-06  2.86e-10 -1.05e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 6.41e-03 -4.42e-04 -3.51e-04  5.12e-02  8.40e-03  5.58e-02  1.72e-03 -2.90e-04
   1.26e-03  7.66e-04 -1.29e-03 -8.07e-06  3.67e-09  1.63e-06 -3.97e-09  9.89e-01
  -1.00e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[ 5.47e-06  7.39e-07  2.54e-06 -5.52e-06  1.91e-06  5.85e-06  4.21e-06  3.80e-06
   8.52e-07 -6.33e-06 -4.09e-06 -1.72e-06]
 [-4.17e-07  1.73e-06  1.07e-06  7.55e-06 -2.65e-06  8.76e-06 -5.13e-07 -3.30e-07
   3.33e-06  3.26e-06  1.22e-06 -1.49e-06]]
SymNet parameters
[ 3.83e-08 -3.20e-08]
SymNet parameters
[[ 1.37e-03  1.58e-03 -3.71e-03  5.83e-04 -7.13e-04 -1.11e-04  1.03e-03 -4.39e-04
   9.85e-01  1.02e-03  6.91e-03  5.63e-04  4.06e-07]
 [ 2.81e-03  4.33e-04  4.00e-04 -1.74e-05  1.45e-03 -2.58e-04 -9.89e-01 -5.98e-03
   2.38e-03  9.18e-04 -8.54e-05 -8.94e-04 -4.79e-06]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.32e-09 -1.28e-09 -4.43e-10 -2.72e-10  1.15e-08 -6.04e-09 -9.06e-10 -1.01e-09
   8.92e-10  2.07e-08  6.84e-09  4.17e-09 -2.03e-09 -4.44e-09]
 [-4.06e-09  5.88e-10 -1.35e-10  1.42e-08 -1.45e-10  6.45e-09 -2.92e-09 -5.72e-10
   6.10e-10 -1.63e-09  3.31e-09 -4.44e-09  6.72e-10  2.49e-09]]
SymNet parameters
[1.61e-09 4.92e-10]
SymNet parameters
[[ 1.69e-03 -5.61e-04 -2.18e-03 -5.72e-04  2.84e-04  1.65e-05 -9.11e-04 -9.84e-01
   7.67e-04 -7.50e-04  4.81e-03 -4.42e-04  3.93e-06  3.44e-03 -1.10e-08]
 [ 9.87e-01  4.27e-03 -4.78e-03 -6.42e-05  7.27e-04 -7.71e-04 -4.79e-04 -3.60e-04
   1.31e-04  4.51e-05  4.38e-04 -4.84e-04 -1.02e-06  1.00e-03 -2.47e-09]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-7.87e-10  2.29e-09  1.67e-09  1.80e-09  8.61e-11  3.46e-09 -7.66e-10  6.48e-10
   5.98e-09 -5.17e-09  4.43e-10 -1.66e-08 -1.07e-09 -4.76e-10  1.12e-09  2.12e-09]
 [-1.52e-10  9.36e-10 -1.41e-09 -5.42e-10  1.83e-09 -3.03e-09  8.84e-10  9.44e-10
  -2.32e-09  3.85e-09  3.70e-10  1.20e-08  8.78e-10 -6.19e-09  8.90e-10 -2.84e-09]]
SymNet parameters
[1.33e-11 1.12e-09]
SymNet parameters
[[ 5.42e-04 -2.12e-04 -1.97e-03 -2.60e-04 -8.28e-05  2.62e-04  6.48e-03 -9.75e-05
  -4.80e-04  5.29e-02  6.41e-03  5.36e-02 -5.39e-07  9.99e-01  5.79e-10  9.99e-01
   3.17e-09]]
SymNet parameters
[0.]
finally, finish this stage
iter:   230    time: 10.16
Func: 1.17e+00  |g|: 5.16e-03
stableloss: 6.48e-02   dataloss: 8.15e-01   sparseloss: 1.22e+01 momentloss: 9.16e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u11, u00*u11, u11*v00, u01*u10, u10*v10, u10*v01, u01**2, v00, u00*u10, v00*v01, u00*u10*v00, u00*u02, u01*v00, v11]
[-0.98 -0.97  0.06  0.05  0.01  0.01  0.01  0.01 -0.01  0.01  0.   -0.   -0.    0.
  0.    0.   -0.   -0.    0.   -0.  ]
[v00*v10, u00*v01, v20, v02, v00, v00*v11, v11, v01*v10, u00*v11, u10*v01, u01*v01, u10*v00, u00*v10, u00*v00*v10, v10**2, u00*v00, u00*u10, u10, u00**2, u01*v00]
[-0.97 -0.97  0.05  0.05  0.01 -0.01  0.01 -0.01  0.    0.   -0.    0.    0.   -0.
  0.   -0.   -0.   -0.    0.   -0.  ]
block:  6
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -1.0095853399633583
current stage is: block-6
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7181, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2442,  1.7287,  1.4675, 18.3607,  9.3567, 20.5002,  0.2412,  1.6161,
         1.6505, 16.8272,  9.3739, 25.8824], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 11.46
Func: 1.48e+00  |g|: 1.48e+01
stableloss: 6.44e-02   dataloss: 1.06e+00   sparseloss: 1.22e+01 momentloss: 9.16e+00
iter:   200    time: 33.22
Func: 1.36e+00  |g|: 9.37e-03
stableloss: 6.45e-02   dataloss: 9.41e-01   sparseloss: 1.22e+01 momentloss: 8.85e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 1.359785
         Iterations: 330
         Function evaluations: 477
         Gradient evaluations: 460
convolution moment and kernels
[[ 1.    0.   -0.01  0.03 -0.08]
 [ 0.    0.    0.01  0.01 -0.07]
 [ 0.    0.03  0.08 -0.01 -0.  ]
 [-0.02 -0.01  0.   -0.01 -0.02]
 [-0.07  0.07 -0.01  0.02 -0.01]]
[[-0.01 -0.03 -0.04  0.02  0.  ]
 [ 0.08  0.02  0.27 -0.11  0.02]
 [-0.15  0.06  0.5   0.2  -0.05]
 [ 0.01  0.27 -0.05  0.11 -0.03]
 [-0.01  0.   -0.12  0.06 -0.01]]
[[ 0.    1.    0.   -0.1  -0.11]
 [ 0.    0.   -0.01 -0.   -0.01]
 [ 0.    0.04 -0.06  0.09 -0.05]
 [-0.    0.   -0.01 -0.01  0.01]
 [ 0.   -0.   -0.02  0.01 -0.01]]
[[-0.01  0.05 -0.05  0.03 -0.01]
 [-0.04  0.05 -0.03 -0.02  0.03]
 [ 0.15 -0.58 -0.42  1.14 -0.27]
 [-0.07  0.16 -0.17  0.07  0.01]
 [-0.   -0.    0.02 -0.   -0.  ]]
[[ 0.    0.    0.    0.01  0.  ]
 [ 1.    0.    0.05  0.01  0.02]
 [ 0.    0.02 -0.09 -0.   -0.02]
 [-0.1   0.02  0.06  0.01  0.01]
 [-0.09  0.05 -0.07  0.01 -0.02]]
[[-0.01 -0.05  0.14 -0.02 -0.01]
 [ 0.04  0.12 -0.6   0.01  0.02]
 [-0.05 -0.11 -0.42  0.09 -0.03]
 [ 0.04  0.06  1.12 -0.13  0.04]
 [-0.01 -0.02 -0.21  0.03 -0.01]]
[[ 0.    0.    1.    0.    0.01]
 [ 0.    0.    0.    0.04  0.01]
 [ 0.    0.    0.58  0.    0.09]
 [ 0.    0.    0.01 -0.   -0.  ]
 [ 0.1  -0.01  0.01  0.01  0.01]]
[[ 1.68e-03 -5.74e-02  2.31e-01 -8.93e-02  1.34e-02]
 [ 4.22e-02  6.07e-01 -1.78e+00  7.40e-01 -8.28e-03]
 [-1.50e-01  2.04e-01  5.66e-01  9.75e-02 -1.20e-01]
 [ 2.86e-02  5.88e-01 -1.65e+00  6.03e-01  3.61e-02]
 [ 1.77e-03 -3.95e-02  1.84e-01 -4.94e-02  3.13e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.62e-05]
 [ 0.00e+00  1.00e+00  0.00e+00  2.69e-03  2.39e-03]
 [ 0.00e+00  0.00e+00  9.43e-04  1.92e-03  2.99e-03]
 [ 0.00e+00  8.59e-04  2.39e-03 -1.90e-03 -1.85e-03]
 [ 5.46e-03  5.35e-03  1.24e-03 -3.41e-03  1.20e-03]]
[[ 0.01 -0.07  0.02  0.05 -0.01]
 [-0.07  0.49 -0.04 -0.46  0.06]
 [ 0.01 -0.04  0.02  0.05 -0.02]
 [ 0.05 -0.43  0.01  0.39 -0.04]
 [-0.    0.05 -0.   -0.04  0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.76e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  9.69e-03  1.72e-02]
 [ 1.00e+00  0.00e+00  9.20e-03  4.56e-03  1.13e-01]
 [ 0.00e+00 -4.37e-04  2.07e-02 -2.70e-03 -7.47e-03]
 [ 6.75e-03 -3.79e-02  2.20e-01  8.20e-03  3.31e-02]]
[[ 3.40e-03  1.98e-01 -4.25e-01  1.28e-01  1.97e-02]
 [ 9.98e-02 -1.26e+00  3.41e+00 -9.87e-01  3.87e-02]
 [-5.28e-02  1.55e+00 -5.14e+00  1.17e+00  2.29e-02]
 [ 1.32e-01 -1.45e+00  3.75e+00 -1.21e+00  8.91e-02]
 [-6.54e-03  2.63e-01 -5.39e-01  2.01e-01  5.47e-03]]
SymNet parameters
[[ 1.12e-13  8.84e-16  1.37e-14 -9.49e-14  3.85e-14 -9.77e-14  3.39e-14 -4.22e-14
   6.36e-15 -4.00e-15  4.93e-14 -7.02e-14]
 [-2.65e-15  4.48e-14  2.03e-14  5.85e-14  1.67e-14  2.78e-14  1.53e-14 -3.60e-14
   3.26e-14 -9.58e-14 -1.67e-14 -3.21e-14]]
SymNet parameters
[-9.72e-15 -1.50e-15]
SymNet parameters
[[ 3.38e-10  2.06e-10  1.86e-10 -9.82e-10  9.28e-10 -4.35e-11  3.42e-11  8.79e-11
  -6.06e-10  4.15e-10  2.27e-10  2.71e-11  3.76e-14]
 [-8.82e-11 -4.75e-12 -2.54e-11  4.81e-10 -1.88e-10  1.33e-11 -4.09e-10  5.13e-10
  -4.07e-10  8.29e-10 -2.94e-10 -4.22e-10 -9.59e-14]]
SymNet parameters
[-1.45e-12 -4.99e-12]
SymNet parameters
[[ 1.44e-14 -2.43e-14  7.65e-15  1.93e-15 -2.02e-13 -1.12e-13  5.87e-14 -4.79e-14
   2.39e-14 -1.50e-13 -1.33e-14 -1.21e-13 -1.86e-14  1.62e-15]
 [-1.45e-13  8.04e-14  1.85e-15  1.51e-13 -1.31e-13  4.38e-13  6.38e-14 -1.58e-14
  -3.16e-15 -1.51e-13  5.24e-14  1.19e-13  4.59e-15 -1.40e-14]]
SymNet parameters
[1.58e-14 3.52e-16]
SymNet parameters
[[ 8.39e-04  3.62e-04  9.93e-01  5.52e-04  9.21e-04 -4.76e-04  1.07e-03 -7.41e-04
   8.50e-04  2.10e-04  8.02e-04 -3.63e-04  2.59e-14 -2.05e-10 -3.90e-13]
 [ 9.70e-04 -9.33e-05 -2.25e-04  2.51e-05 -2.82e-04  4.84e-06 -9.93e-01 -1.52e-03
   1.69e-03  4.65e-04 -3.70e-04  6.22e-04  1.19e-13  2.53e-10 -1.01e-13]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-1.33e-03 -9.92e-01  1.69e-03  8.35e-04  6.14e-04 -3.93e-04 -8.27e-04 -1.00e-03
   6.33e-05  3.46e-04  1.16e-04 -2.15e-04 -3.17e-14 -7.13e-11 -1.36e-13 -4.11e-04]
 [-9.85e-01  1.04e-03 -5.90e-05 -3.93e-04 -1.22e-04  2.67e-04  1.33e-03  8.78e-05
   5.79e-04 -8.90e-04 -4.37e-05  4.99e-05 -1.35e-13 -2.75e-10  2.73e-15 -9.47e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 7.66e-03  4.79e-03  1.28e-03  5.23e-02  9.50e-03  5.44e-02  5.65e-04  7.96e-04
  -4.29e-04  7.25e-06 -2.66e-04 -5.54e-04  4.78e-14  7.91e-11 -5.18e-14  9.89e-01
  -9.99e-01]]
SymNet parameters
[-0.]
SymNet parameters
[[-1.37e-10 -1.13e-10 -9.41e-11  1.66e-10  8.35e-11  5.62e-10 -7.96e-11  2.91e-10
  -2.57e-10 -5.65e-10 -6.77e-10  1.09e-09]
 [ 2.32e-10  2.87e-10  1.92e-10 -3.79e-10  1.80e-10 -2.87e-10  2.94e-10 -4.48e-10
   3.45e-10  2.84e-10  2.65e-10  1.90e-10]]
SymNet parameters
[ 2.63e-12 -2.72e-12]
SymNet parameters
[[ 1.08e-03  5.97e-04  2.99e-04  1.19e-04  2.30e-04  2.69e-04 -5.76e-05 -8.02e-05
   9.93e-01 -2.81e-05  1.24e-03 -5.99e-05  1.12e-10]
 [ 3.99e-04  6.27e-04  1.14e-03 -2.10e-05 -5.45e-04 -3.02e-04 -9.93e-01 -7.36e-04
   4.69e-04  2.94e-04  3.51e-05 -4.16e-04 -2.39e-10]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.72e-14 -1.67e-14 -5.80e-15 -3.47e-15  1.50e-13 -7.88e-14 -1.19e-14 -1.31e-14
   1.16e-14  2.70e-13  8.95e-14  5.46e-14 -2.65e-14 -5.80e-14]
 [-5.31e-14  7.71e-15 -1.78e-15  1.85e-13 -1.85e-15  8.46e-14 -3.83e-14 -7.40e-15
   7.93e-15 -2.15e-14  4.34e-14 -5.81e-14  8.78e-15  3.25e-14]]
SymNet parameters
[2.10e-14 6.42e-15]
SymNet parameters
[[-7.08e-04  1.71e-03 -8.07e-04  4.06e-04  2.55e-04 -9.14e-05 -9.98e-04 -9.89e-01
   6.96e-05  2.72e-04  6.10e-04 -7.01e-04  1.64e-10  4.99e-04 -1.44e-13]
 [ 9.88e-01  1.91e-03 -1.57e-03 -7.14e-04  3.44e-04 -2.07e-04 -9.42e-05 -4.08e-04
   5.77e-04  2.55e-05  4.21e-04  9.91e-05 -4.01e-11  1.52e-03 -3.19e-14]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-1.03e-14  2.99e-14  2.18e-14  2.35e-14  1.14e-15  4.52e-14 -1.00e-14  8.46e-15
   7.81e-14 -6.75e-14  5.77e-15 -2.16e-13 -1.40e-14 -6.18e-15  1.46e-14  2.77e-14]
 [-1.98e-15  1.22e-14 -1.84e-14 -7.10e-15  2.39e-14 -3.95e-14  1.15e-14  1.23e-14
  -3.03e-14  5.03e-14  4.86e-15  1.57e-13  1.15e-14 -8.09e-14  1.16e-14 -3.71e-14]]
SymNet parameters
[1.74e-16 1.46e-14]
SymNet parameters
[[ 1.07e-03  1.68e-03 -3.45e-04 -3.20e-05  2.47e-04 -3.96e-04  7.15e-03  1.72e-03
  -1.05e-03  5.32e-02  8.65e-03  5.30e-02  1.38e-10  9.95e-01  7.86e-15  9.95e-01
   4.07e-14]]
SymNet parameters
[0.]
finally, finish this stage
iter:   330    time: 40.32
Func: 1.36e+00  |g|: 6.18e-07
stableloss: 6.45e-02   dataloss: 9.41e-01   sparseloss: 1.22e+01 momentloss: 8.89e+00
current expression:
[u00*u01, u10*v00, u20, u02, u11, u01*u10*v00, u00, u01, u00*u10, u10, u10*v10, u00*v00, u10*v01, u00**2, v00, v00**2, u01**2, u00*v01, u01*v00, u11*v00]
[-9.77e-01 -9.76e-01  5.44e-02  5.23e-02  9.50e-03  9.26e-03  8.64e-03  5.77e-03
  2.62e-03  2.25e-03  1.66e-03 -1.64e-03 -1.49e-03 -1.31e-03  1.10e-03 -1.05e-03
  1.03e-03 -9.86e-04  9.56e-04 -9.06e-04]
[v00*v10, u00*v01, v02, v20, v11, v00, v01, u00*v00, u00, v10, u01*v01, u00*u01, u01, u10*v01, v00*v01*v10, v01*v10, v00*v11, u10*v10, u00*u10, u02*v01]
[-9.81e-01 -9.73e-01  5.32e-02  5.30e-02  8.65e-03  8.13e-03  2.69e-03 -2.05e-03
  2.04e-03 -2.03e-03 -1.88e-03  1.69e-03  1.68e-03  1.55e-03  1.47e-03 -1.29e-03
 -1.22e-03  1.12e-03 -7.92e-04  7.02e-04]
block:  9
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  0.33725936586890737
current stage is: block-9
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8690, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2617,  1.7715,  1.7203, 15.8349, 11.2532, 21.8216,  0.2533,  1.6178,
         1.7586, 13.4089, 10.5548, 26.1585], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 9.91
Func: 4.21e+00  |g|: 5.48e+01
stableloss: 1.07e-01   dataloss: 3.58e+00   sparseloss: 1.22e+01 momentloss: 8.89e+00
iter:   200    time: 47.60
Func: 3.66e+00  |g|: 2.69e-01
stableloss: 1.04e-01   dataloss: 2.99e+00   sparseloss: 1.25e+01 momentloss: 1.17e+01
iter:   400    time: 62.37
Func: 3.66e+00  |g|: 1.10e-04
stableloss: 1.04e-01   dataloss: 2.99e+00   sparseloss: 1.25e+01 momentloss: 1.19e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 3.655727
         Iterations: 446
         Function evaluations: 551
         Gradient evaluations: 546
convolution moment and kernels
[[ 1.00e+00  0.00e+00  5.74e-03 -4.99e-02 -3.45e-02]
 [ 0.00e+00 -9.57e-03 -2.90e-02 -2.82e-03 -1.77e-02]
 [-6.97e-03  3.56e-04  4.25e-02  3.66e-02 -6.72e-03]
 [ 4.19e-02  1.59e-02  6.70e-03 -1.47e-02 -2.16e-02]
 [-7.32e-02 -5.95e-02 -4.12e-03 -2.03e-02 -4.90e-03]]
[[ 0.01 -0.01 -0.03 -0.07  0.  ]
 [-0.04  0.07  0.08  0.19  0.03]
 [ 0.07 -0.    0.61  0.05 -0.14]
 [-0.04 -0.02  0.25 -0.02  0.07]
 [-0.    0.06 -0.13  0.05 -0.02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.86e-02 -9.62e-02]
 [ 0.00e+00  0.00e+00 -6.63e-03 -1.62e-02 -3.52e-02]
 [ 0.00e+00  6.18e-02 -9.80e-02  5.49e-02 -8.21e-02]
 [ 3.62e-03  5.41e-03  2.65e-02 -1.43e-02 -1.32e-04]
 [-6.25e-03  2.08e-02 -3.46e-02 -1.36e-02 -3.13e-02]]
[[-0.02  0.03 -0.07  0.08 -0.03]
 [-0.03  0.02  0.17 -0.23  0.1 ]
 [ 0.16 -0.6  -0.6   1.33 -0.32]
 [-0.07  0.13  0.03 -0.14  0.06]
 [-0.01  0.03 -0.1   0.11 -0.03]]
[[ 0.    0.    0.   -0.01 -0.  ]
 [ 1.    0.    0.05 -0.02 -0.04]
 [ 0.   -0.01 -0.07 -0.   -0.  ]
 [-0.12 -0.03  0.06 -0.01 -0.  ]
 [-0.11 -0.01 -0.07  0.01 -0.01]]
[[-1.43e-02 -4.40e-02  1.64e-01 -7.29e-02  6.69e-04]
 [ 7.86e-02 -7.60e-02 -4.24e-01  4.15e-02  2.58e-02]
 [-8.50e-02  7.02e-02 -4.73e-01 -1.54e-01 -1.32e-04]
 [ 3.86e-02  2.75e-02  9.31e-01  2.52e-01 -3.88e-02]
 [-1.39e-02  1.95e-02 -2.14e-01 -4.30e-02  3.30e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  1.76e-04]
 [ 0.00e+00  0.00e+00  0.00e+00 -5.41e-03  8.82e-03]
 [ 0.00e+00  0.00e+00  7.71e-03 -4.02e-03  3.27e-01]
 [ 0.00e+00  1.30e-03 -7.49e-03 -1.47e-03 -9.60e-03]
 [ 2.41e-01  5.05e-02  5.25e-03 -2.20e-02  1.37e-01]]
[[ 0.13 -0.5   0.91 -0.39  0.1 ]
 [-0.18  0.7  -1.68  0.27 -0.07]
 [ 0.01  1.01 -1.06  1.66 -0.17]
 [-0.15  0.6  -1.53  0.16 -0.04]
 [ 0.12 -0.47  0.86 -0.36  0.09]]
[[ 0.    0.    0.    0.   -0.04]
 [ 0.    1.    0.    0.   -1.36]
 [ 0.    0.    0.3  -0.01  0.  ]
 [ 0.    0.    0.    0.    0.01]
 [ 0.27 -0.   -0.   -0.01 -0.07]]
[[-0.17  0.64 -0.76  0.76 -0.19]
 [ 1.09 -3.74  5.01 -4.66  1.22]
 [-0.38  0.79  0.78  0.83 -0.4 ]
 [-0.63  2.67 -5.93  3.52 -0.72]
 [ 0.05 -0.18  0.63 -0.28  0.06]]
[[ 0.    0.    0.    0.    0.15]
 [ 0.    0.    0.   -0.    0.03]
 [ 1.    0.    0.8  -0.03  0.01]
 [ 0.    0.   -0.07 -0.   -0.  ]
 [-0.   -0.01  0.44 -0.    0.01]]
[[-0.02  0.5  -1.02  0.48 -0.02]
 [ 0.03 -0.84  2.9  -0.73 -0.01]
 [ 0.1   0.17 -2.95 -0.01  0.17]
 [ 0.07 -0.86  2.86 -0.76  0.03]
 [-0.03  0.44 -0.91  0.43 -0.03]]
SymNet parameters
[[-1.05e-12  5.84e-12 -5.89e-12 -8.09e-12  7.77e-11 -3.96e-12  2.04e-11 -7.57e-12
   8.88e-13 -2.95e-11  2.62e-11 -2.45e-11]
 [-4.71e-12 -3.20e-12 -3.29e-13  2.34e-11 -8.49e-12  6.33e-12  7.98e-12 -7.78e-13
   3.23e-13 -1.55e-11  5.02e-12 -6.42e-12]]
SymNet parameters
[1.13e-14 1.14e-15]
SymNet parameters
[[ 2.32e-11 -6.68e-12  4.86e-11 -1.16e-11 -2.05e-11 -3.31e-11 -3.91e-12 -8.60e-12
  -3.04e-11 -7.61e-12 -2.97e-11  1.88e-11 -1.57e-14]
 [ 2.13e-11  3.55e-11 -5.28e-11  2.23e-11 -2.45e-11 -3.09e-11  2.53e-11 -6.73e-11
  -5.97e-11  4.97e-12  3.66e-11  4.87e-11  4.02e-14]]
SymNet parameters
[ 1.61e-11 -1.79e-10]
SymNet parameters
[[-8.85e-11  1.22e-10 -2.07e-11 -1.43e-10  1.45e-10  6.14e-11  2.64e-12 -2.37e-11
   3.96e-11  5.79e-11 -3.76e-11 -3.09e-11  7.70e-15 -6.78e-16]
 [-3.33e-11  2.04e-10  2.17e-11  2.74e-10 -1.51e-10  1.14e-10  3.11e-12  3.88e-11
  -1.67e-11  8.42e-11 -1.02e-10 -5.53e-12 -1.92e-15  5.85e-15]]
SymNet parameters
[-1.59e-13 -3.65e-13]
SymNet parameters
[[-4.65e-04 -4.50e-04  9.88e-01  3.67e-04 -6.83e-03 -1.54e-03 -2.52e-03  2.07e-03
   7.02e-04  1.62e-04  8.57e-04  2.53e-04  5.98e-12  1.15e-11 -1.53e-10]
 [ 2.64e-04 -2.71e-03  6.15e-04  4.76e-05 -9.77e-05 -6.06e-04 -9.89e-01  5.92e-03
  -2.69e-03  1.46e-04 -5.78e-04  6.12e-04  1.24e-12 -5.94e-11  2.02e-10]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 1.05e-03 -9.97e-01  4.05e-05  7.64e-04  1.03e-03  1.02e-03  5.92e-04  1.02e-03
   3.19e-03  1.58e-04  1.76e-03  4.47e-04  5.00e-12  5.70e-11  1.06e-10 -6.81e-04]
 [-9.81e-01  2.47e-03 -9.68e-04 -9.61e-04 -9.81e-04  1.06e-03  8.71e-04  5.99e-04
   2.50e-03  8.96e-04  8.76e-04 -2.73e-04 -3.15e-11 -9.46e-11  1.13e-10 -8.21e-03]]
SymNet parameters
[ 0.   -0.01]
SymNet parameters
[[ 1.01e-02 -9.90e-04  1.06e-03  5.42e-02 -2.22e-04  5.44e-02  6.61e-04  2.34e-03
   5.18e-04  3.94e-04  9.51e-05  8.77e-05  3.25e-12 -6.88e-11 -3.18e-11  9.94e-01
  -1.01e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[ 2.66e-11 -3.36e-11  5.29e-11  1.74e-11 -7.09e-11 -9.94e-12 -4.46e-11  7.89e-12
  -5.11e-11  3.32e-12 -4.41e-11 -4.53e-12]
 [-1.58e-11  1.67e-11  3.95e-11  2.36e-11 -2.19e-11  1.07e-10 -2.35e-11 -6.02e-11
   7.04e-11 -2.38e-11 -2.08e-11  1.63e-12]]
SymNet parameters
[-3.18e-11  4.44e-11]
SymNet parameters
[[-5.97e-04 -1.86e-03  1.18e-03  5.85e-04  1.64e-04 -7.39e-04  1.16e-03  8.67e-04
   1.02e+00  5.39e-04 -7.43e-03 -1.71e-03  5.82e-12]
 [-1.16e-01  1.32e-04  1.18e-03  2.65e-05 -9.75e-05  1.09e-04 -9.22e-01  4.66e-03
  -1.26e-03  4.63e-04 -1.79e-04 -7.43e-04 -9.81e-12]]
SymNet parameters
[-0.01  0.  ]
SymNet parameters
[[-1.21e-11 -5.92e-13 -6.77e-12 -4.05e-11 -1.61e-11  8.23e-11  2.97e-11  1.28e-11
  -3.26e-12 -1.97e-10 -6.93e-11 -6.42e-11  1.11e-14  1.46e-11]
 [ 2.45e-11 -3.64e-12  2.51e-12 -6.86e-11  5.96e-12 -6.48e-11 -3.86e-11  7.84e-12
   4.46e-12  4.35e-11 -1.27e-10  7.88e-11 -3.65e-15  3.22e-12]]
SymNet parameters
[-3.80e-14  2.81e-14]
SymNet parameters
[[-9.25e-04 -1.30e-03 -6.03e-04 -3.23e-04  1.69e-03 -2.44e-04  8.04e-04 -9.16e-01
   1.17e-01  8.00e-04 -5.80e-04  2.05e-03 -3.22e-11 -2.75e-03 -8.82e-11]
 [ 1.02e+00 -4.58e-03  3.12e-03 -2.77e-04  8.51e-04 -7.03e-04  1.39e-03  1.37e-03
  -3.42e-04 -2.05e-04 -6.92e-04 -1.69e-04 -2.83e-11 -5.87e-03  1.47e-11]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 7.51e-15 -2.81e-14  3.64e-14  2.20e-13  2.88e-14  2.10e-13  6.21e-15  4.32e-15
  -3.78e-14 -1.61e-13  1.41e-13  2.80e-12  5.82e-15  6.17e-13 -6.08e-15  3.27e-13]
 [-2.36e-15 -1.53e-14 -2.38e-15 -1.03e-13 -2.47e-13  3.56e-14  5.89e-16  2.65e-14
   1.47e-13  4.03e-15 -3.37e-13 -7.88e-13 -4.77e-15 -2.67e-13 -4.83e-15 -1.60e-13]]
SymNet parameters
[-7.44e-16 -7.56e-15]
SymNet parameters
[[ 3.72e-04 -1.56e-03 -1.37e-03 -2.60e-04  2.78e-04 -6.82e-04  3.90e-03 -9.87e-04
   4.28e-04  5.52e-02 -1.33e-03  5.36e-02  1.17e-12  1.04e+00  2.03e-11  1.04e+00
   2.95e-12]]
SymNet parameters
[-3.91e-05]
finally, finish this stage
iter:   446    time: 12.88
Func: 3.66e+00  |g|: 5.94e-07
stableloss: 1.04e-01   dataloss: 2.99e+00   sparseloss: 1.25e+01 momentloss: 1.19e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00, u01, u01*u10*v00, u11*v00, u10*v01, u01*u10, 1, u00*v10, u10*v10, u01*v10, u01**2, v00**2, v01, v00*v01, u10, u00*v11]
[-0.99 -0.97  0.05  0.05  0.01 -0.01  0.01  0.01  0.01 -0.   -0.    0.   -0.    0.
  0.    0.    0.   -0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00, v00*v11, v01*v10, v00*v01*v10, u01*v01, v01, u10*v01, u00*v00*v10, u00*v20, v00*v01, u00*u11, u01*v00, u00*v10, v00*v20, u10*v10, u01]
[-0.98 -0.98  0.06  0.05  0.01  0.01  0.01 -0.01  0.   -0.   -0.    0.    0.   -0.
  0.    0.    0.    0.    0.   -0.  ]
block:  12
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -2.2145225646217974
current stage is: block-12
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.4803, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2518,  1.6903,  1.6198, 23.5963, 33.7020, 14.5931,  0.2676,  1.6766,
         1.8366, 20.6026, 24.3724, 21.1671], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 13.32
Func: 6.96e+00  |g|: 8.82e+01
stableloss: 8.52e-02   dataloss: 6.07e+00   sparseloss: 1.25e+01 momentloss: 1.19e+01
iter:   200    time: 60.84
Func: 6.00e+00  |g|: 4.22e+00
stableloss: 9.06e-02   dataloss: 5.04e+00   sparseloss: 1.37e+01 momentloss: 1.21e+01
iter:   400    time: 63.71
Func: 4.57e+00  |g|: 6.27e+00
stableloss: 7.15e-02   dataloss: 3.36e+00   sparseloss: 1.84e+01 momentloss: 9.24e+00
iter:   600    time: 60.00
Func: 4.42e+00  |g|: 1.52e+00
stableloss: 6.98e-02   dataloss: 3.25e+00   sparseloss: 1.78e+01 momentloss: 8.43e+00
iter:   800    time: 59.26
Func: 4.41e+00  |g|: 3.58e-01
stableloss: 6.97e-02   dataloss: 3.24e+00   sparseloss: 1.78e+01 momentloss: 8.51e+00
iter:  1000    time: 59.74
Func: 4.41e+00  |g|: 8.20e-02
stableloss: 6.97e-02   dataloss: 3.23e+00   sparseloss: 1.79e+01 momentloss: 8.59e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 4.407932
         Iterations: 1017
         Function evaluations: 1102
         Gradient evaluations: 1089
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.14e-03 -4.22e-02 -6.43e-02]
 [ 0.00e+00  1.84e-03  3.34e-02 -1.58e-03  3.85e-02]
 [-3.09e-04 -2.86e-02  8.88e-02 -1.65e-01  4.97e-03]
 [ 1.45e-02  3.45e-03  5.58e-02 -3.65e-03  5.41e-02]
 [-4.17e-02 -1.15e-02  7.57e-02 -9.31e-02  2.44e-02]]
[[ 3.45e-02 -1.36e-02 -1.56e-01  1.27e-01 -4.14e-02]
 [-1.24e-01  1.92e-01  1.82e-01 -9.37e-02  2.40e-02]
 [ 1.45e-01 -1.64e-01  5.97e-01  2.16e-01 -4.37e-02]
 [-1.78e-01  3.38e-01 -2.01e-02  3.61e-02 -2.42e-02]
 [ 7.99e-02 -1.43e-01  1.91e-02  9.21e-03  1.37e-04]]
[[ 0.    1.    0.   -0.11 -0.08]
 [ 0.    0.    0.   -0.01 -0.01]
 [ 0.    0.03 -0.02  0.05 -0.03]
 [ 0.01  0.    0.02  0.    0.01]
 [-0.01  0.   -0.01  0.01 -0.  ]]
[[-0.01  0.01 -0.01 -0.   -0.  ]
 [-0.03  0.06 -0.05  0.05  0.  ]
 [ 0.13 -0.61 -0.32  0.98 -0.21]
 [-0.04  0.09 -0.11  0.09 -0.02]
 [-0.    0.01 -0.   -0.01  0.01]]
[[ 0.    0.    0.   -0.01 -0.02]
 [ 1.    0.    0.03  0.01  0.  ]
 [ 0.    0.    0.03 -0.01  0.01]
 [-0.1   0.01  0.03  0.02  0.  ]
 [-0.07  0.01  0.01 -0.    0.01]]
[[ 1.10e-02 -3.92e-02  1.06e-01 -1.33e-02 -6.31e-04]
 [-2.09e-02  9.34e-02 -6.04e-01  4.57e-02 -6.11e-03]
 [ 2.40e-03 -4.96e-02 -3.67e-01  1.31e-02 -7.26e-03]
 [-9.06e-03  6.62e-02  9.57e-01  3.94e-02 -1.70e-02]
 [ 3.21e-03 -6.98e-03 -2.03e-01 -6.38e-05  7.16e-03]]
[[ 0.    0.    1.    0.   -0.02]
 [ 0.    0.    0.   -0.01  0.01]
 [ 0.    0.    0.01  0.03  0.13]
 [ 0.    0.    0.   -0.   -0.01]
 [ 0.04 -0.02  0.03 -0.01 -0.  ]]
[[-0.01  0.09 -0.09  0.07 -0.02]
 [ 0.15 -0.84  1.15 -0.86  0.21]
 [-0.41  2.99 -4.86  3.06 -0.51]
 [ 0.17 -0.93  1.3  -0.95  0.23]
 [-0.02  0.12 -0.15  0.11 -0.02]]
[[ 0.    0.    0.    0.    0.06]
 [ 0.    1.    0.   -0.   -0.1 ]
 [ 0.    0.   -0.   -0.01  0.01]
 [ 0.   -0.01  0.1   0.27 -0.  ]
 [ 0.04  0.    0.01 -0.08 -0.02]]
[[ 0.09 -0.22 -0.03  0.34 -0.14]
 [-0.2   0.5   0.64 -1.61  0.51]
 [ 0.14 -0.07 -0.41  0.92 -0.33]
 [ 0.07 -0.68  0.33  0.11  0.01]
 [-0.05  0.24 -0.19  0.02  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.69e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  3.37e-03 -4.21e-03]
 [ 1.00e+00  0.00e+00  1.00e-01  6.53e-03 -4.15e-03]
 [ 0.00e+00  3.26e-03 -6.37e-05 -7.51e-03 -2.08e-03]
 [ 4.57e-02 -8.25e-03  3.94e-03  2.95e-03  7.32e-03]]
[[ 0.   -0.03  0.02 -0.05  0.01]
 [-0.03  0.26  0.65  0.33 -0.05]
 [ 0.24 -1.16 -0.32 -1.23  0.25]
 [-0.05  0.29  0.64  0.31 -0.04]
 [ 0.01 -0.03  0.02 -0.04  0.01]]
SymNet parameters
[[-4.44e-02  1.42e-01  1.84e-02  8.84e-03 -8.38e-03 -1.80e-03  2.66e-01 -6.97e-04
   8.68e-03  3.00e-04 -1.91e-04 -4.63e-03]
 [ 4.03e-01  7.33e-03 -7.53e-04  1.12e-04  8.30e-04 -3.15e-02 -6.99e-03 -7.64e-03
  -4.15e-02  3.15e-04  2.44e-03 -1.90e-03]]
SymNet parameters
[-1.00e-04 -9.63e-05]
SymNet parameters
[[-3.78e-01 -7.59e-04 -4.04e-04 -6.92e-04 -3.74e-04 -1.78e-03 -1.85e-04  4.85e-03
   6.46e-02  7.16e-04 -1.87e-04  4.10e-04  9.47e-03]
 [ 7.03e-02 -9.82e-05  2.01e-01 -6.30e-03 -3.00e-02 -6.81e-03 -1.42e-01  3.86e-04
  -3.61e-04 -3.16e-04 -1.68e-04  9.04e-04  1.72e-03]]
SymNet parameters
[-1.46e-04  1.31e-06]
SymNet parameters
[[-2.31e-06 -1.31e-07 -2.76e-06  1.90e-06  7.79e-07 -8.35e-07  8.12e-07  1.60e-06
  -1.37e-06  4.71e-07 -3.00e-07 -1.73e-06 -1.09e-06  2.65e-06]
 [-1.55e-06 -2.16e-07  7.54e-07  5.33e-07  3.03e-07  1.41e-06 -2.90e-06 -8.54e-07
   1.92e-06  1.07e-06 -2.34e-06  2.55e-07  8.79e-07  1.27e-07]]
SymNet parameters
[-7.05e-07  1.69e-07]
SymNet parameters
[[ 1.36e-04 -3.38e-04  6.26e-01  2.60e-04  5.92e-05 -4.34e-04 -7.85e-04  3.73e-04
   7.66e-04  9.46e-05  9.06e-05  4.14e-05  2.17e-01 -4.37e-01  1.04e-06]
 [-4.92e-04 -9.48e-04  1.08e-03  2.03e-04 -2.09e-04 -6.57e-04 -1.28e+00  8.54e-03
  -3.27e-03  5.82e-04 -2.25e-05  5.73e-04 -4.50e-04 -6.65e-03 -1.14e-06]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-1.49e-03 -9.29e-01  1.43e-03  1.27e-03 -7.49e-05  1.27e-04 -4.62e-04  1.99e-03
  -8.03e-04 -1.03e-04  4.15e-04  4.04e-06  1.11e-01  1.07e-02  1.25e-08 -6.49e-02]
 [-9.36e-01  1.91e-03 -1.59e-03 -4.83e-04  3.76e-04  1.87e-04 -9.78e-04  1.09e-03
  -4.03e-04  9.90e-05 -3.13e-05  6.14e-06  1.65e-01 -5.42e-04  1.74e-06 -1.26e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 9.05e-04 -3.75e-03  1.05e-03  4.99e-02  9.15e-04  5.16e-02 -6.61e-04 -2.98e-04
   5.15e-03  3.35e-04 -4.40e-04  1.47e-04  8.03e-05 -4.61e-05  1.60e-06  1.23e+00
  -1.12e+00]]
SymNet parameters
[0.]
SymNet parameters
[[ 4.22e-04  1.65e-04  1.04e-02  1.29e-03 -2.07e-03  1.02e-03  6.38e-02  6.17e-02
  -1.89e-01 -7.40e-04  3.18e-03 -3.34e-02]
 [ 7.10e-05 -8.35e-03 -1.76e-02  2.03e-03  3.38e-04 -7.88e-04  6.52e-02 -3.88e-02
   1.88e-01 -7.37e-04 -8.48e-03 -3.72e-02]]
SymNet parameters
[ 4.35e-05 -7.23e-05]
SymNet parameters
[[-6.77e-04  4.94e-04  2.32e-03  3.89e-05 -6.57e-06  1.56e-04 -3.43e-04  2.74e-04
   8.38e-01 -4.46e-05  2.71e-04  1.94e-04  3.52e-01]
 [-2.05e-04 -7.78e-04  1.47e-04  1.81e-04 -1.54e-04 -2.79e-04 -1.06e+00  1.49e-01
  -9.24e-04  4.80e-04  1.35e-04 -3.97e-04  2.35e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 8.53e-03  1.03e-02  2.44e-03  2.65e-03 -6.26e-05  6.11e-03 -9.65e-03 -5.71e-04
   2.67e-01  2.45e-03  6.09e-02  1.30e-03  7.11e-04 -3.40e-03]
 [ 6.40e-04 -2.73e-04  2.73e-04  1.28e-03 -2.70e-03  1.88e-04 -3.13e-01 -2.59e-02
   2.11e-03 -8.15e-05  1.25e-04 -4.02e-03  8.26e-05 -2.62e-02]]
SymNet parameters
[1.21e-04 6.29e-05]
SymNet parameters
[[-1.11e-04 -4.06e-05 -1.26e-03 -2.18e-06  4.90e-04 -2.08e-04  1.58e-03 -7.78e-01
  -5.89e-04  8.11e-04  2.19e-04  8.56e-05  2.94e-04  3.52e-02 -3.65e-01]
 [ 1.02e+00 -6.06e-03  1.96e-03 -6.00e-04 -2.13e-04  4.81e-05 -5.18e-04 -4.66e-04
   1.43e-01 -1.36e-04  3.34e-04  3.76e-04  1.71e-02  7.94e-03  1.02e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-2.55e-07 -5.42e-07 -1.15e-06 -1.43e-06  8.76e-07  8.71e-07 -4.47e-07 -1.22e-06
   2.94e-07 -9.76e-07 -2.10e-06  6.56e-07 -3.03e-07  2.89e-07 -9.94e-07 -4.86e-07]
 [ 9.02e-07 -7.42e-07 -9.93e-07  3.97e-07 -1.13e-06  3.70e-07  2.01e-07  9.02e-07
  -5.22e-07  1.08e-06 -1.59e-06 -9.52e-07  1.14e-07  2.45e-06  1.23e-06 -8.92e-07]]
SymNet parameters
[-5.36e-08  8.40e-08]
SymNet parameters
[[ 4.57e-04 -9.78e-04 -3.25e-04  5.44e-06 -2.66e-04 -3.86e-04  8.56e-04  4.59e-04
   2.71e-03  5.17e-02 -9.43e-05  4.80e-02  4.05e-05  1.11e+00  3.21e-04  1.22e+00
  -1.84e-06]]
SymNet parameters
[-0.]
finally, finish this stage
iter:  1017    time: 18.09
Func: 4.41e+00  |g|: 9.42e-02
stableloss: 6.97e-02   dataloss: 3.23e+00   sparseloss: 1.79e+01 momentloss: 8.59e+00
current expression:
[u10*v00, u00*u01, u20, u02, u01*u10*v00, u00*u01**2, u10*v00*v10, u00*u11*v00, u10*v01, v10, u01, u00**2*u01, u00**2*u10*v00, u20*v00**2, u10*v10, v00**2*v10, u01*u10, u00**3, v00, u00*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.01 -0.    0.    0.    0.
 -0.   -0.   -0.   -0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v00*v11, u00*v01*v10, u01*v01, v10, u00*v00, u10*v00, v01*v10, v00, u00*v00*v10**2, u10*v00*v10, v00**2*v20, v00**3, 1, u00*u10, u10*v01]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.01  0.    0.   -0.    0.    0.   -0.
 -0.    0.   -0.   -0.   -0.   -0.  ]
block:  15
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.4234890717458161
current stage is: block-15
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8880, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2567,  1.7018,  1.7188, 24.7099, 11.7304, 16.5741,  0.2574,  1.7119,
         1.7273, 22.3138, 12.0353, 18.3912], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 85.86
Func: 6.95e+00  |g|: 9.55e+01
stableloss: 1.35e-01   dataloss: 5.48e+00   sparseloss: 1.79e+01 momentloss: 8.59e+00
iter:   200    time: 76.33
Func: 6.18e+00  |g|: 9.92e+00
stableloss: 1.27e-01   dataloss: 4.63e+00   sparseloss: 1.89e+01 momentloss: 8.87e+00
iter:   400    time: 81.31
Func: 6.14e+00  |g|: 9.83e-01
stableloss: 1.28e-01   dataloss: 4.58e+00   sparseloss: 1.90e+01 momentloss: 9.08e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 6.137127
         Iterations: 556
         Function evaluations: 677
         Gradient evaluations: 662
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -4.49e-03  6.60e-04 -5.57e-02]
 [ 0.00e+00 -1.87e-03  5.77e-03  2.05e-02  1.04e-02]
 [-1.85e-03  2.09e-02  5.50e-02  2.42e-02 -7.79e-03]
 [ 3.72e-02 -2.72e-02  2.09e-02  7.65e-03  1.55e-02]
 [-4.69e-02  5.44e-02  1.62e-02  3.51e-02 -9.01e-04]]
[[-0.02  0.02 -0.11  0.04  0.  ]
 [ 0.04  0.06  0.17 -0.   -0.04]
 [-0.09  0.07  0.59  0.14  0.01]
 [ 0.02  0.06  0.08  0.04 -0.05]
 [-0.01  0.01 -0.04 -0.01  0.02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.57e-02 -8.93e-02]
 [ 0.00e+00  0.00e+00  1.11e-02 -7.08e-03  5.08e-03]
 [ 0.00e+00  3.52e-02 -8.87e-02  5.33e-02 -7.16e-02]
 [ 5.65e-03 -1.91e-03  8.96e-03 -1.86e-03  6.55e-03]
 [ 6.73e-04 -3.14e-03 -2.50e-02  5.51e-03 -1.97e-02]]
[[-1.60e-02  4.29e-02 -4.87e-02  3.33e-02 -1.37e-02]
 [-3.32e-02  4.53e-02 -3.66e-02  1.84e-02  9.02e-03]
 [ 1.38e-01 -5.82e-01 -3.46e-01  1.00e+00 -2.07e-01]
 [-3.61e-02  5.83e-02 -7.82e-02  4.79e-02 -2.30e-04]
 [-1.07e-02  3.02e-02 -2.66e-02  1.93e-02 -8.76e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00 -3.96e-03 -1.61e-02]
 [ 1.00e+00  0.00e+00  2.98e-02  2.04e-03 -4.71e-03]
 [ 0.00e+00  1.15e-02  1.09e-02 -9.81e-03  7.77e-03]
 [-7.42e-02  3.09e-04  4.76e-02  1.02e-02  1.39e-03]
 [-4.46e-02  2.22e-02  1.13e-02  3.59e-03  6.93e-03]]
[[ 0.01 -0.05  0.13 -0.02  0.  ]
 [-0.01  0.08 -0.63  0.02 -0.02]
 [-0.01  0.   -0.33  0.06  0.02]
 [-0.01  0.02  0.93 -0.   -0.03]
 [ 0.    0.01 -0.2   0.02  0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -7.26e-02]
 [ 0.00e+00  0.00e+00  0.00e+00 -8.28e-04  3.43e-02]
 [ 0.00e+00  0.00e+00  3.18e-01  1.74e-02  2.28e-01]
 [ 0.00e+00  3.97e-03 -5.34e-03 -7.33e-04 -3.81e-04]
 [ 3.42e-04 -5.73e-02  6.37e-02  1.71e-03  3.32e-02]]
[[ 8.70e-03  2.43e-02  4.17e-03 -5.59e-02  1.91e-02]
 [ 1.45e-01 -5.11e-01  4.75e-01 -2.33e-01  1.23e-01]
 [-5.04e-01  2.75e+00 -4.12e+00  2.36e+00 -4.79e-01]
 [ 1.90e-01 -6.77e-01  7.27e-01 -4.10e-01  1.69e-01]
 [ 3.68e-03  3.83e-02 -1.91e-02 -3.54e-02  1.29e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.88e-02]
 [ 0.00e+00  1.00e+00  0.00e+00 -4.28e-05  8.74e-02]
 [ 0.00e+00  0.00e+00 -3.26e-03 -1.36e-01  7.22e-03]
 [ 0.00e+00 -2.64e-02 -6.40e-02  3.64e-01 -3.61e-03]
 [-2.72e-02 -7.00e-04  4.20e-04 -4.73e-02  1.38e-02]]
[[ 0.14 -0.33  0.03  0.24 -0.1 ]
 [-0.35  1.17 -0.36 -0.5   0.14]
 [ 0.1  -0.46  0.61 -0.58  0.16]
 [ 0.25 -0.81  0.06  0.83 -0.23]
 [-0.07  0.15  0.08 -0.27  0.09]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.28e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.23e-03 -2.72e-02]
 [ 1.00e+00  0.00e+00  5.69e-02  8.63e-02  8.55e-03]
 [ 0.00e+00  1.22e-02  2.06e-03 -6.18e-03 -8.59e-03]
 [-2.04e-02 -1.44e-03  6.52e-03  2.51e-02 -8.47e-04]]
[[-0.01  0.02 -0.1  -0.03  0.01]
 [ 0.02 -0.03  1.43 -0.03  0.02]
 [ 0.24 -1.   -1.15 -0.88  0.18]
 [-0.01  0.07  1.33  0.02  0.01]
 [-0.01  0.03 -0.13  0.01  0.  ]]
SymNet parameters
[[ 1.27e-03  1.28e-01  7.94e-02  8.26e-04 -1.70e-02 -4.38e-04  3.25e-01 -4.48e-02
  -3.45e-03  9.17e-04 -8.60e-04 -4.86e-03]
 [ 4.89e-01 -3.37e-03 -8.43e-03  1.64e-03 -2.16e-03 -1.73e-02  7.68e-04 -8.83e-03
  -7.25e-02  1.17e-03  5.44e-04  4.88e-04]]
SymNet parameters
[-1.12e-04 -5.54e-05]
SymNet parameters
[[-4.77e-01  6.47e-04  7.79e-04 -1.57e-03  1.04e-03 -1.12e-02 -5.73e-04  4.32e-03
   6.61e-02 -8.77e-04 -2.19e-03 -2.56e-05  5.76e-03]
 [ 8.62e-02 -6.23e-04  5.85e-02 -2.60e-03 -2.59e-02 -7.17e-04 -3.32e-01  5.66e-02
   7.78e-03  4.76e-04 -2.50e-04  2.64e-03 -3.06e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-5.70e-07  2.62e-07 -1.04e-07 -2.78e-07 -3.32e-07 -1.04e-07  6.82e-07 -6.70e-07
   1.66e-07 -2.54e-07 -2.24e-07 -1.01e-07  3.65e-07 -3.74e-07]
 [ 2.53e-07 -2.31e-07 -1.55e-07  2.49e-07 -2.28e-07 -3.08e-08  2.47e-07 -1.28e-07
   1.27e-07 -2.56e-08 -8.34e-08 -2.67e-07 -4.55e-07  1.49e-07]]
SymNet parameters
[6.75e-07 1.13e-07]
SymNet parameters
[[ 1.93e-04  1.63e-04  7.28e-01 -2.69e-04 -7.95e-04  1.74e-04 -1.13e-03  2.16e-04
  -3.24e-04 -2.37e-04  5.79e-05  5.09e-04  3.10e-01 -3.11e-01 -1.01e-07]
 [ 1.05e-02 -9.49e-03  1.10e-03  1.11e-04 -2.05e-04 -3.35e-04 -1.07e+00  1.36e-03
  -3.45e-03  5.81e-04  8.89e-05  4.06e-04 -1.24e-01 -1.50e-01  2.84e-07]]
SymNet parameters
[ 6.54e-06 -9.64e-04]
SymNet parameters
[[-1.32e-03 -9.27e-01 -6.69e-03  6.71e-06 -7.16e-04  1.85e-04  6.97e-04 -6.58e-04
  -4.49e-05 -1.13e-04  6.25e-05  2.63e-04  5.72e-03  9.86e-02 -2.08e-08 -7.96e-02]
 [-9.38e-01  3.73e-04  5.76e-03 -2.74e-04 -8.55e-05  3.87e-04 -1.07e-03  1.38e-03
  -1.07e-03 -2.86e-04  4.01e-04  1.99e-04  1.58e-01 -1.14e-02 -2.65e-08 -1.17e-02]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 9.04e-04 -3.08e-04 -1.17e-03  5.12e-02 -1.06e-03  4.85e-02  6.14e-05  4.55e-03
   7.19e-04  4.23e-04 -1.04e-03  2.18e-04 -1.39e-04  6.87e-05  3.46e-07  1.27e+00
  -1.13e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[ 5.39e-05  2.08e-03  3.31e-02  1.51e-03  1.64e-03 -1.40e-03  8.48e-02  8.07e-02
  -1.80e-01 -9.10e-04  1.20e-02 -3.17e-02]
 [ 6.41e-04  6.44e-04 -2.81e-02  2.71e-04  3.01e-03  2.84e-03  9.29e-02 -9.30e-02
   1.77e-01  2.16e-04  9.57e-04 -3.16e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-3.80e-04 -2.40e-04 -8.26e-04  4.29e-05 -2.20e-04 -1.09e-04 -2.39e-05 -9.73e-02
   7.72e-01  1.22e-04 -1.63e-04 -2.00e-05  3.36e-01]
 [ 3.56e-03  7.61e-04 -7.26e-04  3.10e-04  7.13e-05 -1.35e-04 -1.13e+00  7.49e-02
  -2.30e-03  4.52e-04 -3.23e-04 -1.18e-04 -2.72e-03]]
SymNet parameters
[-0.01  0.  ]
SymNet parameters
[[-7.51e-03  1.22e-02 -5.19e-03  2.26e-03  7.00e-04  5.72e-05 -5.28e-03 -2.91e-02
   3.00e-01  1.03e-03  4.90e-02 -2.10e-03  4.76e-02 -3.54e-03]
 [-7.19e-03  8.39e-03 -7.50e-03 -5.88e-04 -6.18e-04 -1.07e-03 -3.61e-01 -3.36e-02
   4.23e-04  6.50e-04 -7.98e-04 -1.35e-03 -3.72e-02 -5.95e-03]]
SymNet parameters
[1.04e-04 6.14e-05]
SymNet parameters
[[-3.58e-04 -1.31e-03 -1.99e-03 -2.17e-04 -1.53e-04  2.81e-04  6.53e-04 -7.84e-01
  -7.86e-04  3.90e-04  7.97e-04 -1.76e-04  1.82e-04  5.24e-02 -4.23e-01]
 [ 9.87e-01 -3.49e-03  3.00e-03 -8.54e-04 -9.39e-05 -2.87e-04  1.25e-01 -8.98e-03
   6.49e-02 -1.48e-04  1.27e-04  1.54e-04 -5.88e-03  2.04e-02 -4.27e-02]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-3.26e-07 -5.44e-07  1.57e-07 -4.63e-07  3.93e-07 -1.33e-06  8.39e-07 -1.32e-06
   1.16e-07 -4.18e-07  9.37e-08  2.42e-07 -9.85e-07 -3.84e-07 -6.73e-07  4.37e-07]
 [ 8.60e-07 -1.48e-07  1.40e-07 -1.61e-07 -1.59e-07 -7.97e-07 -3.22e-07 -6.54e-07
   1.17e-07 -6.35e-07 -3.82e-07  9.11e-07  3.96e-07  3.69e-07  9.41e-07 -1.95e-07]]
SymNet parameters
[-7.21e-08  4.44e-07]
SymNet parameters
[[ 5.53e-04 -8.87e-04  2.41e-03  1.97e-05  3.62e-04 -1.91e-04  6.66e-04 -8.14e-04
   9.16e-04  5.17e-02 -8.12e-04  4.86e-02 -2.26e-04  1.13e+00  3.95e-04  1.26e+00
   2.54e-08]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   556    time: 91.39
Func: 6.14e+00  |g|: 2.16e-02
stableloss: 1.28e-01   dataloss: 4.58e+00   sparseloss: 1.90e+01 momentloss: 9.06e+00
current expression:
[u10*v00, u00*u01, u02, u20, u00*u01**2, u10*v00*v10, u01*u10*v00, u00*u11*v00, u00, u00*u10*v01, v01, u00**3, u20*v00**2, u00**2*u10*v00, u00*u01*v01, u10*v10, u00**2*v01, u01*u10, u00**2*u10, u00*u10*v00]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.01  0.   -0.    0.    0.
 -0.   -0.   -0.   -0.    0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v00*v11, u00*v01*v10, v00, u10*v00*v10, v00**3, u01*v01, u10*v01, u00*u10, u10, u00*u01*v00, u10*v00*v01, v00**2*v20, u00*v10, v10**2, v01]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01 -0.   -0.    0.   -0.   -0.    0.
  0.    0.    0.    0.   -0.   -0.  ]
block:  18
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -1.9319118467234415
current stage is: block-18
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9372, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2574,  1.6438,  1.5859, 22.9460, 11.0025, 17.7306,  0.2534,  1.6293,
         1.5809, 20.3525, 11.6327, 19.2126], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 123.18
Func: 8.96e+00  |g|: 1.16e+02
stableloss: 1.34e-01   dataloss: 7.08e+00   sparseloss: 1.90e+01 momentloss: 9.06e+00
iter:   200    time: 111.17
Func: 8.04e+00  |g|: 1.20e+01
stableloss: 1.36e-01   dataloss: 6.15e+00   sparseloss: 1.91e+01 momentloss: 9.43e+00
iter:   400    time: 102.75
Func: 8.01e+00  |g|: 3.46e+00
stableloss: 1.38e-01   dataloss: 6.05e+00   sparseloss: 1.99e+01 momentloss: 9.62e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 7.932034
         Iterations: 531
         Function evaluations: 625
         Gradient evaluations: 613
convolution moment and kernels
[[ 1.    0.   -0.    0.01 -0.04]
 [ 0.    0.    0.02 -0.01  0.02]
 [-0.    0.02  0.08 -0.01  0.03]
 [-0.06 -0.    0.02 -0.01  0.03]
 [-0.05  0.01  0.03 -0.01  0.02]]
[[ 4.32e-03 -1.69e-04 -4.76e-02  2.54e-02 -2.34e-03]
 [-3.42e-02  1.01e-01  7.31e-02 -2.79e-03  1.74e-03]
 [ 1.77e-02 -5.03e-02  6.86e-01  7.96e-02 -2.96e-02]
 [-5.69e-02  1.66e-01  1.09e-01  5.39e-02 -1.38e-02]
 [ 3.00e-02 -7.13e-02 -2.54e-02 -2.62e-02  1.25e-02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.13e-02 -8.83e-02]
 [ 0.00e+00  0.00e+00 -9.66e-04 -9.61e-03  1.54e-02]
 [ 0.00e+00  2.36e-02 -9.16e-02  4.85e-02 -7.98e-02]
 [ 1.10e-02 -5.44e-03  1.22e-02  1.16e-02  2.60e-02]
 [ 1.29e-03 -2.10e-02 -2.34e-02 -2.44e-03 -2.00e-02]]
[[-0.02  0.07 -0.1   0.07 -0.03]
 [-0.05  0.04 -0.02  0.    0.03]
 [ 0.17 -0.62 -0.27  0.92 -0.2 ]
 [-0.06  0.09 -0.17  0.14 -0.02]
 [-0.    0.01  0.02 -0.02  0.  ]]
[[ 0.    0.    0.    0.   -0.  ]
 [ 1.    0.    0.03 -0.   -0.01]
 [ 0.    0.01 -0.01 -0.03  0.02]
 [-0.08 -0.01  0.04 -0.    0.01]
 [-0.05  0.02 -0.01 -0.02  0.01]]
[[ 0.01 -0.07  0.15 -0.01 -0.  ]
 [-0.02  0.12 -0.64 -0.02  0.02]
 [ 0.02 -0.13 -0.19  0.01 -0.01]
 [-0.04  0.15  0.79  0.05 -0.01]
 [ 0.02 -0.06 -0.12 -0.02  0.  ]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.64e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  3.12e-03 -7.28e-02]
 [ 0.00e+00  0.00e+00  5.65e-02  6.19e-03  2.07e-01]
 [ 0.00e+00  5.02e-04 -9.87e-03 -6.77e-03  1.29e-01]
 [ 7.57e-02  1.35e-02 -1.44e-03 -1.15e-02  3.23e-02]]
[[-5.01e-02  2.03e-01 -2.54e-01  2.37e-01 -6.06e-02]
 [ 2.91e-01 -1.12e+00  1.46e+00 -1.28e+00  3.45e-01]
 [-5.10e-01  2.95e+00 -4.60e+00  3.22e+00 -6.07e-01]
 [-7.45e-02  3.44e-01 -7.15e-01  1.45e-01 -2.38e-03]
 [ 9.54e-02 -3.82e-01  6.17e-01 -3.32e-01  7.75e-02]]
[[ 0.    0.    0.    0.    0.1 ]
 [ 0.    1.    0.   -0.01 -0.03]
 [ 0.    0.   -0.01 -0.1   0.03]
 [ 0.   -0.01 -0.01  0.37 -0.02]
 [-0.04  0.08 -0.02  0.07 -0.  ]]
[[ 0.07 -0.24  0.01  0.2  -0.06]
 [-0.01  0.49  0.34 -0.78  0.12]
 [-0.27  0.16  0.09 -0.51  0.31]
 [ 0.46 -1.1   0.24  0.93 -0.38]
 [-0.14  0.28 -0.05 -0.25  0.12]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.74e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -6.65e-04  3.06e-02]
 [ 1.00e+00  0.00e+00  3.78e-01  1.32e-01  5.94e-03]
 [ 0.00e+00  1.56e-03  7.46e-03  3.17e-03 -1.92e-01]
 [-7.30e-02 -6.68e-02  1.45e-01  6.87e-02 -2.94e-03]]
[[ 0.05 -0.13  0.14 -0.33  0.12]
 [-0.12  0.4   0.64  0.95 -0.26]
 [ 0.17 -0.71 -1.31 -1.41  0.32]
 [ 0.31 -1.32  3.23 -0.76  0.17]
 [-0.15  0.67 -1.06  0.46 -0.08]]
SymNet parameters
[[ 3.95e-02  1.31e-01  4.28e-02 -2.58e-03 -2.99e-02  3.26e-03  3.53e-01 -4.01e-02
  -1.21e-03  2.78e-04  1.61e-04 -2.24e-03]
 [ 5.19e-01 -1.75e-02 -2.73e-03 -1.51e-03  7.75e-04 -1.98e-02 -1.57e-03 -1.22e-03
  -7.19e-02  8.24e-04  2.36e-03 -9.92e-04]]
SymNet parameters
[2.82e-05 6.42e-05]
SymNet parameters
[[-5.04e-01  9.31e-03  4.89e-04 -1.22e-03 -6.48e-04 -6.74e-03 -8.68e-04  6.35e-04
   7.43e-02  5.93e-04 -1.19e-03  1.36e-05  1.12e-02]
 [ 5.08e-02  5.05e-04  5.45e-03 -2.17e-03 -1.09e-02  5.18e-04 -4.45e-01  5.85e-02
   4.66e-03 -4.07e-04  5.00e-04  2.25e-03 -4.40e-02]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-3.61e-06  4.25e-06 -2.74e-06  8.09e-06  1.51e-05  9.90e-07 -2.41e-05 -1.89e-05
  -1.24e-05  4.95e-06  7.59e-06  3.94e-06 -1.28e-05 -3.46e-06]
 [-1.15e-05  1.60e-05  1.00e-05 -1.17e-05  9.33e-06  5.73e-06 -3.31e-06  1.30e-05
  -2.91e-05  6.14e-06 -6.84e-06  1.95e-06 -1.04e-05  1.62e-05]]
SymNet parameters
[ 7.49e-06 -4.15e-05]
SymNet parameters
[[ 1.40e-02  8.32e-04  7.65e-01  1.89e-04 -1.09e-03 -5.51e-04 -5.48e-05  4.48e-04
   1.98e-04  2.09e-04  1.64e-05 -1.02e-04  3.18e-01 -2.57e-01  9.42e-06]
 [ 1.73e-03 -7.85e-03  7.91e-04 -1.07e-05  1.14e-04 -1.49e-05 -1.03e+00  7.61e-06
   3.17e-03  2.01e-04  3.90e-04 -5.83e-05 -7.32e-02 -2.50e-01  7.91e-06]]
SymNet parameters
[-9.71e-05 -3.31e-03]
SymNet parameters
[[-1.77e-03 -8.96e-01  4.24e-04  3.21e-04  8.06e-05  5.13e-04  1.44e-02 -1.43e-03
  -6.97e-04 -1.58e-04  1.21e-04 -6.35e-04 -3.41e-02  9.94e-02 -8.59e-06 -8.92e-02]
 [-9.64e-01 -8.36e-04  1.16e-02 -7.00e-04  7.91e-04  2.89e-04  2.88e-04  1.21e-03
  -1.77e-03 -2.02e-04  1.30e-04  2.58e-04  1.45e-01  1.01e-03  9.63e-06 -9.85e-03]]
SymNet parameters
[0.01 0.  ]
SymNet parameters
[[ 8.35e-04  1.08e-03 -7.74e-04  5.08e-02 -7.21e-04  4.93e-02  8.68e-05  2.19e-03
   3.06e-03  1.02e-04 -3.58e-04  4.33e-04 -4.19e-04  3.73e-04  3.03e-06  1.26e+00
  -1.14e+00]]
SymNet parameters
[0.]
SymNet parameters
[[-4.00e-01 -3.39e-03  2.45e-02  1.52e-04  1.03e-03  2.32e-03 -4.60e-02  4.67e-02
  -8.69e-02 -9.22e-04  5.96e-03 -1.72e-02]
 [ 5.15e-02  1.33e-02 -3.02e-02  2.34e-03  1.63e-03  3.60e-04  1.42e-01 -1.65e-01
   1.75e-01 -4.30e-03  2.22e-02 -2.50e-02]]
SymNet parameters
[ 1.98e-04 -2.30e-05]
SymNet parameters
[[ 4.01e-04 -4.47e-04  3.36e-04  7.10e-07 -8.48e-05  7.83e-05  2.84e-03 -1.84e-01
   6.89e-01  1.31e-04 -9.47e-04  2.30e-04  4.40e-01]
 [ 3.49e-02  1.24e-03 -3.08e-03 -8.13e-05 -1.88e-06  5.68e-05 -1.18e+00 -7.98e-02
   1.01e-03 -1.77e-04 -1.02e-04 -1.27e-03 -5.89e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-4.24e-02  2.11e-02  3.99e-02 -2.47e-03 -1.10e-03  1.91e-03 -1.40e-01  1.24e-01
   2.30e-02  5.26e-03  9.34e-03  1.96e-02  7.45e-02 -7.31e-04]
 [-3.40e-03 -6.10e-02 -9.85e-03  2.74e-03 -5.75e-05  4.79e-04 -3.22e-01 -5.54e-02
  -5.42e-02  1.99e-03  9.86e-03  1.61e-03  5.37e-02  6.06e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 4.45e-05 -7.27e-05 -1.58e-03 -1.77e-05 -1.80e-04 -5.17e-05 -1.69e-03 -7.19e-01
  -2.09e-02 -1.60e-04  9.62e-04  1.37e-04 -1.75e-02  4.36e-02 -5.78e-01]
 [ 9.76e-01 -1.10e-03  6.79e-04 -2.38e-04  6.64e-06 -7.36e-04  2.61e-01  1.68e-02
  -7.04e-02  1.14e-04  7.89e-05  4.27e-04  3.64e-02  1.97e-02  8.43e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-2.16e-05  3.11e-06 -2.64e-07  1.64e-05  4.93e-07 -1.34e-05  1.20e-05 -1.45e-05
   4.76e-06  2.71e-05  2.58e-06 -6.00e-06  2.30e-05 -2.89e-06 -3.93e-05 -1.82e-05]
 [ 5.41e-05 -1.89e-05  7.01e-06 -2.65e-07 -1.16e-06  6.34e-07 -4.61e-05  5.21e-05
   4.34e-05  1.79e-06  2.23e-05 -2.64e-06  2.39e-05 -3.11e-05  6.28e-09 -4.89e-05]]
SymNet parameters
[2.06e-05 1.99e-05]
SymNet parameters
[[-8.92e-04  3.03e-03 -1.30e-05 -5.96e-05  4.28e-05  1.96e-05  8.20e-04 -3.05e-03
  -1.19e-03  5.15e-02 -1.40e-03  4.87e-02  7.79e-06  1.21e+00  5.30e-04  1.38e+00
   1.94e-06]]
SymNet parameters
[0.]
finally, finish this stage
iter:   531    time: 86.91
Func: 7.93e+00  |g|: 7.00e-01
stableloss: 1.40e-01   dataloss: 5.92e+00   sparseloss: 2.04e+01 momentloss: 1.00e+01
current expression:
[u10*v00, u00*u01, u02, u20, u10*v00*v10, u00*u01**2, u01*u10*v00, u00*u10*v01, u00*u11*v00, u00, u01*u10, u00**2*u10*v00, u10, u20*v00**2, u00**2*u10, u00**3, v10, u10*v10, u00*u01*v01, u01]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.01  0.    0.   -0.    0.
  0.   -0.    0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v00*v11, u00*v01*v10, u00*u01*v01, v00**3, v00, v00**2, u10*v00*v10, u10*v00*v01, v01, 1, u01, v10**2, v01*v10, v00**2*v10, u00*v00]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01 -0.01  0.01 -0.   -0.    0.   -0.
  0.    0.    0.    0.    0.   -0.  ]
block:  21
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  0.9937013816894474
current stage is: block-21
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8226, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2648,  1.8580,  1.5759, 34.3285, 13.1937, 17.2629,  0.2806,  1.8673,
         1.8896, 29.3701, 13.3154, 24.0453], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 210.12
Func: 2.04e+01  |g|: 1.01e+03
stableloss: 3.09e-01   dataloss: 1.80e+01   sparseloss: 2.04e+01 momentloss: 1.00e+01
iter:   200    time: 114.54
Func: 1.65e+01  |g|: 8.34e+01
stableloss: 3.25e-01   dataloss: 1.41e+01   sparseloss: 2.07e+01 momentloss: 1.12e+01
iter:   400    time: 119.78
Func: 1.61e+01  |g|: 6.09e+00
stableloss: 3.22e-01   dataloss: 1.37e+01   sparseloss: 2.07e+01 momentloss: 1.36e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 16.113396
         Iterations: 546
         Function evaluations: 650
         Gradient evaluations: 640
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -2.11e-02 -2.43e-02 -5.41e-02]
 [ 0.00e+00  1.57e-04  3.29e-02  1.74e-02  2.67e-02]
 [-8.65e-03 -2.03e-03  4.17e-02 -2.22e-02  2.80e-02]
 [ 3.57e-02  5.74e-03  4.48e-02  1.20e-02  2.71e-02]
 [-6.43e-02  1.39e-02  3.27e-03 -5.50e-03  8.83e-03]]
[[ 0.   -0.02 -0.06  0.01 -0.01]
 [ 0.01  0.07  0.19  0.01  0.01]
 [-0.05  0.08  0.47  0.2  -0.07]
 [-0.01  0.09  0.12  0.02 -0.01]
 [ 0.02 -0.06  0.01 -0.04  0.02]]
[[ 0.    1.    0.   -0.1  -0.09]
 [ 0.    0.    0.01 -0.01  0.02]
 [ 0.    0.02 -0.1   0.04 -0.07]
 [-0.   -0.    0.    0.01  0.01]
 [ 0.   -0.01 -0.05  0.01 -0.03]]
[[-0.02  0.05 -0.04  0.04 -0.02]
 [-0.01  0.03 -0.08  0.02  0.02]
 [ 0.09 -0.49 -0.38  1.04 -0.24]
 [ 0.   -0.02 -0.05  0.03  0.02]
 [-0.02  0.04 -0.02  0.01 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  4.31e-03 -1.42e-03]
 [ 1.00e+00  0.00e+00  1.66e-02 -3.26e-03 -1.72e-02]
 [ 0.00e+00  2.78e-02 -2.11e-02 -5.77e-03 -1.33e-02]
 [-8.92e-02  4.21e-03  4.41e-02  5.77e-03  2.42e-04]
 [-6.21e-02  1.88e-02 -3.55e-03  2.04e-03 -2.39e-04]]
[[ 2.70e-03 -3.74e-02  1.18e-01 -1.70e-02 -3.30e-04]
 [-5.48e-03  6.02e-02 -5.85e-01  3.09e-02 -7.77e-03]
 [ 1.58e-02 -7.72e-02 -2.69e-01 -8.16e-02  3.96e-02]
 [-1.62e-02  5.56e-02  9.51e-01  4.69e-02 -3.29e-02]
 [-4.40e-04  8.76e-03 -2.23e-01  2.22e-02  2.14e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  3.80e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -1.77e-02  2.57e-01]
 [ 0.00e+00  0.00e+00  2.71e-01 -5.42e-01  1.72e-01]
 [ 0.00e+00 -8.60e-04 -6.02e-01  1.60e-04 -2.15e-01]
 [-3.06e-02  9.74e-02  2.57e-01 -1.43e-01  1.02e-01]]
[[ 0.23 -0.32 -0.07  0.01  0.11]
 [-0.42  0.69 -0.1   0.45 -0.5 ]
 [-0.17  1.85 -3.72  1.63  0.23]
 [ 0.26 -0.82  1.52 -1.01  0.16]
 [ 0.02 -0.09 -0.11  0.24 -0.09]]
[[ 0.    0.    0.    0.    0.  ]
 [ 0.    1.    0.   -0.16 -0.02]
 [ 0.    0.   -0.13  0.08 -0.1 ]
 [ 0.    0.    0.01  0.38  0.08]
 [ 0.    0.04  0.02  0.12 -0.  ]]
[[ 0.02 -0.   -0.26  0.34 -0.09]
 [-0.15  0.5   0.34 -0.82  0.11]
 [-0.02 -0.08  0.47 -0.81  0.45]
 [ 0.27 -0.63 -0.75  1.77 -0.68]
 [-0.12  0.19  0.22 -0.5   0.21]]
[[ 0.    0.    0.    0.    0.09]
 [ 0.    0.    0.    0.   -0.26]
 [ 1.    0.    0.32  0.66  0.17]
 [ 0.   -0.02  0.66 -0.02  0.24]
 [ 0.05 -0.07 -0.01  0.22  0.01]]
[[-0.21  0.32 -0.01 -0.11 -0.03]
 [ 0.55 -1.14  2.   -0.74  0.48]
 [-0.08 -0.04 -1.79  0.04 -0.34]
 [-0.2   0.46  0.28  0.82 -0.22]
 [ 0.03  0.04  0.07 -0.37  0.2 ]]
SymNet parameters
[[-0.05  0.13  0.14  0.   -0.02  0.    0.24 -0.03 -0.01 -0.   -0.   -0.  ]
 [ 0.46  0.    0.02  0.    0.01 -0.02  0.04  0.02 -0.06  0.    0.   -0.  ]]
SymNet parameters
[ 7.64e-05 -6.91e-05]
SymNet parameters
[[-0.43 -0.02  0.02 -0.    0.   -0.01 -0.04 -0.02  0.06 -0.   -0.    0.   -0.02]
 [ 0.14 -0.08  0.03 -0.   -0.02 -0.01 -0.3   0.04  0.01 -0.    0.    0.    0.  ]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-8.82e-07  5.63e-06  6.29e-07  2.14e-06 -3.48e-06 -2.04e-06  3.93e-07 -2.15e-06
   3.34e-06  3.40e-06 -5.77e-06  2.15e-05  7.37e-06 -3.56e-06]
 [-4.40e-06 -9.78e-07 -1.43e-06 -1.82e-05 -1.59e-06 -2.86e-06  4.66e-06  5.72e-06
  -2.48e-06  1.02e-05  5.64e-07 -1.50e-06 -1.26e-06 -6.50e-06]]
SymNet parameters
[-4.75e-06  3.03e-06]
SymNet parameters
[[ 2.98e-03 -1.09e-01  7.27e-01 -1.18e-04 -1.37e-04 -3.31e-04 -8.18e-04  7.05e-04
   7.55e-05  2.73e-04 -1.24e-04 -2.24e-05  3.50e-01 -2.97e-01 -6.38e-06]
 [ 1.95e-01 -4.03e-02 -6.38e-03  2.80e-06  7.60e-04 -1.36e-04 -9.60e-01  1.80e-03
  -2.09e-03  2.54e-04 -5.39e-05  8.62e-04 -8.78e-02 -1.64e-01  3.23e-06]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-2.27e-04 -8.17e-01 -1.64e-01 -7.33e-05  8.17e-04  5.61e-05  1.59e-04 -1.56e-03
  -1.59e-03 -3.87e-04 -1.63e-04  4.92e-05 -3.64e-02  1.38e-01  4.71e-06 -7.77e-02]
 [-8.94e-01 -2.77e-03  3.48e-02  1.80e-04 -2.35e-04 -9.46e-05 -1.35e-01  1.16e-03
  -2.05e-03 -2.36e-04  1.40e-04 -2.60e-04  1.41e-01  2.37e-02 -1.26e-05 -1.60e-02]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 9.23e-04 -1.87e-03 -3.20e-04  5.13e-02 -6.49e-04  4.93e-02 -5.00e-04  3.57e-03
   2.08e-03 -1.67e-04 -1.22e-03  5.97e-04  2.06e-04 -2.03e-04  3.20e-06  1.37e+00
  -1.30e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[-5.21e-01  2.63e-03  2.00e-02  1.83e-04  5.97e-04  2.08e-03  4.39e-02  1.02e-02
  -6.24e-02  5.27e-04  2.24e-04 -1.58e-02]
 [-7.29e-03  1.60e-02 -5.81e-03 -4.92e-03  1.32e-03  7.44e-03  1.47e-01 -1.80e-01
   2.62e-01 -2.53e-03  1.30e-02 -3.37e-02]]
SymNet parameters
[-2.45e-05 -4.09e-04]
SymNet parameters
[[ 5.97e-03 -1.95e-03  2.74e-04  6.78e-05 -1.41e-04  1.27e-04 -7.50e-04  3.84e-04
   7.70e-01 -9.82e-05 -1.61e-04 -1.52e-04  4.51e-01]
 [ 2.83e-02  2.05e-03  1.77e-03  2.96e-05 -2.01e-04  5.80e-06 -1.12e+00 -4.75e-02
  -4.54e-03  2.16e-04 -2.49e-04 -2.51e-04 -3.74e-04]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 1.11e-02  1.32e-02 -9.80e-04  5.35e-03 -3.97e-04 -5.41e-03 -1.47e-01  1.73e-01
   1.91e-02  1.14e-03  1.30e-02  3.02e-02  1.38e-01  5.95e-03]
 [ 7.57e-04 -5.73e-02  1.11e-02  1.86e-03 -1.08e-03 -2.29e-03 -4.04e-01 -4.54e-02
  -2.79e-02 -1.92e-04  4.95e-03  1.14e-03 -1.59e-03 -1.34e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-6.55e-04 -1.70e-03 -9.71e-04 -2.42e-04 -3.48e-04 -5.99e-06  8.53e-04 -6.71e-01
  -2.02e-02 -4.63e-07  1.05e-03  9.32e-04 -2.22e-03  6.32e-02 -5.31e-01]
 [ 1.11e+00 -5.76e-04  3.55e-03 -1.12e-03  2.70e-04 -7.03e-04  7.08e-04  1.22e-03
  -5.41e-02  5.69e-04 -8.38e-04 -7.17e-04  4.56e-02  1.23e-02  9.61e-03]]
SymNet parameters
[0.   0.01]
SymNet parameters
[[ 8.26e-05  2.63e-06 -6.06e-05  1.07e-06 -7.22e-06  1.14e-05 -3.33e-06  6.77e-05
   3.68e-05  1.73e-06 -1.15e-05 -4.14e-07  8.29e-05 -2.49e-06  2.74e-05  1.15e-05]
 [-3.88e-05  6.99e-06 -5.30e-06  8.53e-06  2.65e-07  6.62e-08 -2.69e-05  6.83e-05
   2.55e-05  5.96e-07 -3.99e-06 -1.10e-07 -3.71e-05  4.87e-06  4.55e-05 -3.79e-07]]
SymNet parameters
[ 1.51e-05 -2.79e-05]
SymNet parameters
[[ 2.74e-04  1.25e-04  5.08e-04 -5.01e-04 -3.20e-04  7.51e-04  7.49e-04 -2.71e-04
   3.03e-04  5.25e-02  7.54e-04  4.79e-02 -3.73e-02  1.14e+00 -1.81e-02  1.30e+00
   1.32e-06]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   546    time: 130.21
Func: 1.61e+01  |g|: 7.72e-01
stableloss: 3.22e-01   dataloss: 1.37e+01   sparseloss: 2.07e+01 momentloss: 1.36e+01
current expression:
[u10*v00, u00*u01, u02, u20, u00, u00*u01**2, u01*u10*v00, u10*v00*v10, u00*u11*v00, u00**3, v00, u00*u10, u00*v00, u00*u10*v01, u00**2*u10*v00, v01, u01, u01**2, u01*u10, u20*v00**2]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01 -0.01 -0.    0.   -0.    0.
  0.    0.   -0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v01*v10, u00*u01*v01, u00*v00*v11, v01, v00, v01*v10, v00**3, u10*v00*v10, u00*v00, u10*v01, v00**2*v01, u00*u01*v00, u01*v00, u00*v00*v10, v00**2*v20]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01  0.01 -0.01  0.01  0.01 -0.   -0.   -0.
 -0.    0.    0.    0.    0.    0.  ]
block:  24
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  1.2946651415348858
current stage is: block-24
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9398, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2543,  1.7362,  1.6999, 23.4780, 14.3976, 16.7550,  0.2490,  1.6688,
         1.6281, 20.8219, 13.7416, 17.4475], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 192.74
Func: 2.04e+01  |g|: 3.67e+02
stableloss: 2.57e-01   dataloss: 1.76e+01   sparseloss: 2.07e+01 momentloss: 1.36e+01
iter:   200    time: 132.75
Func: 1.77e+01  |g|: 7.76e+01
stableloss: 2.49e-01   dataloss: 1.49e+01   sparseloss: 2.06e+01 momentloss: 1.40e+01
iter:   400    time: 137.03
Func: 1.74e+01  |g|: 5.58e+00
stableloss: 2.41e-01   dataloss: 1.46e+01   sparseloss: 2.10e+01 momentloss: 1.09e+01
iter:   600    time: 157.59
Func: 1.73e+01  |g|: 1.05e+01
stableloss: 2.40e-01   dataloss: 1.44e+01   sparseloss: 2.19e+01 momentloss: 1.11e+01
iter:   800    time: 136.40
Func: 1.71e+01  |g|: 1.18e+01
stableloss: 2.41e-01   dataloss: 1.41e+01   sparseloss: 2.25e+01 momentloss: 1.07e+01
iter:  1000    time: 134.89
Func: 1.70e+01  |g|: 5.42e+00
stableloss: 2.43e-01   dataloss: 1.41e+01   sparseloss: 2.20e+01 momentloss: 1.09e+01
iter:  1200    time: 136.01
Func: 1.70e+01  |g|: 9.22e-01
stableloss: 2.43e-01   dataloss: 1.41e+01   sparseloss: 2.19e+01 momentloss: 1.08e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 16.972237
         Iterations: 1214
         Function evaluations: 1325
         Gradient evaluations: 1312
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.77e-02 -4.85e-03 -5.47e-02]
 [ 0.00e+00 -9.29e-04  9.51e-05  9.58e-05  1.17e-03]
 [-3.18e-03  2.34e-02  8.32e-02  2.12e-02  4.19e-02]
 [-4.25e-02 -4.94e-04 -2.31e-02  5.36e-03 -1.42e-02]
 [-5.09e-02  2.44e-02  2.39e-02  4.01e-04  1.41e-02]]
[[ 0.02 -0.05  0.01 -0.01  0.01]
 [-0.04  0.13  0.08 -0.03  0.01]
 [-0.03  0.05  0.51  0.28 -0.1 ]
 [-0.    0.06  0.23 -0.07  0.03]
 [ 0.   -0.02 -0.07  0.01  0.  ]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.19e-02 -8.39e-02]
 [ 0.00e+00  0.00e+00  1.15e-02  7.81e-04  2.08e-02]
 [ 0.00e+00  1.88e-02 -1.11e-01  4.23e-02 -7.46e-02]
 [ 3.65e-03  4.99e-03 -2.06e-04  7.07e-03  7.19e-03]
 [ 4.43e-03 -1.76e-02 -4.75e-02 -3.64e-03 -2.87e-02]]
[[-0.02  0.05 -0.05  0.04 -0.02]
 [-0.02  0.02 -0.05  0.    0.04]
 [ 0.11 -0.52 -0.37  1.05 -0.25]
 [-0.01 -0.02 -0.02 -0.02  0.04]
 [-0.02  0.04 -0.02  0.02 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00 -4.76e-03 -8.75e-03]
 [ 1.00e+00  0.00e+00  3.44e-02 -6.22e-03 -2.77e-03]
 [ 0.00e+00  6.90e-03  2.07e-02 -1.09e-03  1.34e-02]
 [-7.48e-02 -1.83e-03  5.81e-02 -6.57e-03  9.88e-03]
 [-4.27e-02  1.25e-02  2.02e-02  2.48e-04  1.07e-02]]
[[ 0.   -0.03  0.12 -0.02  0.01]
 [-0.01  0.05 -0.61  0.01 -0.01]
 [ 0.02 -0.04 -0.3   0.04  0.01]
 [-0.03  0.06  0.91  0.   -0.03]
 [ 0.01 -0.01 -0.19  0.01  0.01]]
[[ 0.    0.    1.    0.   -0.08]
 [ 0.    0.    0.    0.01 -0.06]
 [ 0.    0.    0.52  0.18  0.26]
 [ 0.    0.    0.   -0.02  0.02]
 [-0.16 -0.02  0.18  0.07  0.09]]
[[ 0.01  0.06 -0.21 -0.1   0.07]
 [ 0.09 -0.39  1.08 -0.16  0.03]
 [-0.25  1.92 -4.21  1.85 -0.29]
 [-0.06  0.16  0.35  0.27 -0.07]
 [ 0.05 -0.09 -0.02 -0.2   0.09]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.01e-01]
 [ 0.00e+00  1.00e+00  0.00e+00 -9.68e-04 -1.48e-01]
 [ 0.00e+00  0.00e+00 -9.90e-03  1.35e-01 -3.49e-04]
 [ 0.00e+00 -8.26e-03  1.63e-01  6.38e-01  2.64e-02]
 [ 2.64e-02 -7.89e-02  5.85e-03  1.55e-01 -1.97e-02]]
[[ 0.05 -0.1  -0.06  0.26 -0.13]
 [ 0.06 -0.21  0.8  -1.08  0.32]
 [-0.36  1.06 -0.09 -0.76  0.31]
 [ 0.59 -1.82  0.11  1.66 -0.65]
 [-0.25  0.67 -0.16 -0.48  0.24]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.79e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -5.41e-03  2.63e-02]
 [ 1.00e+00  0.00e+00 -5.64e-04 -1.54e-01  2.78e-02]
 [ 0.00e+00 -1.89e-02  2.33e-02  3.87e-02 -1.61e-02]
 [ 1.06e-01 -3.30e-02 -6.25e-03 -5.35e-02 -3.47e-04]]
[[ 0.04 -0.1   0.11 -0.01 -0.02]
 [-0.02  0.02  0.82  0.07  0.02]
 [ 0.06 -0.28 -1.13 -0.67  0.16]
 [ 0.1  -0.42  1.34 -0.15  0.04]
 [-0.01  0.07 -0.07  0.05 -0.02]]
SymNet parameters
[[ 1.10e-02  1.58e-01  6.26e-02  5.44e-03 -2.10e-02 -5.06e-04  3.63e-01 -3.85e-02
   9.72e-04 -3.29e-03 -1.35e-03 -2.55e-03]
 [ 5.23e-01  3.40e-04 -2.20e-02  5.17e-03  3.94e-03 -1.50e-02  1.23e-02  4.87e-03
  -7.08e-02 -2.28e-03  3.06e-04 -5.73e-04]]
SymNet parameters
[-4.09e-05  2.52e-05]
SymNet parameters
[[-4.78e-01  8.52e-03  6.74e-03 -3.13e-03 -4.00e-04 -1.32e-02 -1.03e-02 -7.44e-03
   7.68e-02  1.03e-03 -2.18e-03  5.95e-04  1.61e-02]
 [ 1.01e-01  4.36e-04  1.18e-02 -8.53e-03 -2.18e-02 -6.09e-04 -3.82e-01  4.72e-02
   1.26e-03  1.94e-03  1.39e-03  1.21e-03 -5.43e-02]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-5.67e-07  2.49e-07 -1.33e-06  1.12e-06  3.27e-06 -1.61e-06  2.35e-06  5.85e-06
  -1.65e-06 -2.37e-06  5.11e-06 -2.86e-06 -2.46e-06 -1.17e-06]
 [ 1.63e-06  1.70e-06  1.29e-07 -1.29e-06 -5.47e-07 -8.70e-07  2.87e-06 -6.66e-07
   6.65e-06 -1.15e-06 -2.86e-06  2.63e-06  1.89e-06 -7.08e-06]]
SymNet parameters
[ 2.20e-06 -1.74e-06]
SymNet parameters
[[ 3.55e-02 -2.88e-04  7.89e-01  6.64e-05  2.49e-05  3.88e-04 -2.57e-04  1.61e-04
   2.62e-04 -1.43e-04 -2.42e-05 -1.74e-04  2.99e-01 -3.13e-01  2.62e-06]
 [ 1.02e-01 -5.68e-02 -5.99e-03 -2.54e-04  5.20e-04 -3.98e-04 -9.53e-01  1.28e-03
   1.77e-03 -1.57e-04 -3.78e-05  8.20e-04 -1.17e-01 -1.93e-01 -1.86e-06]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-4.13e-03 -8.55e-01 -9.02e-02  8.23e-04 -1.48e-03 -3.68e-04  3.44e-02  1.40e-04
  -1.45e-03  1.75e-04  3.36e-04 -4.63e-05 -5.32e-03  1.14e-01 -2.08e-06 -8.06e-02]
 [-9.44e-01  6.24e-04  6.06e-02 -8.30e-04  3.95e-04  2.17e-04 -1.54e-03  1.53e-03
  -1.88e-03 -1.07e-05  1.25e-04  4.81e-04  1.57e-01 -9.71e-03  3.45e-07 -1.13e-02]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 7.98e-04 -6.48e-04 -6.90e-04  5.11e-02 -9.50e-04  4.86e-02  1.22e-04  3.76e-03
   3.58e-03  3.19e-04 -2.41e-04  5.81e-05 -8.70e-06  1.01e-02  1.72e-06  1.31e+00
  -1.21e+00]]
SymNet parameters
[0.]
SymNet parameters
[[-3.85e-01 -1.35e-02 -2.59e-03 -1.10e-03  3.18e-03  1.70e-04  5.57e-02  6.70e-03
  -3.61e-02 -2.06e-03 -1.45e-02 -3.28e-02]
 [ 3.67e-01  1.65e-02 -6.63e-03 -1.73e-04  1.11e-03  5.37e-04  6.71e-02 -2.06e-03
   4.31e-02  1.15e-03  1.71e-02 -3.20e-02]]
SymNet parameters
[ 1.5e-04 -8.5e-05]
SymNet parameters
[[ 7.00e-01  2.35e-04 -1.36e-04 -3.54e-04 -7.96e-05 -6.23e-04 -9.25e-04  1.96e-04
   3.01e-01 -2.00e-04 -7.32e-04 -4.01e-04  2.16e-01]
 [-4.47e-04  2.31e-03 -1.80e-03  1.62e-04  2.34e-04 -3.19e-04 -1.16e+00 -3.63e-01
   3.47e-03 -1.24e-03 -2.91e-04  4.50e-04 -3.23e-02]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.68e-02  5.27e-03 -3.59e-03  3.12e-04 -1.66e-03  3.29e-04 -1.45e-01  1.62e-01
  -1.00e-02  9.18e-03  1.14e-04 -4.55e-03 -1.40e-02 -1.79e-02]
 [-1.22e-01 -5.92e-02  8.98e-03  1.22e-04  9.67e-04 -5.45e-04 -1.45e-02  1.11e-03
  -1.11e-01  2.31e-04  4.54e-03 -1.09e-04  4.19e-02  4.73e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-8.16e-04 -1.57e-03  2.83e-04 -1.12e-04 -1.70e-04  1.22e-04  5.30e-01 -2.25e-01
  -1.47e-03  1.08e-03 -4.92e-05 -1.51e-04  4.75e-03  3.81e-02 -3.73e-01]
 [ 1.40e+00 -3.26e-04 -6.22e-04 -2.33e-04 -1.20e-04 -1.12e-03 -1.33e-04 -3.58e-03
  -4.36e-01  8.12e-05 -1.07e-03 -5.44e-04 -2.51e-01 -1.46e-04  2.07e-02]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-2.10e-06  2.01e-06 -1.97e-06 -4.41e-06 -7.94e-07  2.42e-06  5.56e-06  1.06e-08
   1.32e-06  2.41e-06  2.77e-06  2.42e-07 -2.19e-06 -3.06e-06 -1.97e-06  3.45e-06]
 [-7.12e-07  6.10e-07 -8.46e-07 -2.26e-06 -3.80e-07 -1.00e-06  3.48e-07 -3.32e-06
   2.87e-06 -3.32e-06 -8.51e-07 -1.78e-06 -5.59e-07  3.07e-06 -2.74e-07 -2.56e-06]]
SymNet parameters
[ 3.09e-06 -3.33e-06]
SymNet parameters
[[-6.21e-04 -2.21e-04 -3.25e-03  2.85e-04 -2.07e-04 -1.48e-04  2.62e-04  3.12e-03
  -5.43e-03  5.12e-02 -1.05e-03  4.79e-02  5.25e-04  1.64e+00 -3.87e-04  1.80e+00
  -2.90e-06]]
SymNet parameters
[0.]
finally, finish this stage
iter:  1214    time: 40.32
Func: 1.70e+01  |g|: 1.08e+00
stableloss: 2.43e-01   dataloss: 1.41e+01   sparseloss: 2.19e+01 momentloss: 1.08e+01
current expression:
[u10*v00, u00*u01, u02, u20, u00*u01**2, u10*v00*v10, u01*u10*v00, u00*u11*v00, u00, u00*u10*v01, u01*u10, u20*v00**2, u00**3, v01, v10, u00**2*u10*v00, u00*v00, u00*u10*v00, u10, u00*u01*v01]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.01  0.    0.   -0.    0.
  0.    0.   -0.   -0.   -0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v01*v10, u00*v00*v11, v10, v00, v01, u00, u01*v00*v10, u10, v00*v01, v10**2, u00*v00, u00**2*v00, u01*v01*v10, u00**2]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01 -0.01  0.    0.   -0.    0.   -0.
 -0.    0.   -0.   -0.   -0.   -0.  ]
block:  27
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.5668696628886468
current stage is: block-27
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9503, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2702,  1.8352,  1.6927, 26.2343, 17.0023, 16.4780,  0.2506,  1.6507,
         1.5943, 20.9999, 14.3190, 16.6646], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 197.16
Func: 2.63e+01  |g|: 1.01e+03
stableloss: 1.75e-01   dataloss: 2.31e+01   sparseloss: 2.19e+01 momentloss: 1.08e+01
iter:   200    time: 158.98
Func: 2.10e+01  |g|: 1.19e+02
stableloss: 1.95e-01   dataloss: 1.78e+01   sparseloss: 2.15e+01 momentloss: 1.00e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 20.840890
         Iterations: 369
         Function evaluations: 435
         Gradient evaluations: 423
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -2.48e-02 -3.48e-02 -4.23e-02]
 [ 0.00e+00  8.01e-03  1.25e-02 -2.58e-03  6.99e-03]
 [ 3.17e-03  1.75e-02  4.85e-02 -6.51e-03  5.00e-03]
 [ 2.09e-02  4.12e-03  3.97e-02 -4.19e-03  2.05e-02]
 [-4.15e-02  4.75e-03  4.91e-03 -1.05e-02 -4.23e-04]]
[[-0.    0.01 -0.07  0.03 -0.01]
 [ 0.    0.03  0.15 -0.02  0.03]
 [-0.01  0.    0.69  0.15 -0.09]
 [-0.03  0.08  0.07  0.02  0.01]
 [ 0.01 -0.02 -0.03  0.01  0.  ]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.61e-02 -8.55e-02]
 [ 0.00e+00  0.00e+00  4.63e-03 -5.04e-03  6.22e-03]
 [ 0.00e+00  2.15e-02 -9.48e-02  4.23e-02 -7.73e-02]
 [ 9.80e-04  5.07e-03  2.41e-03  8.79e-03  5.64e-04]
 [ 1.12e-03 -1.43e-02 -3.70e-02  1.32e-03 -2.66e-02]]
[[-0.02  0.05 -0.04  0.03 -0.02]
 [-0.03  0.03 -0.06  0.03  0.02]
 [ 0.12 -0.54 -0.34  1.   -0.22]
 [-0.01 -0.01 -0.02  0.02  0.02]
 [-0.02  0.06 -0.05  0.03 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  3.19e-03 -2.06e-03]
 [ 1.00e+00  0.00e+00  1.70e-02  2.99e-03 -2.02e-02]
 [ 0.00e+00 -6.94e-03  2.69e-02 -1.71e-02  2.50e-02]
 [-7.93e-02  7.87e-03  3.76e-02 -2.24e-03 -5.71e-03]
 [-4.72e-02  2.21e-04  6.63e-03 -1.58e-02  9.64e-03]]
[[ 1.61e-02 -6.31e-02  1.61e-01 -4.13e-02  3.55e-03]
 [-1.87e-02  7.49e-02 -6.31e-01 -6.97e-04  1.80e-02]
 [ 2.16e-02 -7.10e-02 -2.55e-01  5.21e-02 -3.06e-02]
 [-3.54e-02  8.61e-02  8.99e-01 -2.75e-02  1.23e-02]
 [ 1.28e-02 -1.55e-02 -1.86e-01  2.24e-02 -3.71e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -2.35e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -8.90e-03 -8.10e-04]
 [ 0.00e+00  0.00e+00  1.94e-01 -1.98e-01  2.54e-01]
 [ 0.00e+00 -6.17e-03  7.26e-03 -8.69e-04  1.61e-02]
 [-1.21e-01  2.62e-01  1.63e-01  4.39e-03  1.02e-01]]
[[ 7.23e-02 -2.55e-01 -4.46e-02  5.76e-02  4.87e-02]
 [ 3.13e-02  1.17e-01  1.14e+00 -7.37e-01 -6.95e-02]
 [-5.14e-01  2.50e+00 -6.02e+00  3.56e+00 -2.55e-01]
 [ 5.34e-03  2.12e-01  9.79e-01 -6.05e-01 -1.08e-01]
 [ 8.71e-02 -3.06e-01  3.46e-02 -2.34e-03  6.52e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.60e-02]
 [ 0.00e+00  1.00e+00  0.00e+00 -6.54e-03  1.04e-02]
 [ 0.00e+00  0.00e+00 -4.24e-04 -6.66e-03 -9.00e-03]
 [ 0.00e+00  3.52e-03  5.07e-04  4.36e-01  2.15e-03]
 [ 5.87e-02 -2.19e-02  3.85e-02 -4.95e-03  8.60e-03]]
[[ 0.12 -0.25  0.02  0.28 -0.11]
 [-0.31  0.83 -0.16 -0.84  0.24]
 [ 0.08 -0.02  0.37 -0.17  0.09]
 [ 0.25 -0.97 -0.1   0.89 -0.31]
 [-0.11  0.3   0.02 -0.27  0.12]]
[[ 0.    0.    0.    0.    0.32]
 [ 0.    0.    0.   -0.   -0.01]
 [ 1.    0.    0.22  0.16 -0.  ]
 [ 0.   -0.01  0.05 -0.04  0.01]
 [ 0.09 -0.27  0.    0.01 -0.03]]
[[-0.06  0.28 -0.11 -0.1  -0.  ]
 [ 0.12 -0.64  0.95  0.47  0.09]
 [ 0.24 -0.6   0.24 -2.01  0.14]
 [ 0.05 -0.57  0.98  0.42  0.1 ]
 [-0.03  0.26 -0.16 -0.05 -0.01]]
SymNet parameters
[[ 3.06e-02  1.51e-01  3.37e-02 -1.91e-03 -2.52e-02  2.57e-03  3.96e-01 -3.31e-02
  -9.65e-03 -4.92e-04 -5.02e-04 -4.31e-03]
 [ 5.44e-01 -3.10e-03 -1.34e-02 -2.29e-04  4.03e-04 -1.52e-02  2.41e-02 -6.42e-03
  -7.18e-02  3.63e-05 -4.71e-04 -2.87e-03]]
SymNet parameters
[3.00e-06 4.07e-05]
SymNet parameters
[[-5.03e-01 -1.49e-03 -1.19e-04 -1.67e-03  4.41e-04 -9.41e-03 -2.36e-02  2.93e-04
   8.02e-02 -1.55e-04 -1.57e-03  2.42e-03  2.82e-02]
 [ 5.23e-02  2.55e-02  3.74e-03 -1.19e-03 -1.13e-02 -7.89e-05 -4.13e-01  4.78e-02
   6.19e-03 -3.44e-04 -1.23e-04  8.49e-04 -4.14e-02]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-7.05e-05  1.76e-04 -8.79e-05  2.83e-04  1.77e-05 -5.51e-05  3.47e-05  7.34e-05
  -7.15e-06 -2.28e-04 -2.36e-04 -1.43e-04 -2.91e-05 -2.75e-05]
 [ 2.88e-05 -4.18e-05  5.24e-05  9.99e-05 -1.16e-04  1.67e-04  8.19e-05  5.55e-05
  -1.83e-05 -9.38e-05 -2.53e-07 -2.87e-04  4.52e-06 -1.07e-04]]
SymNet parameters
[ 3.18e-05 -2.44e-05]
SymNet parameters
[[ 3.95e-02  8.13e-04  7.68e-01 -4.76e-04  1.74e-03  2.97e-04 -3.93e-04  2.44e-03
   5.83e-05  4.40e-05 -2.06e-04 -3.94e-04  3.02e-01 -3.23e-01 -3.05e-04]
 [ 4.11e-02 -1.24e-02  1.46e-04 -6.96e-05  3.00e-04  2.99e-04 -9.86e-01  7.22e-04
  -6.10e-04  3.64e-05 -2.18e-04  6.09e-04 -8.23e-02 -2.30e-01 -1.21e-04]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 3.56e-04 -8.61e-01 -3.15e-02 -7.10e-04  1.56e-04  2.12e-04  4.43e-02 -3.27e-03
  -2.43e-03  1.20e-04 -4.75e-05 -7.37e-05 -3.32e-02  1.11e-01  6.49e-05 -8.88e-02]
 [-9.72e-01  2.67e-03  1.15e-02 -1.11e-03 -1.35e-04  1.07e-03 -4.39e-04 -2.16e-03
  -2.40e-03 -7.69e-05  7.60e-05 -1.48e-04  1.50e-01  1.81e-02  1.01e-04 -1.35e-02]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 3.12e-04  6.99e-04  6.11e-04  5.04e-02 -1.69e-03  4.95e-02 -2.43e-04  1.45e-03
   4.55e-03 -3.57e-04 -7.15e-04  3.17e-05 -1.69e-04 -2.01e-04 -4.02e-05  1.30e+00
  -1.17e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[-0.34 -0.01 -0.    0.    0.    0.    0.06 -0.01 -0.06 -0.01 -0.02 -0.03]
 [ 0.31  0.03 -0.    0.    0.   -0.    0.09 -0.02  0.06 -0.01  0.02 -0.03]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 6.23e-01  1.33e-04 -6.65e-04 -8.83e-05 -2.31e-04 -3.09e-04  1.89e-03 -1.08e-03
   3.62e-01  1.48e-05  2.62e-05  1.77e-04  2.75e-01]
 [-5.04e-03 -1.48e-03 -1.28e-03  2.33e-04  2.35e-04  7.89e-05 -1.14e+00 -3.62e-01
  -1.41e-03 -8.62e-04  1.11e-04 -5.22e-04  1.66e-04]]
SymNet parameters
[-3.31e-04 -6.57e-05]
SymNet parameters
[[ 0.01 -0.   -0.   -0.    0.    0.   -0.12  0.13 -0.    0.    0.   -0.01  0.03 -0.02]
 [-0.06 -0.07 -0.01  0.    0.    0.   -0.01 -0.   -0.13 -0.    0.02  0.    0.03 -0.01]]
SymNet parameters
[ 2.26e-04 -4.37e-05]
SymNet parameters
[[ 9.58e-05  4.53e-04  4.70e-04 -2.58e-05 -2.89e-04  6.91e-05  4.81e-01 -2.80e-01
   1.40e-03 -4.42e-05 -1.30e-04  4.90e-05 -9.81e-04  3.43e-02 -3.19e-01]
 [ 1.30e+00 -3.93e-04 -1.86e-03 -1.48e-04 -1.65e-05 -2.48e-04  5.25e-03  5.48e-04
  -4.19e-01  3.44e-04 -1.71e-03 -3.68e-04 -1.09e-01  5.23e-03 -5.44e-04]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-2.89e-05  3.20e-05 -3.12e-05 -1.51e-04 -8.08e-07  2.08e-05  8.02e-05  2.54e-07
   1.84e-05  1.22e-04  2.13e-05  6.71e-06 -2.84e-05 -4.55e-05 -2.89e-05  4.82e-05]
 [-1.04e-05  1.31e-05 -1.33e-05 -9.45e-05  2.98e-06 -3.23e-05  5.02e-06 -4.85e-05
   4.15e-05  2.68e-05 -4.68e-05 -2.84e-05 -6.62e-06  4.56e-05 -4.15e-06 -3.58e-05]]
SymNet parameters
[ 4.53e-05 -4.80e-05]
SymNet parameters
[[-3.46e-04  1.79e-03 -1.55e-03  2.52e-04  2.10e-04 -4.70e-04 -1.31e-04  9.40e-04
   9.78e-04  5.13e-02  2.39e-04  4.77e-02 -5.36e-02  1.55e+00 -3.93e-04  1.74e+00
  -1.78e-04]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   369    time: 172.65
Func: 2.08e+01  |g|: 1.10e+01
stableloss: 1.96e-01   dataloss: 1.77e+01   sparseloss: 2.12e+01 momentloss: 1.02e+01
current expression:
[u10*v00, u00*u01, u02, u20, u00*u01**2, u10*v00*v10, u01*u10*v00, u00*u11*v00, u00*u10*v01, u00, u00*u10, u00*u10*v00, v10, u00**2*u10*v00, u20*v00**2, v00, 1, u00*v01, u00**3, u00*u01*v01]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.    0.    0.
  0.   -0.   -0.   -0.   -0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v01*v10, u00*v00*v11, u00*u01*v01, u00*v00, u01*v00*v10, u00*v00**2, u00, v00**3, v00**2*v20, u00**3*v00, u00*v00*v10, u01*v01*v10, u00*u01*v00, v10, u01]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01 -0.01  0.    0.   -0.   -0.    0.
  0.   -0.   -0.    0.    0.    0.  ]
block:  30
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.6215787749680719
current stage is: block-30
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8778, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2511,  1.6798,  1.5834, 34.3350, 12.8174, 14.1384,  0.2528,  1.6407,
         1.6108, 28.4601, 11.4790, 15.6819], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 187.08
Func: 3.17e+01  |g|: 1.44e+03
stableloss: 2.27e-01   dataloss: 2.82e+01   sparseloss: 2.12e+01 momentloss: 1.02e+01
iter:   200    time: 179.13
Func: 2.56e+01  |g|: 1.36e+02
stableloss: 2.28e-01   dataloss: 2.20e+01   sparseloss: 2.18e+01 momentloss: 1.09e+01
iter:   400    time: 194.97
Func: 2.54e+01  |g|: 5.14e+00
stableloss: 2.26e-01   dataloss: 2.16e+01   sparseloss: 2.26e+01 momentloss: 1.10e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 25.338176
         Iterations: 577
         Function evaluations: 702
         Gradient evaluations: 691
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -5.35e-02 -1.02e-02 -5.61e-02]
 [ 0.00e+00 -6.31e-04  1.07e-02 -3.65e-02  7.25e-03]
 [ 3.57e-03  5.58e-02  3.52e-02  8.10e-02 -6.90e-04]
 [-8.79e-02 -5.48e-03 -9.49e-05 -1.85e-02  1.55e-02]
 [-4.32e-02  3.95e-02  1.06e-02  3.79e-02  1.88e-03]]
[[-0.02  0.04 -0.05  0.02  0.01]
 [ 0.01  0.01  0.11 -0.03 -0.01]
 [-0.04  0.02  0.67  0.12 -0.04]
 [-0.    0.1   0.12  0.09 -0.04]
 [-0.   -0.02 -0.05 -0.03  0.02]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.31e-02 -8.79e-02]
 [ 0.00e+00  0.00e+00 -2.60e-03  9.83e-03  1.54e-03]
 [ 0.00e+00  2.28e-02 -1.10e-01  3.93e-02 -8.83e-02]
 [ 9.37e-03  8.51e-03 -1.03e-02  6.91e-03 -2.16e-03]
 [ 3.14e-03 -9.59e-03 -4.04e-02 -3.63e-04 -2.93e-02]]
[[-0.02  0.05 -0.06  0.04 -0.02]
 [-0.03  0.03 -0.04  0.02  0.02]
 [ 0.13 -0.57 -0.32  1.   -0.22]
 [-0.02  0.04 -0.07  0.01  0.02]
 [-0.02  0.05 -0.04  0.04 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  2.30e-03 -1.31e-02]
 [ 1.00e+00  0.00e+00  2.45e-02 -1.07e-02 -1.38e-02]
 [ 0.00e+00  7.01e-03  2.35e-02 -1.29e-02  5.44e-03]
 [-7.92e-02  1.21e-03  4.55e-02 -7.92e-03 -1.95e-03]
 [-4.68e-02  1.78e-02  4.01e-03 -8.36e-04  2.81e-03]]
[[ 3.47e-03 -4.14e-02  1.36e-01 -2.59e-02  4.02e-03]
 [ 1.83e-03  7.20e-02 -6.50e-01  2.05e-02 -2.76e-03]
 [-1.43e-02 -3.70e-02 -2.53e-01  2.29e-02  4.65e-04]
 [-8.80e-03  5.54e-02  9.00e-01 -2.58e-03 -1.14e-02]
 [ 3.54e-03  5.51e-03 -2.11e-01  3.50e-02 -2.27e-03]]
[[ 0.    0.    1.    0.   -0.14]
 [ 0.    0.    0.   -0.   -0.01]
 [ 0.    0.    0.68  0.02  0.35]
 [ 0.    0.01  0.   -0.04 -0.  ]
 [-0.17  0.03  0.2  -0.01  0.1 ]]
[[ 5.43e-02 -9.43e-02 -1.01e-01 -8.80e-02  6.11e-02]
 [ 4.56e-02 -6.02e-02  8.29e-01 -2.25e-01  8.30e-02]
 [-4.03e-01  2.16e+00 -4.80e+00  2.56e+00 -5.29e-01]
 [ 2.65e-03  3.70e-02  8.22e-01 -3.10e-01  1.20e-01]
 [ 7.30e-02 -1.29e-01 -1.22e-01 -2.76e-02  3.76e-02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.71e-01]
 [ 0.00e+00  1.00e+00  0.00e+00 -8.11e-02 -4.24e-02]
 [ 0.00e+00  0.00e+00  7.44e-03 -2.06e-01  2.26e-02]
 [ 0.00e+00 -1.58e-01 -2.74e-04  3.99e-01 -2.47e-02]
 [ 1.33e-02  6.16e-02  3.16e-02 -8.67e-02  1.29e-03]]
[[ 0.16 -0.42 -0.02  0.43 -0.15]
 [-0.31  0.97  0.41 -1.51  0.39]
 [ 0.14 -0.51  0.38 -0.01  0.07]
 [ 0.27 -1.01  0.37  0.53 -0.21]
 [-0.09  0.28 -0.12 -0.13  0.06]]
[[ 0.    0.    0.    0.    0.26]
 [ 0.    0.    0.   -0.02  0.01]
 [ 1.    0.   -0.17  0.    0.01]
 [ 0.   -0.04 -0.   -0.    0.01]
 [ 0.13 -0.07  0.01  0.01  0.01]]
[[ 1.70e-04  3.18e-02  4.21e-02 -3.63e-02  1.19e-02]
 [ 4.03e-03 -3.35e-01  1.20e+00 -2.28e-02 -4.15e-02]
 [ 2.37e-01 -3.83e-01 -9.22e-01 -9.62e-01  3.29e-01]
 [ 1.44e-02 -3.78e-01  1.14e+00  8.42e-02 -6.37e-02]
 [ 5.08e-03  2.10e-02  1.05e-01 -1.06e-01  2.51e-02]]
SymNet parameters
[[ 1.68e-02  1.61e-01  7.17e-02 -1.47e-03 -1.57e-02  1.74e-03  3.35e-01 -4.46e-02
   1.37e-03  3.03e-04 -1.44e-04 -5.25e-03]
 [ 4.74e-01 -1.36e-02 -5.89e-02  4.24e-03 -7.77e-03 -1.45e-02 -5.16e-03 -5.08e-03
  -6.47e-02  3.71e-04  2.63e-03  7.99e-04]]
SymNet parameters
[-9.50e-05 -2.93e-05]
SymNet parameters
[[-5.48e-01  1.67e-02  4.71e-02 -2.23e-03  4.34e-03 -1.57e-02 -4.69e-03 -4.93e-04
   7.81e-02 -2.52e-03 -4.38e-03  9.32e-04  1.75e-02]
 [ 1.40e-01  3.04e-03  3.57e-02 -3.81e-03 -2.64e-02 -5.28e-03 -3.83e-01  6.54e-02
   2.49e-02 -1.35e-03 -2.46e-04  2.68e-03 -4.04e-02]]
SymNet parameters
[-1.60e-04  2.25e-05]
SymNet parameters
[[-1.18e-05  1.04e-06 -9.39e-07  2.24e-06  4.06e-06 -2.49e-06 -5.51e-06 -3.30e-09
  -2.59e-06 -1.22e-05 -1.62e-05 -3.09e-06  2.61e-06  1.03e-05]
 [-5.96e-07  3.85e-07  9.91e-06 -8.24e-07 -4.94e-06 -6.57e-06 -7.01e-06 -3.85e-06
  -2.93e-06 -5.88e-06  7.14e-07  6.50e-06  2.79e-06  1.49e-05]]
SymNet parameters
[-2.61e-05 -2.58e-05]
SymNet parameters
[[ 3.04e-01 -3.15e-03  7.23e-01  8.70e-04 -8.50e-04  1.20e-03 -1.77e-03 -5.37e-04
  -4.74e-03  4.93e-04  1.54e-04 -1.31e-04  2.54e-01 -2.30e-01  6.93e-06]
 [ 7.71e-02 -1.05e-01 -7.72e-03 -3.27e-04 -3.56e-05  6.86e-04 -9.73e-01  1.18e-03
   3.92e-03 -5.70e-04  1.60e-06  8.12e-04 -1.62e-01 -1.26e-01  3.61e-06]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-9.15e-03 -8.08e-01 -5.76e-02 -8.28e-04 -5.29e-03 -2.33e-04  2.89e-01  5.06e-03
  -6.17e-04  3.87e-04 -1.32e-05 -6.21e-05  8.53e-03  6.75e-02  2.48e-06 -8.39e-02]
 [-9.28e-01 -3.28e-05  1.05e-01 -1.26e-03 -8.64e-05  1.47e-03 -4.72e-03 -1.06e-03
  -1.79e-03 -1.14e-04 -8.62e-05 -3.35e-05  1.85e-01 -2.04e-02  9.34e-06 -1.02e-02]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 9.26e-04 -4.89e-04  1.65e-04  5.10e-02 -1.26e-03  4.88e-02 -5.96e-05  7.59e-04
   1.72e-03 -5.07e-04 -6.03e-04  6.21e-04  8.78e-06  2.62e-01  7.54e-06  1.34e+00
  -1.25e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[-3.83e-01 -2.13e-02 -8.24e-03 -1.03e-03  2.34e-03  3.83e-04  4.45e-02  1.06e-03
  -8.20e-02 -2.40e-03 -1.54e-02 -3.51e-02]
 [ 3.32e-01  1.62e-02 -3.20e-03  2.48e-03  1.77e-03 -1.81e-03  8.96e-02 -1.39e-02
   7.14e-02 -5.58e-04  1.65e-02 -3.05e-02]]
SymNet parameters
[ 9.46e-05 -4.39e-06]
SymNet parameters
[[ 7.41e-01  5.97e-04 -3.90e-04  4.15e-04 -1.61e-04 -2.34e-04  4.25e-02 -2.53e-02
   4.32e-01  1.87e-04 -1.37e-03 -7.62e-05  2.87e-01]
 [-2.41e-03  3.28e-03  1.07e-03  3.84e-04  7.93e-05 -2.43e-04 -1.13e+00 -3.09e-01
   1.18e-02 -1.27e-03  1.59e-03  2.28e-05 -3.35e-02]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-0.02  0.    0.01  0.   -0.   -0.   -0.14  0.16 -0.03  0.01 -0.01 -0.01  0.02 -0.01]
 [-0.1  -0.09 -0.02 -0.   -0.    0.    0.    0.01 -0.13  0.    0.01  0.    0.03 -0.  ]]
SymNet parameters
[8.03e-06 1.32e-04]
SymNet parameters
[[ 6.44e-03 -1.68e-03 -9.01e-04  1.81e-04 -2.00e-04 -2.04e-06  6.03e-01 -3.49e-01
   2.33e-04  5.65e-04 -1.37e-03 -1.63e-04  6.52e-03  4.10e-02 -3.52e-01]
 [ 1.15e+00  6.27e-04  7.37e-04  1.59e-04 -6.85e-04 -4.60e-04  6.63e-02  1.72e-02
  -3.15e-01  4.74e-04 -3.51e-04  4.83e-05 -1.27e-01  1.74e-03 -5.60e-02]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-3.68e-06  1.90e-06 -2.16e-06 -6.48e-07 -5.57e-07  3.70e-07 -9.69e-06 -3.17e-06
  -4.40e-06 -5.82e-06 -6.01e-07 -1.18e-05  1.56e-05 -5.32e-06 -9.57e-06 -9.06e-06]
 [-2.68e-06  4.11e-06  2.67e-06  1.30e-05 -5.56e-06  2.14e-06  3.03e-06 -7.02e-06
   9.04e-07  3.38e-07  1.41e-06 -6.47e-06  2.01e-06  3.82e-06  5.01e-06 -2.15e-06]]
SymNet parameters
[ 1.14e-05 -2.21e-06]
SymNet parameters
[[-7.13e-04  2.51e-03 -8.54e-04 -6.39e-04  2.37e-05 -4.59e-04  2.71e-04  7.92e-04
  -3.64e-03  5.24e-02  9.64e-05  4.73e-02  8.05e-02  1.38e+00 -6.27e-05  1.66e+00
   1.61e-05]]
SymNet parameters
[0.]
finally, finish this stage
iter:   577    time: 247.38
Func: 2.53e+01  |g|: 2.16e+00
stableloss: 2.25e-01   dataloss: 2.16e+01   sparseloss: 2.26e+01 momentloss: 1.08e+01
current expression:
[u10*v00, u00*u01, u02, u20, u00*u01**2, u10*v00*v10, u01*u10*v00, u00*u11*v00, u00*u10*v01, u00*v00, u00, u10*v10, u01*u10, v00**2, u20*v00**2, u00*u01*v01, u00**2*u10, u00*v01, u00**2*u10*v00, 1]
[-0.98 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01 -0.01  0.01  0.    0.    0.
  0.   -0.    0.   -0.    0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*v00, u00*u01*v01, u00*v01*v10, u00*v00*v11, u00, v10**2, v00, u01*v00*v10, u00*v10, v10, v00**2*v20, u01*v10, v00**3, u01, u01*v01*v10]
[-0.99 -0.98  0.05  0.05  0.02 -0.01  0.01  0.01  0.01 -0.01  0.01  0.01  0.    0.
 -0.    0.    0.   -0.    0.   -0.  ]
block:  35
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  1.3087874669323571
current stage is: block-35
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8436, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2601,  1.7389,  1.6345, 26.9017, 16.0862, 16.3970,  0.2516,  1.6093,
         1.6629, 21.3923, 15.0293, 18.2552], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 219.28
Func: 6.27e+01  |g|: 2.93e+03
stableloss: 3.64e-01   dataloss: 5.84e+01   sparseloss: 2.26e+01 momentloss: 1.08e+01
iter:   200    time: 219.31
Func: 4.84e+01  |g|: 5.26e+02
stableloss: 3.69e-01   dataloss: 4.39e+01   sparseloss: 2.31e+01 momentloss: 1.10e+01
iter:   400    time: 220.32
Func: 4.68e+01  |g|: 4.17e+01
stableloss: 3.55e-01   dataloss: 4.23e+01   sparseloss: 2.35e+01 momentloss: 1.17e+01
iter:   600    time: 236.69
Func: 4.65e+01  |g|: 2.05e+01
stableloss: 3.60e-01   dataloss: 4.19e+01   sparseloss: 2.39e+01 momentloss: 1.16e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 46.387709
         Iterations: 777
         Function evaluations: 876
         Gradient evaluations: 863
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -8.74e-02 -3.45e-02 -8.51e-02]
 [ 0.00e+00 -5.96e-03 -6.35e-02  1.25e-02 -4.07e-02]
 [-1.55e-02 -4.09e-03  1.03e-01 -2.43e-04  4.85e-02]
 [ 2.71e-02 -5.68e-03 -4.62e-02 -1.27e-02 -2.94e-02]
 [-4.01e-02  7.05e-03  5.59e-02  8.97e-03  2.90e-02]]
[[ 0.02 -0.05  0.   -0.07  0.04]
 [-0.02  0.06  0.07  0.13 -0.07]
 [-0.04  0.1   0.63  0.13 -0.03]
 [-0.04  0.09  0.02  0.08 -0.05]
 [ 0.01 -0.02 -0.02 -0.01  0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.15e-02 -8.07e-02]
 [ 0.00e+00  0.00e+00 -9.82e-06 -1.01e-02  2.20e-03]
 [ 0.00e+00  1.75e-02 -1.23e-01  3.65e-02 -7.94e-02]
 [ 2.31e-04 -6.80e-03 -1.14e-02 -2.09e-03 -1.08e-02]
 [-7.69e-04 -2.66e-02 -5.97e-02 -1.06e-02 -3.38e-02]]
[[-0.01  0.03 -0.02  0.02 -0.02]
 [-0.03  0.03 -0.05  0.    0.05]
 [ 0.11 -0.51 -0.38  1.05 -0.27]
 [ 0.   -0.06  0.04 -0.05  0.07]
 [-0.02  0.06 -0.06  0.05 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00 -4.05e-03 -5.15e-03]
 [ 1.00e+00  0.00e+00  2.36e-02 -1.00e-03 -1.07e-02]
 [ 0.00e+00 -1.12e-02 -1.58e-02  2.06e-02 -1.25e-02]
 [-7.10e-02 -6.67e-03  3.10e-02 -2.90e-03 -9.76e-03]
 [-4.17e-02 -3.99e-03  5.78e-03  1.08e-02  9.43e-04]]
[[ 1.30e-03 -2.21e-02  1.29e-01 -4.27e-02  1.17e-02]
 [-1.21e-02  3.91e-02 -6.36e-01  6.76e-02 -2.91e-02]
 [ 2.12e-02 -2.11e-02 -2.46e-01 -3.45e-02  2.98e-02]
 [-5.45e-03 -2.67e-02  9.46e-01  1.06e-02 -2.03e-02]
 [-8.11e-03  4.75e-02 -2.24e-01  2.35e-02  6.71e-04]]
[[ 0.    0.    1.    0.    0.16]
 [ 0.    0.    0.    0.   -0.01]
 [ 0.    0.    0.73  0.11  0.31]
 [ 0.   -0.01  0.05  0.    0.06]
 [-0.15  0.05  0.46  0.1   0.19]]
[[ 0.06  0.02 -0.29 -0.07  0.14]
 [-0.1  -0.09  1.    0.08 -0.3 ]
 [ 0.23  0.63 -2.67  0.47  0.46]
 [-0.22  0.27  0.5   0.46 -0.41]
 [ 0.11 -0.14 -0.07 -0.25  0.19]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.03e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -1.06e-01  1.44e-02]
 [ 0.00e+00  0.00e+00  8.16e-03  8.79e-02  1.69e-02]
 [ 0.00e+00  1.32e-02 -8.03e-02  2.58e-01  1.10e-02]
 [-5.99e-03 -9.94e-02 -1.42e-02  7.47e-02  5.53e-03]]
[[ 0.03 -0.02 -0.07  0.09 -0.04]
 [-0.09  0.29  0.07 -0.34  0.1 ]
 [-0.16  0.52  0.17 -0.73  0.16]
 [ 0.33 -1.01 -0.35  1.41 -0.36]
 [-0.1   0.22  0.18 -0.43  0.13]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.95e-02]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.04e-03  8.93e-03]
 [ 1.00e+00  0.00e+00 -9.17e-04 -2.81e-01  1.14e-01]
 [ 0.00e+00  3.15e-02 -1.46e-02  3.56e-03 -2.22e-02]
 [ 7.93e-02 -4.98e-02 -2.03e-01 -1.69e-01 -5.12e-02]]
[[ 0.04 -0.17  0.19  0.04 -0.1 ]
 [ 0.13 -0.1   0.99 -0.4   0.4 ]
 [-0.45  0.99 -3.07  1.21 -0.71]
 [ 0.18 -0.25  1.26 -0.62  0.45]
 [ 0.01 -0.11  0.09  0.13 -0.12]]
SymNet parameters
[[-2.84e-02  1.35e-01  5.74e-02  1.23e-02 -1.42e-02 -2.85e-03  3.94e-01 -4.22e-02
  -3.46e-03  8.66e-04 -5.63e-03 -2.93e-03]
 [ 5.48e-01  3.26e-02 -1.33e-02 -3.14e-03 -2.59e-04 -3.39e-03 -6.66e-04 -3.38e-03
  -8.89e-02 -1.17e-03  7.69e-03  4.32e-04]]
SymNet parameters
[ 5.12e-05 -1.06e-04]
SymNet parameters
[[-5.24e-01 -3.54e-02  1.41e-02  5.10e-03  6.65e-04 -1.45e-02 -1.44e-04  6.71e-04
   8.87e-02  2.39e-04 -7.95e-03 -6.84e-05 -1.48e-03]
 [ 1.03e-01 -2.74e-02  3.07e-02 -1.30e-02 -1.38e-02  2.25e-03 -4.03e-01  4.48e-02
   5.67e-03 -9.44e-04  6.32e-03  2.58e-03 -7.30e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-2.18e-05  5.79e-05  2.07e-05  9.05e-06  3.66e-06 -1.65e-05  1.26e-05 -5.76e-06
  -1.64e-05  2.00e-05 -4.81e-06  2.44e-05  2.26e-05  1.97e-05]
 [-4.00e-05  3.53e-06 -1.53e-05  2.72e-05 -7.24e-06 -2.38e-06 -2.92e-05 -6.57e-05
   3.80e-05  3.90e-05  1.46e-05 -1.54e-05  9.89e-06  1.07e-05]]
SymNet parameters
[-4.30e-05  1.23e-05]
SymNet parameters
[[ 5.98e-04 -7.35e-03  7.00e-01 -4.58e-04 -8.17e-04 -3.38e-05 -8.68e-04  1.89e-03
  -4.32e-04  2.10e-04  2.83e-04  2.63e-04  4.12e-01 -4.21e-01  2.87e-06]
 [ 6.57e-02 -3.85e-02 -1.63e-03 -1.53e-03  8.13e-04  6.13e-04 -1.08e+00 -9.36e-04
  -1.61e-04 -2.07e-03 -5.69e-05  6.10e-04 -8.66e-02 -1.10e-01  2.87e-06]]
SymNet parameters
[5.20e-05 2.97e-04]
SymNet parameters
[[ 9.94e-04 -8.27e-01 -4.56e-02 -2.91e-04  6.52e-04 -2.58e-04 -4.43e-04 -2.58e-03
  -9.52e-04  4.57e-04 -1.89e-04 -1.63e-04 -1.30e-02  1.03e-01 -3.49e-05 -7.20e-02]
 [-9.64e-01  3.86e-03  3.39e-02 -1.05e-03 -1.53e-03 -1.27e-03 -1.20e-02 -3.08e-03
  -2.01e-03  5.92e-05 -1.19e-04 -1.41e-04  1.78e-01 -2.70e-02  2.16e-05 -1.94e-02]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 6.45e-04 -2.87e-03  1.92e-04  4.94e-02 -6.77e-04  4.74e-02  5.35e-06  4.57e-03
   3.07e-03  2.06e-04 -6.37e-05  1.88e-04  2.57e-04  3.09e-04  1.34e-05  1.31e+00
  -1.23e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[-3.14e-01  9.94e-04  1.91e-03 -1.19e-03  3.46e-03 -3.10e-04  6.85e-02  2.24e-02
  -4.56e-03  3.34e-03 -1.43e-02 -2.30e-02]
 [ 5.08e-01 -3.10e-03 -2.95e-03  3.54e-04  6.49e-03  1.62e-03  6.87e-02 -3.90e-03
   1.08e-02  6.63e-03  1.69e-02 -3.75e-02]]
SymNet parameters
[-2.96e-06  1.89e-04]
SymNet parameters
[[ 9.34e-01  3.12e-02 -1.16e-03  4.45e-04 -1.14e-04 -5.73e-04 -2.63e-02  1.45e-02
   4.10e-01 -1.71e-04  4.30e-03 -2.25e-04  1.72e-01]
 [-4.92e-04 -2.79e-03 -1.12e-03  5.61e-04 -7.19e-05 -5.84e-04 -1.12e+00 -4.67e-01
  -2.56e-03 -7.92e-03  2.65e-04  2.86e-03 -2.21e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-7.47e-03  8.65e-03 -2.65e-03 -1.48e-03 -2.32e-03  1.64e-03  2.64e-01  5.82e-01
   2.50e-03  1.69e-02 -1.47e-03 -9.96e-03 -1.01e-03 -3.43e-02]
 [-4.34e-01 -7.77e-02 -3.76e-03  3.18e-04  9.06e-04  1.07e-03 -1.63e-02  3.94e-04
  -2.20e-01 -1.91e-04 -1.15e-02  1.83e-03 -9.00e-02  1.74e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-4.36e-03  8.23e-04  1.23e-03 -1.73e-04  2.44e-04  1.27e-04  8.49e-01 -3.57e-01
  -5.28e-04  2.57e-03  4.54e-04 -2.36e-04 -4.79e-03  9.46e-02 -1.95e-01]
 [ 1.03e+00  2.30e-02 -2.10e-03  4.48e-04  2.91e-04 -1.89e-05 -3.26e-02 -1.53e-02
  -2.99e-01 -1.80e-04  4.04e-03 -5.16e-06 -3.39e-01  9.07e-04 -1.15e-02]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 6.72e-06  8.60e-06 -2.52e-05 -2.34e-06  4.21e-05  4.26e-05 -2.92e-05  9.58e-06
   1.77e-05  1.56e-05 -2.47e-05  3.31e-05 -8.05e-06  3.00e-05 -9.27e-06  1.52e-05]
 [ 3.03e-06 -1.84e-05 -7.66e-06 -6.92e-06 -1.24e-05 -2.11e-05  1.05e-05  3.54e-05
  -2.48e-06  5.39e-05 -9.47e-06  1.07e-05  9.33e-06  8.25e-06 -1.54e-05  2.15e-05]]
SymNet parameters
[ 1.43e-06 -1.13e-05]
SymNet parameters
[[-1.59e-04 -7.66e-04 -1.32e-04  2.23e-04  6.74e-04 -2.00e-04  5.82e-04 -2.68e-04
   6.46e-04  5.15e-02  3.34e-04  4.73e-02 -5.57e-02  1.39e+00 -7.73e-01  1.56e+00
   2.94e-06]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   777    time: 278.07
Func: 4.64e+01  |g|: 7.96e+00
stableloss: 3.59e-01   dataloss: 4.18e+01   sparseloss: 2.38e+01 momentloss: 1.15e+01
current expression:
[u10*v00, u00*u01, u02, u20, u00*u01**2, u10*v00*v10, u01*u10*v00, u00*u11*v00, u00, u01, u00*u10, u00**3, v01, u01**2, u20*v00**2, u00*u10*v01, u00*u01*v01, u00**2*u10*v00, u01*v01, v10]
[-0.99 -0.98  0.05  0.05  0.01  0.01  0.01  0.01  0.01 -0.01  0.01 -0.    0.    0.
  0.    0.   -0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00*v10**2, u00*u01*v01, u00*v01*v10, u00*v00*v11, v00, u10*v01, v00**3, v00**2*v20, v02*v10, u01*v01*v10, u00*v10, u01*v00, v01*v10**2, u00**2*v01*v10, u00*v00, u01*v01]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01  0.    0.   -0.    0.   -0.   -0.
 -0.   -0.   -0.    0.   -0.    0.  ]
block:  40
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.16140571097476075
current stage is: block-40
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7128, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2764,  1.7938,  1.6542, 16.7801, 12.6364, 19.0958,  0.2597,  1.6209,
         1.5463, 14.8837, 11.6849, 18.8648], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward2>)
iter:     0    time: 167.00
Func: 6.57e+01  |g|: 2.21e+03
stableloss: 2.87e-01   dataloss: 6.05e+01   sparseloss: 2.38e+01 momentloss: 1.15e+01
iter:   200    time: 257.53
Func: 5.53e+01  |g|: 5.41e+02
stableloss: 3.09e-01   dataloss: 4.99e+01   sparseloss: 2.42e+01 momentloss: 1.19e+01
iter:   400    time: 262.41
Func: 5.31e+01  |g|: 7.43e+01
stableloss: 2.99e-01   dataloss: 4.78e+01   sparseloss: 2.38e+01 momentloss: 1.20e+01
iter:   600    time: 260.94
Func: 5.20e+01  |g|: 4.09e+01
stableloss: 3.00e-01   dataloss: 4.68e+01   sparseloss: 2.38e+01 momentloss: 1.18e+01
iter:   800    time: 259.33
Func: 5.18e+01  |g|: 4.84e+00
stableloss: 2.99e-01   dataloss: 4.66e+01   sparseloss: 2.37e+01 momentloss: 1.17e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 51.818271
         Iterations: 857
         Function evaluations: 929
         Gradient evaluations: 916
convolution moment and kernels
[[ 1.00e+00  0.00e+00  2.25e-03  4.06e-02 -3.50e-02]
 [ 0.00e+00  2.34e-04  2.87e-02 -1.85e-02  2.98e-02]
 [-7.13e-03 -1.60e-02  8.18e-02  1.93e-02  2.28e-02]
 [ 1.99e-02 -2.32e-02  2.63e-02 -3.77e-02  1.83e-02]
 [-6.75e-02 -1.75e-02  4.53e-02 -6.17e-03  1.30e-02]]
[[-0.    0.03 -0.12  0.01  0.01]
 [-0.03  0.01  0.3  -0.   -0.01]
 [-0.    0.15  0.35  0.15 -0.04]
 [-0.05  0.    0.32 -0.05  0.02]
 [ 0.02 -0.01 -0.07  0.    0.  ]]
[[ 0.00e+00  1.00e+00  0.00e+00 -8.49e-02 -8.19e-02]
 [ 0.00e+00  0.00e+00  1.27e-03 -3.64e-03 -2.40e-05]
 [ 0.00e+00  1.75e-02 -4.21e-02  3.61e-02 -3.12e-02]
 [-2.42e-03  2.50e-03  1.55e-02  7.13e-03  6.23e-03]
 [ 1.05e-02 -1.28e-02 -5.60e-03 -3.11e-04 -5.76e-03]]
[[-3.17e-03  1.53e-02 -1.67e-03  9.02e-03 -7.77e-03]
 [-3.37e-02  3.12e-02 -7.00e-02  1.59e-02  1.24e-02]
 [ 1.17e-01 -5.13e-01 -3.48e-01  1.01e+00 -2.06e-01]
 [-3.46e-02  2.63e-02 -6.68e-02  4.25e-02 -6.82e-03]
 [-1.87e-03  1.68e-02 -4.93e-03 -1.60e-03  8.47e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00  2.75e-03  1.72e-02]
 [ 1.00e+00  0.00e+00  7.40e-03  1.06e-02 -2.22e-02]
 [ 0.00e+00 -7.72e-04 -5.77e-02  1.79e-02 -9.65e-03]
 [-8.89e-02 -2.14e-03  1.08e-02  2.69e-02 -1.99e-02]
 [-6.23e-02 -2.79e-03 -6.07e-02  1.04e-02 -1.60e-02]]
[[-3.26e-04 -5.51e-02  1.75e-01 -4.99e-02 -3.74e-03]
 [ 3.12e-02  4.21e-02 -6.60e-01  4.81e-02  3.22e-02]
 [-4.75e-02 -4.51e-02 -1.52e-01 -1.05e-01 -2.50e-02]
 [ 6.25e-02 -5.67e-02  9.42e-01  3.43e-02  2.32e-02]
 [-3.00e-02  4.89e-02 -2.02e-01  9.64e-04 -7.99e-03]]
[[ 0.    0.    1.    0.    0.53]
 [ 0.    0.    0.    0.02  0.09]
 [ 0.    0.    0.29  0.17  0.07]
 [ 0.    0.08 -0.03 -0.01  0.04]
 [-0.24 -0.06  0.11  0.    0.03]]
[[-0.    0.16 -0.43  0.03  0.01]
 [-0.09 -0.03  0.99  0.04  0.04]
 [ 0.59 -0.89 -0.79 -0.61  0.26]
 [-0.08 -0.    1.15 -0.23  0.12]
 [ 0.03 -0.02 -0.24 -0.03  0.02]]
[[ 0.    0.    0.    0.    0.03]
 [ 0.    1.    0.   -0.09  0.05]
 [ 0.    0.   -0.01  0.01 -0.01]
 [ 0.    0.19  0.05  0.63  0.1 ]
 [ 0.02 -0.    0.   -0.01 -0.01]]
[[ 0.11 -0.13 -0.25  0.51 -0.22]
 [-0.32  0.73  0.41 -1.38  0.5 ]
 [ 0.04 -0.04  0.01  0.12 -0.04]
 [ 0.32 -0.88 -0.13  1.03 -0.39]
 [-0.12  0.19  0.18 -0.42  0.19]]
[[ 0.    0.    0.    0.   -0.54]
 [ 0.    0.    0.   -0.   -0.1 ]
 [ 1.    0.    0.22 -0.15  0.14]
 [ 0.   -0.09  0.    0.03 -0.05]
 [ 0.16  0.07  0.13  0.01  0.06]]
[[ 6.08e-02 -1.81e-01  1.97e-01 -4.85e-02  5.23e-02]
 [ 6.30e-02 -1.40e-01  1.04e+00 -1.92e-01 -9.56e-02]
 [-7.54e-01  2.67e+00 -5.38e+00  2.32e+00 -3.73e-01]
 [ 8.68e-02 -2.42e-01  9.24e-01  7.10e-02 -1.61e-01]
 [ 1.71e-03  6.04e-02 -3.17e-02  1.40e-02  3.60e-02]]
SymNet parameters
[[-0.1   0.12  0.21  0.02 -0.02 -0.    0.04  0.01 -0.    0.   -0.   -0.  ]
 [ 0.51  0.02  0.03 -0.03 -0.    0.01  0.01  0.09 -0.05 -0.01  0.    0.  ]]
SymNet parameters
[-3.80e-05 -1.17e-05]
SymNet parameters
[[-0.37 -0.02 -0.01  0.02 -0.   -0.    0.    0.02  0.07  0.    0.   -0.   -0.01]
 [-0.01 -0.07  0.3  -0.01 -0.05 -0.   -0.01  0.01 -0.02 -0.    0.   -0.    0.15]]
SymNet parameters
[-1.79e-05 -6.11e-05]
SymNet parameters
[[-1.12e-06  1.82e-05  8.41e-07 -2.52e-06 -9.26e-06  2.02e-05  2.10e-05  3.50e-05
   1.73e-05 -1.17e-05  2.72e-06 -4.10e-06 -1.18e-05 -8.92e-06]
 [ 3.44e-05 -8.34e-06 -2.16e-05  1.43e-05 -1.07e-05 -4.58e-06  2.76e-05 -3.30e-05
   1.21e-06 -1.08e-05 -2.82e-05  8.59e-07 -1.05e-05 -2.01e-05]]
SymNet parameters
[1.07e-05 1.02e-05]
SymNet parameters
[[-1.46e-01 -1.25e-03  6.76e-01  5.64e-04 -9.06e-04 -1.50e-03 -8.52e-04  8.36e-04
  -1.48e-03  2.33e-04 -8.34e-05 -9.19e-06  1.32e-01 -2.65e-01  3.04e-05]
 [ 1.22e-01  8.83e-03  3.08e-03 -3.51e-03  1.12e-04  5.07e-04 -1.17e+00  2.55e-03
   3.04e-04  9.48e-05  2.05e-04  1.94e-03 -5.03e-02 -4.03e-02 -7.57e-06]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 1.63e-02 -7.42e-01 -7.68e-02  9.73e-04  8.76e-04  3.29e-04 -1.62e-01  1.22e-03
  -7.95e-04 -1.63e-04  7.59e-06  1.81e-04  9.32e-02  1.11e-01  1.12e-06 -6.01e-02]
 [-1.07e+00 -1.00e-03 -8.79e-03  7.19e-03 -1.25e-04 -1.17e-03  8.17e-04  4.13e-03
  -2.64e-03  6.64e-05  1.98e-04 -4.37e-04  1.64e-01  1.27e-01  1.01e-05 -1.75e-02]]
SymNet parameters
[ 0.01 -0.  ]
SymNet parameters
[[ 3.50e-04 -6.79e-03  1.01e-04  4.46e-02 -9.44e-04  4.99e-02  5.59e-04  1.24e-03
   9.56e-04 -4.17e-04 -2.34e-04 -1.63e-04 -3.89e-02 -6.23e-02  5.17e-06  1.24e+00
  -1.23e+00]]
SymNet parameters
[-0.]
SymNet parameters
[[-4.20e-01 -1.59e-02  5.34e-03 -4.53e-04  7.05e-03  6.67e-04  6.94e-02 -8.26e-04
   1.55e-02 -5.08e-04 -1.29e-02 -1.64e-02]
 [ 4.68e-01  7.68e-03  1.25e-03 -3.17e-03  7.77e-03  2.57e-03  6.92e-02 -3.15e-04
  -9.13e-03 -1.18e-03  1.94e-02 -1.89e-02]]
SymNet parameters
[1.33e-05 1.07e-04]
SymNet parameters
[[ 1.09e+00  4.42e-02 -5.26e-03 -3.19e-03 -7.50e-04  6.35e-04  7.73e-03 -1.43e-04
   3.26e-01 -3.95e-05  3.56e-03 -1.15e-03  1.39e-01]
 [ 4.56e-02  2.80e-04 -1.63e-03 -2.74e-04 -2.43e-04  3.01e-04 -1.09e+00 -4.67e-01
  -5.67e-03 -1.29e-02  9.71e-04  5.02e-03 -2.60e-02]]
SymNet parameters
[ 1.66e-04 -8.18e-05]
SymNet parameters
[[-1.01e-01  8.40e-03  7.19e-04  3.62e-04 -1.01e-03 -1.36e-03  1.51e-04  6.65e-01
   3.50e-04  4.27e-02 -1.16e-03 -1.07e-02 -2.00e-03 -4.95e-02]
 [-5.36e-01 -9.25e-02  5.92e-03  2.09e-03  9.09e-04 -2.22e-03 -6.93e-03 -7.27e-04
  -1.72e-01  4.25e-04 -9.78e-03  2.04e-03 -8.79e-02  8.38e-04]]
SymNet parameters
[1.28e-05 4.63e-04]
SymNet parameters
[[-1.65e-02  1.74e-03  1.13e-03  4.70e-05  2.42e-04  3.71e-05  1.05e+00 -3.05e-01
  -4.62e-03  2.28e-03  3.55e-04 -1.88e-03  4.28e-03  8.16e-02 -1.29e-01]
 [ 1.01e+00  3.83e-02 -3.93e-03 -2.92e-03 -3.69e-04  4.41e-04  6.18e-03  2.61e-03
  -2.69e-01 -6.14e-04  3.95e-03 -5.89e-04 -2.75e-01 -2.47e-03  1.67e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-1.80e-05 -1.71e-05  1.33e-05  3.29e-05 -4.28e-05  1.65e-05  2.97e-05  9.83e-06
  -4.29e-05 -3.13e-06 -5.75e-06 -1.94e-05  2.80e-05 -3.01e-05  1.07e-05 -6.69e-06]
 [-2.11e-06  1.41e-05 -1.72e-05 -1.78e-05  2.51e-05 -3.08e-06 -1.27e-06 -9.60e-07
  -2.95e-05  8.85e-06  9.53e-06  3.03e-05 -1.38e-05 -2.80e-05  5.26e-06 -1.25e-05]]
SymNet parameters
[ 3.96e-05 -8.84e-06]
SymNet parameters
[[ 2.36e-04 -2.68e-04  1.64e-03 -3.17e-04  1.46e-05  4.67e-04  2.52e-05 -4.80e-04
  -9.78e-04  4.76e-02 -1.43e-04  4.80e-02  2.78e-02  1.46e+00 -7.31e-01  1.63e+00
  -2.49e-05]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   857    time: 140.40
Func: 5.18e+01  |g|: 6.26e+00
stableloss: 3.00e-01   dataloss: 4.66e+01   sparseloss: 2.38e+01 momentloss: 1.16e+01
current expression:
[u10*v00, u00*u01, u20, u02, u00, u00*u01**2, u10*v00*v10, u01*u10*v00, u00*u11*v00, u01, u01*u02, u00**3, u00**2*u01, 1, u00*u10*v01, u00*u10, u01*u10*v01, u01*v01, u02*u10*v00, u00**2*u02]
[-0.99 -0.98  0.05  0.04  0.01  0.01  0.01  0.01  0.01 -0.01  0.01 -0.01  0.01 -0.
  0.    0.    0.    0.    0.    0.  ]
[u00*v01, v00*v10, v20, v02, v00*v10**2, u00*u01*v01, u00*v00*v11, u00*v01*v10, u01*v00, u01*v01, v01*v10, u00**2*v02, v00**3, v00, u10*v01, u00*v00, u02*v01, u01*v02, u00**3*v01, u01*v01*v10]
[-0.99 -0.98  0.05  0.05  0.02  0.01  0.01  0.01 -0.   -0.   -0.    0.   -0.    0.
  0.   -0.    0.    0.    0.   -0.  ]
u_obs.abs().max()
tensor(3.9235, device='cuda:0', dtype=torch.float64)
model(u_obs[0],T=50*dt).abs().max()
tensor(3.3638, device='cuda:0', dtype=torch.float64)
model(u_obs[0],T=100*dt).abs().max()
tensor(2.4962, device='cuda:0', dtype=torch.float64)
--name=burgers-frozen-upwind-sparse0.005-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=frozen --device=cuda:0 --stablize=0 --sparsity=0.005 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
0
--name=burgers-frozen-upwind-sparse0-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=frozen --device=cuda:1 --stablize=0 --sparsity=0 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
1
--name=burgers-frozen-central-sparse0.005-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=frozen --device=cuda:2 --stablize=0 --sparsity=0.005 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
2
--name=burgers-frozen-central-sparse0-noise0.001 --kernel_size=5 --viscosity=0.05 --blocks=0-6,9,12,15,18,21,24,27,30,35,40 --dataname=burgers --constraint=frozen --device=cuda:3 --stablize=0 --sparsity=0 --momentsparsity=0.001 --data_start_time=1 --dt=1e-2 --max_dt=1/1600 --hidden_layers=5 --start_noise=0.001 --end_noise=0.001
3
wait
{'--name': 'burgers-frozen-central-sparse0-noise0.001', '--dtype': 'double', '--device': 'cuda:3', '--constraint': 'frozen', '--dt': 0.01, '--cell_num': 1, '--eps': 6.283185307179586, '--blocks': [0, 1, 2, 3, 4, 5, 6, 9, 12, 15, 18, 21, 24, 27, 30, 35, 40], '--kernel_size': 5, '--max_order': 2, '--dx': 0.19634954084936207, '--hidden_layers': 5, '--scheme': 'upwind', '--dataname': 'burgers', '--viscosity': 0.05, '--zoom': 4, '--max_dt': 0.000625, '--batch_size': 28, '--data_timescheme': 'rk2', '--channel_names': 'u,v', '--freq': 4, '--data_start_time': 1.0, '--start_noise': 0.001, '--end_noise': 0.001, '--stablize': 0.0, '--sparsity': 0.0, '--momentsparsity': 0.001, '--npseed': -1, '--torchseed': -1, '--maxiter': 2000, '--recordfile': 'None', '--recordcycle': 200, '--savecycle': -1, '--start_from': -1}
Traceback (most recent call last):
  File "train.py", line 58, in <module>
    globalnames, callback, model, data_model, sampling, addnoise = setenv.setenv(options)
  File "/data/users2/sajad/code/PDE-Net/setenv.py", line 68, in setenv
    globalnames, callback, model = _set_model(options)
  File "/data/users2/sajad/code/PDE-Net/setenv.py", line 45, in _set_model
    model.to(globalnames['device'])
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 386, in to
    return self._apply(convert)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 193, in _apply
    module._apply(fn)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 193, in _apply
    module._apply(fn)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 205, in _apply
    self._buffers[key] = fn(buf)
  File "/home/users/mabavisani/anaconda3/envs/PDE-Net-2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 384, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
